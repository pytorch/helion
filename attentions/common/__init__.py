# Common utilities for standalone attention kernels
from .fla_utils import (
    IS_NVIDIA,
    IS_INTEL,
    IS_INTEL_ALCHEMIST,
    IS_NVIDIA_HOPPER,
    IS_NVIDIA_BLACKWELL,
    IS_TF32_SUPPORTED,
    IS_GATHER_SUPPORTED,
    device,
    device_name,
    device_platform,
    autotune_cache_kwargs,
    check_shared_mem,
    autocast_custom_fwd,
    autocast_custom_bwd,
    input_guard,
    contiguous,
    tensor_cache,
    assert_close,
    get_abs_err,
    get_err_ratio,
)

from .ops_utils import (
    exp,
    exp2,
    log,
    log2,
    softplus,
    softplus2,
    prepare_lens,
    prepare_chunk_indices,
    prepare_chunk_offsets,
    prepare_cu_seqlens_from_lens,
    prepare_cu_seqlens_from_mask,
    prepare_position_ids,
    prepare_sequence_ids,
    prepare_token_indices,
    get_max_num_splits,
    LN2,
    RCP_LN2,
)

__all__ = [
    # Platform detection
    "IS_NVIDIA",
    "IS_INTEL",
    "IS_INTEL_ALCHEMIST",
    "IS_NVIDIA_HOPPER",
    "IS_NVIDIA_BLACKWELL",
    "IS_TF32_SUPPORTED",
    "IS_GATHER_SUPPORTED",
    # Device
    "device",
    "device_name",
    "device_platform",
    # Decorators and utilities
    "autotune_cache_kwargs",
    "check_shared_mem",
    "autocast_custom_fwd",
    "autocast_custom_bwd",
    "input_guard",
    "contiguous",
    "tensor_cache",
    "assert_close",
    "get_abs_err",
    "get_err_ratio",
    # Triton ops
    "exp",
    "exp2",
    "log",
    "log2",
    "softplus",
    "softplus2",
    # Index utilities
    "prepare_lens",
    "prepare_chunk_indices",
    "prepare_chunk_offsets",
    "prepare_cu_seqlens_from_lens",
    "prepare_cu_seqlens_from_mask",
    "prepare_position_ids",
    "prepare_sequence_ids",
    "prepare_token_indices",
    "get_max_num_splits",
    # Constants
    "LN2",
    "RCP_LN2",
]
