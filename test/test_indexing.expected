This file is automatically generated by assertExpectedJournal calls in test_indexing.py.
Update expected outputs by running tests with the EXPECTTEST_ACCEPT=1 environment variable set.

--- assertExpectedJournal(TestIndexing.test_arange)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_arange(out, length, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < length
    tl.store(out + indices_0 * 1, indices_0, mask_0)

def arange(length: int, device: torch.device, *, _launcher=_default_launcher):
    out = torch.empty([length], dtype=torch.int32, device=device)
    _BLOCK_SIZE_0 = 32
    _launcher(_helion_arange, (triton.cdiv(length, _BLOCK_SIZE_0),), out, length, _BLOCK_SIZE_0, num_warps=4, num_stages=2)
    return out

--- assertExpectedJournal(TestIndexing.test_arange_block_size_multiple)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_arange_block_size_mul(out, _BLOCK_SIZE_0: tl.constexpr, mul_2: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    mul = 2 * offset_0
    indices = mul + tl.arange(0, mul_2)
    tl.store(out + indices * 1, indices, None)

def arange_block_size_mul(x: torch.Tensor, *, _launcher=_default_launcher):
    out = torch.zeros([x.size(0) * 2], dtype=torch.int32, device=x.device)
    _BLOCK_SIZE_0 = 64
    _launcher(_helion_arange_block_size_mul, (triton.cdiv(64, _BLOCK_SIZE_0),), out, _BLOCK_SIZE_0, 2 * _BLOCK_SIZE_0, num_warps=4, num_stages=2)
    return out

--- assertExpectedJournal(TestIndexing.test_arange_three_args_step)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_arange_three_args_step(out, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mul = 2 * offset_0
    iota = (mul + 2 * tl.arange(0, _BLOCK_SIZE_0)).to(tl.int64)
    v_0 = tl.cast(iota, tl.int32)
    tl.store(out + indices_0 * 1, v_0, None)

def arange_three_args_step(x: torch.Tensor, *, _launcher=_default_launcher):
    out = torch.zeros([x.size(0) // 2], dtype=torch.int32, device=x.device)
    _BLOCK_SIZE_0 = 8
    _launcher(_helion_arange_three_args_step, (triton.cdiv(32, _BLOCK_SIZE_0),), out, _BLOCK_SIZE_0, num_warps=4, num_stages=2)
    return out

--- assertExpectedJournal(TestIndexing.test_broadcasting_block_ptr_indexing)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_broadcast_add_3d(x, bias1, bias2, out, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    num_blocks_0 = tl.cdiv(16, _BLOCK_SIZE_0)
    num_blocks_1 = tl.cdiv(24, _BLOCK_SIZE_1)
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0 % num_blocks_1
    pid_2 = tl.program_id(0) // (num_blocks_0 * num_blocks_1)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    offset_1 = pid_1 * _BLOCK_SIZE_1
    offset_2 = pid_2 * _BLOCK_SIZE_2
    load = tl.load(tl.make_block_ptr(x, [16, 24, 32], [768, 32, 1], [offset_0, offset_1, offset_2], [_BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2], [2, 1, 0]), boundary_check=[0, 1, 2], padding_option='zero')
    load_1 = tl.load(tl.make_block_ptr(bias1, [1, 24, 32], [768, 32, 1], [0, offset_1, offset_2], [1, _BLOCK_SIZE_1, _BLOCK_SIZE_2], [2, 1, 0]), boundary_check=[1, 2], padding_option='zero')
    v_0 = load + load_1
    load_2 = tl.load(tl.make_block_ptr(bias2, [16, 1, 32], [32, 32, 1], [offset_0, 0, offset_2], [_BLOCK_SIZE_0, 1, _BLOCK_SIZE_2], [2, 1, 0]), boundary_check=[0, 2], padding_option='zero')
    v_1 = v_0 + load_2
    tl.store(tl.make_block_ptr(out, [16, 24, 32], [768, 32, 1], [offset_0, offset_1, offset_2], [_BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2], [2, 1, 0]), v_1, boundary_check=[0, 1, 2])

def broadcast_add_3d(x: torch.Tensor, bias1: torch.Tensor, bias2: torch.Tensor, *, _launcher=_default_launcher):
    d0, d1, d2 = x.size()
    out = torch.empty_like(x)
    _BLOCK_SIZE_0 = 8
    _BLOCK_SIZE_1 = 8
    _BLOCK_SIZE_2 = 8
    _launcher(_helion_broadcast_add_3d, (triton.cdiv(16, _BLOCK_SIZE_0) * triton.cdiv(24, _BLOCK_SIZE_1) * triton.cdiv(32, _BLOCK_SIZE_2),), x, bias1, bias2, out, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, num_warps=4, num_stages=2)
    return out

--- assertExpectedJournal(TestIndexing.test_broadcasting_pointer_indexing)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_broadcast_add_3d(x, bias1, bias2, out, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    num_blocks_0 = tl.cdiv(16, _BLOCK_SIZE_0)
    num_blocks_1 = tl.cdiv(24, _BLOCK_SIZE_1)
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0 % num_blocks_1
    pid_2 = tl.program_id(0) // (num_blocks_0 * num_blocks_1)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    offset_2 = pid_2 * _BLOCK_SIZE_2
    indices_2 = (offset_2 + tl.arange(0, _BLOCK_SIZE_2)).to(tl.int32)
    load = tl.load(x + (indices_0[:, None, None] * 768 + indices_1[None, :, None] * 32 + indices_2[None, None, :] * 1), None)
    load_1 = tl.load(bias1 + (indices_1[None, :, None] * 32 + indices_2[None, None, :] * 1), None)
    v_0 = load + load_1
    load_2 = tl.load(bias2 + (indices_0[:, None, None] * 32 + indices_2[None, None, :] * 1), None)
    v_1 = v_0 + load_2
    tl.store(out + (indices_0[:, None, None] * 768 + indices_1[None, :, None] * 32 + indices_2[None, None, :] * 1), v_1, None)

def broadcast_add_3d(x: torch.Tensor, bias1: torch.Tensor, bias2: torch.Tensor, *, _launcher=_default_launcher):
    d0, d1, d2 = x.size()
    out = torch.empty_like(x)
    _BLOCK_SIZE_0 = 8
    _BLOCK_SIZE_1 = 8
    _BLOCK_SIZE_2 = 8
    _launcher(_helion_broadcast_add_3d, (triton.cdiv(16, _BLOCK_SIZE_0) * triton.cdiv(24, _BLOCK_SIZE_1) * triton.cdiv(32, _BLOCK_SIZE_2),), x, bias1, bias2, out, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, num_warps=4, num_stages=2)
    return out

--- assertExpectedJournal(TestIndexing.test_broadcasting_tensor_descriptor_indexing)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

helion.runtime.set_triton_allocator()

@triton.jit
def _helion_broadcast_add_3d(x, bias1, bias2, out, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    x_desc = tl.make_tensor_descriptor(x, [16, 24, 32], [768, 32, 1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2])
    bias1_desc = tl.make_tensor_descriptor(bias1, [1, 24, 32], [768, 32, 1], [1, _BLOCK_SIZE_1, _BLOCK_SIZE_2])
    bias2_desc = tl.make_tensor_descriptor(bias2, [16, 1, 32], [32, 32, 1], [_BLOCK_SIZE_0, 1, _BLOCK_SIZE_2])
    out_desc = tl.make_tensor_descriptor(out, [16, 24, 32], [768, 32, 1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2])
    num_blocks_0 = tl.cdiv(16, _BLOCK_SIZE_0)
    num_blocks_1 = tl.cdiv(24, _BLOCK_SIZE_1)
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0 % num_blocks_1
    pid_2 = tl.program_id(0) // (num_blocks_0 * num_blocks_1)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    offset_1 = pid_1 * _BLOCK_SIZE_1
    offset_2 = pid_2 * _BLOCK_SIZE_2
    load = x_desc.load([offset_0, offset_1, offset_2])
    load_1 = bias1_desc.load([0, offset_1, offset_2])
    v_0 = load + load_1
    load_2 = bias2_desc.load([offset_0, 0, offset_2])
    v_1 = v_0 + load_2
    out_desc.store([offset_0, offset_1, offset_2], v_1)

def broadcast_add_3d(x: torch.Tensor, bias1: torch.Tensor, bias2: torch.Tensor, *, _launcher=_default_launcher):
    d0, d1, d2 = x.size()
    out = torch.empty_like(x)
    _BLOCK_SIZE_0 = 8
    _BLOCK_SIZE_1 = 8
    _BLOCK_SIZE_2 = 8
    _launcher(_helion_broadcast_add_3d, (triton.cdiv(16, _BLOCK_SIZE_0) * triton.cdiv(24, _BLOCK_SIZE_1) * triton.cdiv(32, _BLOCK_SIZE_2),), x, bias1, bias2, out, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, num_warps=4, num_stages=2)
    return out

--- assertExpectedJournal(TestIndexing.test_hl_arange_non_power_of_2)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion__matmul_layernorm_bwd_dxdy(z, grad_out, weight, mean, rstd, y, grad_x, x, grad_y, grad_out_stride_0, grad_out_stride_1, grad_x_stride_0, grad_x_stride_1, grad_y_stride_0, grad_y_stride_1, mean_stride_0, rstd_stride_0, weight_stride_0, x_stride_0, x_stride_1, y_stride_0, y_stride_1, z_stride_0, z_stride_1, m, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr, _RDIM_SIZE_2: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < m
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    mask_1 = indices_1 < 7
    indices_2 = tl.arange(0, _RDIM_SIZE_2).to(tl.int32)
    mask_2 = indices_2 < 3
    load = tl.load(z + (indices_0[:, None] * z_stride_0 + indices_1[None, :] * z_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
    v_0 = tl.cast(load, tl.float32)
    load_1 = tl.load(grad_out + (indices_0[:, None] * grad_out_stride_0 + indices_1[None, :] * grad_out_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
    v_1 = tl.cast(load_1, tl.float32)
    load_2 = tl.load(weight + indices_1 * weight_stride_0, mask_1, other=0)
    v_2 = tl.cast(load_2, tl.float32)
    mean_tile = tl.load(mean + indices_0 * mean_stride_0, mask_0, other=0)
    rstd_tile = tl.load(rstd + indices_0 * rstd_stride_0, mask_0, other=0)
    subscript = mean_tile[:, None]
    v_3 = v_0 - subscript
    subscript_1 = rstd_tile[:, None]
    v_4 = v_3 * subscript_1
    v_5 = v_2[None, :]
    v_6 = v_5 * v_1
    v_7 = v_4 * v_6
    sum_1 = tl.cast(tl.reshape(tl.sum(v_7, 1), [_BLOCK_SIZE_0, 1]), tl.float32)
    v_8 = 0.14285714285714285
    v_9 = sum_1 * v_8
    sum_2 = tl.cast(tl.reshape(tl.sum(v_6, 1), [_BLOCK_SIZE_0, 1]), tl.float32)
    v_10 = 0.14285714285714285
    v_11 = sum_2 * v_10
    v_12 = v_4 * v_9
    v_13 = v_12 + v_11
    v_14 = v_6 - v_13
    subscript_2 = rstd_tile[:, None]
    v_15 = v_14 * subscript_2
    load_5 = tl.load(y + (indices_2[:, None] * y_stride_0 + indices_1[None, :] * y_stride_1), mask_2[:, None] & mask_1[None, :], other=0)
    permute = tl.permute(load_5, [1, 0])
    v_16 = tl.cast(permute, tl.float32)
    mm = tl.split(tl.permute(tl.reshape(tl.split(tl.permute(tl.reshape(tl.dot(tl.reshape(tl.permute(tl.join(tl.cast(v_15, tl.float32), tl.zeros_like(tl.cast(v_15, tl.float32))), [0, 2, 1]), [16, 16]), tl.reshape(tl.permute(tl.join(tl.reshape(tl.permute(tl.join(tl.reshape(tl.permute(tl.join(tl.cast(v_16, tl.float32), tl.zeros_like(tl.cast(v_16, tl.float32))), [2, 0, 1]), [16, 4]), tl.zeros_like(tl.reshape(tl.permute(tl.join(tl.cast(v_16, tl.float32), tl.zeros_like(tl.cast(v_16, tl.float32))), [2, 0, 1]), [16, 4]))), [0, 2, 1]), [16, 8]), tl.zeros_like(tl.reshape(tl.permute(tl.join(tl.reshape(tl.permute(tl.join(tl.cast(v_16, tl.float32), tl.zeros_like(tl.cast(v_16, tl.float32))), [2, 0, 1]), [16, 4]), tl.zeros_like(tl.reshape(tl.permute(tl.join(tl.cast(v_16, tl.float32), tl.zeros_like(tl.cast(v_16, tl.float32))), [2, 0, 1]), [16, 4]))), [0, 2, 1]), [16, 8]))), [0, 2, 1]), [16, 16]), input_precision='tf32', out_dtype=tl.float32), [16, 2, 8]), [0, 2, 1]))[0], [16, 2, 4]), [0, 2, 1]))[0]
    v_17 = tl.cast(mm, tl.float16)
    tl.store(grad_x + (indices_0[:, None] * grad_x_stride_0 + indices_2[None, :] * grad_x_stride_1), v_17, mask_0[:, None] & mask_2[None, :])
    load_6 = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_2[None, :] * x_stride_1), mask_0[:, None] & mask_2[None, :], other=0)
    permute_1 = tl.permute(load_6, [1, 0])
    v_18 = tl.cast(permute_1, tl.float32)
    mm_1 = tl.split(tl.permute(tl.reshape(tl.split(tl.permute(tl.reshape(tl.split(tl.permute(tl.reshape(tl.dot(tl.reshape(tl.permute(tl.join(tl.reshape(tl.permute(tl.join(tl.cast(v_18, tl.float32), tl.zeros_like(tl.cast(v_18, tl.float32))), [2, 0, 1]), [8, 16]), tl.zeros_like(tl.reshape(tl.permute(tl.join(tl.cast(v_18, tl.float32), tl.zeros_like(tl.cast(v_18, tl.float32))), [2, 0, 1]), [8, 16]))), [2, 0, 1]), [16, 16]), tl.reshape(tl.permute(tl.join(tl.cast(v_15, tl.float32), tl.zeros_like(tl.cast(v_15, tl.float32))), [0, 2, 1]), [16, 16]), input_precision='tf32', out_dtype=tl.float32), [16, 2, 8]), [0, 2, 1]))[0], [2, 8, 8]), [1, 2, 0]))[0], [2, 4, 8]), [1, 2, 0]))[0]
    v_19 = tl.cast(mm_1, tl.float16)
    iota = tl.arange(0, 4)
    iota_1 = tl.arange(0, 8)
    tl.atomic_add(grad_y + (iota[:, None] * grad_y_stride_0 + iota_1[None, :] * grad_y_stride_1), v_19, mask=(iota < 3)[:, None] & (iota_1 < 7)[None, :], sem='relaxed')

def _matmul_layernorm_bwd_dxdy(grad_out: torch.Tensor, x: torch.Tensor, y: torch.Tensor, z: torch.Tensor, mean: torch.Tensor, rstd: torch.Tensor, weight: torch.Tensor, *, _launcher=_default_launcher):
    m, n = z.shape
    grad_x = torch.empty_like(x)
    grad_y = torch.zeros_like(y)
    _BLOCK_SIZE_0 = 16
    _RDIM_SIZE_1 = 8
    _RDIM_SIZE_2 = 4
    _launcher(_helion__matmul_layernorm_bwd_dxdy, (triton.cdiv(m, _BLOCK_SIZE_0),), z, grad_out, weight, mean, rstd, y, grad_x, x, grad_y, grad_out.stride(0), grad_out.stride(1), grad_x.stride(0), grad_x.stride(1), grad_y.stride(0), grad_y.stride(1), mean.stride(0), rstd.stride(0), weight.stride(0), x.stride(0), x.stride(1), y.stride(0), y.stride(1), z.stride(0), z.stride(1), m, _BLOCK_SIZE_0, _RDIM_SIZE_1, _RDIM_SIZE_2, num_warps=4, num_stages=2)
    return (grad_x, grad_y)

--- assertExpectedJournal(TestIndexing.test_mask_load)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_masked_load(x, out, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < 200
    v_0 = tl.full([], 2, tl.int32)
    v_1 = indices_0 % v_0
    v_2 = tl.full([], 0, tl.int32)
    v_3 = v_1 != v_2
    v_4 = libdevice.signbit(v_1) != 0 if v_1.dtype is tl.float32 else v_1 < 0
    v_5 = libdevice.signbit(v_0) != 0 if v_0.dtype is tl.float32 else v_0 < 0
    v_6 = v_4 != v_5
    v_7 = v_3 & v_6
    v_8 = v_1 + v_0
    v_9 = tl.where(v_7, v_8, v_1)
    v_10 = tl.full([], 0, tl.int32)
    v_11 = v_9 == v_10
    load = tl.load(x + indices_0 * 1, mask_0 & v_11, other=0)
    tl.store(out + indices_0 * 1, load, mask_0)

def masked_load(x: torch.Tensor, *, _launcher=_default_launcher):
    out = torch.zeros_like(x)
    _BLOCK_SIZE_0 = 16
    _launcher(_helion_masked_load, (triton.cdiv(200, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, num_warps=4, num_stages=2)
    return out

--- assertExpectedJournal(TestIndexing.test_mask_store)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_masked_store(x, out, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < 200
    load = tl.load(x + indices_0 * 1, mask_0, other=0)
    v_0 = tl.full([], 2, tl.int32)
    v_1 = indices_0 % v_0
    v_2 = tl.full([], 0, tl.int32)
    v_3 = v_1 != v_2
    v_4 = libdevice.signbit(v_1) != 0 if v_1.dtype is tl.float32 else v_1 < 0
    v_5 = libdevice.signbit(v_0) != 0 if v_0.dtype is tl.float32 else v_0 < 0
    v_6 = v_4 != v_5
    v_7 = v_3 & v_6
    v_8 = v_1 + v_0
    v_9 = tl.where(v_7, v_8, v_1)
    v_10 = tl.full([], 0, tl.int32)
    v_11 = v_9 == v_10
    tl.store(out + indices_0 * 1, load, mask_0 & v_11)

def masked_store(x: torch.Tensor, *, _launcher=_default_launcher):
    out = torch.zeros_like(x)
    _BLOCK_SIZE_0 = 16
    _launcher(_helion_masked_store, (triton.cdiv(200, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, num_warps=4, num_stages=2)
    return out

--- assertExpectedJournal(TestIndexing.test_pairwise_add)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_pairwise_add(x, out, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < 499
    load = tl.load(x + indices_0 * 1, mask_0, other=0)
    v_0 = tl.full([], 1, tl.int32)
    v_1 = indices_0 + v_0
    load_1 = tl.load(x + (indices_0 + 1) * 1, mask_0, other=0)
    v_2 = load + load_1
    tl.store(out + indices_0 * 1, v_2, mask_0)

def pairwise_add(x: torch.Tensor, *, _launcher=_default_launcher):
    out = x.new_empty([x.size(0) - 1])
    _BLOCK_SIZE_0 = 32
    _launcher(_helion_pairwise_add, (triton.cdiv(499, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, num_warps=4, num_stages=2)
    return out

--- assertExpectedJournal(TestIndexing.test_reduction_tensor_descriptor_indexing_block_size)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_reduction_sum(x, out, out_stride_0, x_stride_0, x_stride_1, m, _, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < m
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    mask_1 = indices_1 < _
    load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
    sum_1 = tl.sum(load, 1)
    tl.store(out + indices_0 * out_stride_0, sum_1, mask_0)

def reduction_sum(x: torch.Tensor, *, _launcher=_default_launcher):
    m, _ = x.size()
    out = torch.empty([m], device=x.device, dtype=x.dtype)
    _BLOCK_SIZE_0 = 4
    _RDIM_SIZE_1 = triton.next_power_of_2(_)
    _launcher(_helion_reduction_sum, (triton.cdiv(m, _BLOCK_SIZE_0),), x, out, out.stride(0), x.stride(0), x.stride(1), m, _, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=3)
    return out

--- assertExpectedJournal(TestIndexing.test_reduction_tensor_descriptor_indexing_reduction_loop)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_reduction_sum(x, out, out_stride_0, x_stride_0, x_stride_1, m, _, _BLOCK_SIZE_0: tl.constexpr, _REDUCTION_BLOCK_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < m
    sum_1_acc = tl.full([_BLOCK_SIZE_0, _REDUCTION_BLOCK_1], 0, tl.float32)
    for roffset_1 in tl.range(0, _, _REDUCTION_BLOCK_1):
        rindex_1 = roffset_1 + tl.arange(0, _REDUCTION_BLOCK_1).to(tl.int32)
        mask_1 = rindex_1 < _
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + rindex_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = load.to(tl.float32)
        v_1 = sum_1_acc + v_0
        sum_1_acc = v_1
    sum_1 = tl.sum(sum_1_acc, 1)
    v_2 = sum_1.to(tl.float16)
    tl.store(out + indices_0 * out_stride_0, v_2, mask_0)

def reduction_sum(x: torch.Tensor, *, _launcher=_default_launcher):
    m, _ = x.size()
    out = torch.empty([m], device=x.device, dtype=x.dtype)
    _BLOCK_SIZE_0 = 8
    _REDUCTION_BLOCK_1 = 8
    _launcher(_helion_reduction_sum, (triton.cdiv(m, _BLOCK_SIZE_0),), x, out, out.stride(0), x.stride(0), x.stride(1), m, _, _BLOCK_SIZE_0, _REDUCTION_BLOCK_1, num_warps=4, num_stages=3)
    return out

--- assertExpectedJournal(TestIndexing.test_slice_block_size_multiple)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_arange_block_size_mul(ones, out, _BLOCK_SIZE_0: tl.constexpr, mul_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    mul = 2 * offset_0
    iota = mul + tl.arange(0, mul_1)
    load = tl.load(ones + iota * 1, None)
    iota_1 = mul + tl.arange(0, mul_1)
    tl.store(out + iota_1 * 1, load, None)

def arange_block_size_mul(x: torch.Tensor, *, _launcher=_default_launcher):
    out = torch.zeros([x.size(0) * 2], dtype=torch.int32, device=x.device)
    ones = torch.ones_like(out)
    _BLOCK_SIZE_0 = 64
    _launcher(_helion_arange_block_size_mul, (triton.cdiv(64, _BLOCK_SIZE_0),), ones, out, _BLOCK_SIZE_0, 2 * _BLOCK_SIZE_0, num_warps=4, num_stages=2)
    return out

--- assertExpectedJournal(TestIndexing.test_tile_count_top_level)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_fn(out, n, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < n
    tile_count = tl.cdiv(n, _BLOCK_SIZE_0)
    tl.store(out + indices_0 * 1, tile_count, mask_0)

def fn(n: int, device: torch.device, *, _launcher=_default_launcher):
    out = torch.zeros([n], dtype=torch.int32, device=device)
    _BLOCK_SIZE_0 = 64
    _launcher(_helion_fn, (triton.cdiv(n, _BLOCK_SIZE_0),), out, n, _BLOCK_SIZE_0, num_warps=4, num_stages=2)
    return out

--- assertExpectedJournal(TestIndexing.test_tile_count_with_begin_end)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_fn(out, begin, end, _BLOCK_SIZE_0: tl.constexpr):
    tile_count = tl.cdiv(end + -1 * begin, _BLOCK_SIZE_0)
    tl.store(out + tl.zeros([], tl.int32), tile_count, None)

def fn(begin: int, end: int, device: torch.device, *, _launcher=_default_launcher):
    out = torch.zeros([1], dtype=torch.int32, device=device)
    _BLOCK_SIZE_0 = 32
    _launcher(_helion_fn, (triton.cdiv(end + -1 * begin, _BLOCK_SIZE_0),), out, begin, end, _BLOCK_SIZE_0, num_warps=4, num_stages=2)
    return out

--- assertExpectedJournal(TestIndexing.test_tile_with_offset_block_ptr)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_tile_offset_kernel(x, out, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    v_0 = tl.full([], 10, tl.int32)
    v_1 = indices_0 + v_0
    load = tl.load(tl.make_block_ptr(x, [200], [1], [offset_0 + 10], [_BLOCK_SIZE_0], [0]), boundary_check=[0], padding_option='zero')
    tl.store(tl.make_block_ptr(out, [190], [1], [offset_0], [_BLOCK_SIZE_0], [0]), load, boundary_check=[0])

def tile_offset_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    out = x.new_empty(x.size(0) - 10)
    _BLOCK_SIZE_0 = 32
    _launcher(_helion_tile_offset_kernel, (triton.cdiv(190, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, num_warps=4, num_stages=2)
    return out

--- assertExpectedJournal(TestIndexing.test_tile_with_offset_from_expr)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from torch._inductor.runtime import triton_helpers
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_attention(q, k, v, lse, o, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_2: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_3 = tl.arange(0, _RDIM_SIZE_2).to(tl.int32)
    full = tl.full([_BLOCK_SIZE_0], 0.0, tl.float32)
    v_0 = float('inf')
    v_1 = full - v_0
    full_1 = tl.full([_BLOCK_SIZE_0], 0.0, tl.float32)
    v_2 = 1.0
    v_3 = full_1 + v_2
    acc = tl.full([_BLOCK_SIZE_0, 64], 0.0, tl.float32)
    q_i = tl.load(q + (indices_0[:, None] * 64 + indices_3[None, :] * 1), None)
    symnode_0 = 64 * triton_helpers.div_floor_integer(offset_0, 64)
    for offset_2 in tl.range(0, 64, _BLOCK_SIZE_1):
        indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_1).to(tl.int32)
        q_i_copy = q_i
        v_1_copy = v_1
        acc_copy = acc
        v_3_copy = v_3
        q_i_copy_0 = q_i_copy
        v_1_copy_0 = v_1_copy
        acc_copy_0 = acc_copy
        v_3_copy_0 = v_3_copy
        v_4 = tl.cast(symnode_0, tl.int32)
        v_5 = indices_2 + v_4
        k_j = tl.load(k + ((indices_2 + symnode_0)[:, None] * 64 + indices_3[None, :] * 1), None)
        v_6 = tl.cast(symnode_0, tl.int32)
        v_7 = indices_2 + v_6
        v_j = tl.load(v + ((indices_2 + symnode_0)[:, None] * 64 + indices_3[None, :] * 1), None)
        permute = tl.permute(k_j, [1, 0])
        qk = tl.dot(tl.cast(q_i_copy_0, tl.bfloat16), tl.cast(permute, tl.bfloat16), input_precision='tf32', out_dtype=tl.float32)
        amax = tl.cast(tl.max(qk, 1), tl.float32)
        v_8 = 0.18033688
        v_9 = amax * v_8
        v_10 = triton_helpers.maximum(v_1_copy_0, v_9)
        v_11 = 0.18033688
        v_12 = qk * v_11
        subscript = v_10[:, None]
        v_13 = v_12 - subscript
        v_14 = libdevice.exp2(v_13)
        v_15 = v_1_copy_0 - v_10
        v_16 = libdevice.exp2(v_15)
        l_ij = tl.cast(tl.sum(v_14, 1), tl.float32)
        subscript_1 = v_16[:, None]
        v_17 = acc_copy_0 * subscript_1
        v_18 = tl.cast(v_14, tl.bfloat16)
        acc = tl.dot(tl.cast(v_18, tl.bfloat16), tl.cast(v_j, tl.bfloat16), acc=v_17, input_precision='tf32', out_dtype=tl.float32)
        v_19 = v_3_copy_0 * v_16
        v_3 = v_19 + l_ij
        v_1 = v_10
    v_21 = libdevice.log2(v_3)
    v_22 = v_1 + v_21
    subscript_2 = v_3[:, None]
    v_23 = acc / subscript_2
    tl.store(lse + indices_0 * 1, v_22, None)
    v_24 = tl.cast(v_23, tl.bfloat16)
    tl.store(o + (indices_0[:, None] * 64 + indices_3[None, :] * 1), v_24, None)

def attention(q_in: torch.Tensor, k_in: torch.Tensor, v_in: torch.Tensor, *, _launcher=_default_launcher):
    B, H, M, D = q_in.shape
    Bk, Hk, N, Dk = k_in.shape
    Bv, Hv, Nv, Dv = v_in.shape
    D = 64
    Dv = 64
    q = q_in.reshape(-1, D)
    k = k_in.reshape(-1, D)
    v = v_in.reshape(-1, Dv)
    MM = q.shape[0]
    o = q.new_empty(MM, Dv)
    lse = q.new_empty(MM, dtype=torch.float32)
    _BLOCK_SIZE_0 = 32
    _RDIM_SIZE_2 = 64
    _BLOCK_SIZE_1 = 32
    _launcher(_helion_attention, (triton.cdiv(8192, _BLOCK_SIZE_0),), q, k, v, lse, o, _BLOCK_SIZE_0, _RDIM_SIZE_2, _BLOCK_SIZE_1, num_warps=4, num_stages=2)
    return (o.reshape(B, H, M, Dv), lse.reshape(B, H, M))

--- assertExpectedJournal(TestIndexing.test_tile_with_offset_pointer)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_tile_offset_kernel(x, out, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < 190
    v_0 = tl.full([], 10, tl.int32)
    v_1 = indices_0 + v_0
    load = tl.load(x + (indices_0 + 10) * 1, mask_0, other=0)
    tl.store(out + indices_0 * 1, load, mask_0)

def tile_offset_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    out = x.new_empty(x.size(0) - 10)
    _BLOCK_SIZE_0 = 32
    _launcher(_helion_tile_offset_kernel, (triton.cdiv(190, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, num_warps=4, num_stages=2)
    return out

--- assertExpectedJournal(TestIndexing.test_tile_with_offset_tensor_descriptor)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

helion.runtime.set_triton_allocator()

@triton.jit
def _helion_tile_offset_2d_kernel(x, out, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    x_desc = tl.make_tensor_descriptor(x, [128, 64], [64, 1], [_BLOCK_SIZE_0, _RDIM_SIZE_1])
    out_desc = tl.make_tensor_descriptor(out, [118, 64], [64, 1], [_BLOCK_SIZE_0, _RDIM_SIZE_1])
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    v_0 = tl.full([], 10, tl.int32)
    v_1 = indices_0 + v_0
    load = x_desc.load([offset_0 + 10, 0])
    out_desc.store([offset_0, 0], load)

def tile_offset_2d_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    M, N = x.size()
    out = x.new_empty(M - 10, N)
    _BLOCK_SIZE_0 = 32
    _RDIM_SIZE_1 = 64
    _launcher(_helion_tile_offset_2d_kernel, (triton.cdiv(118, _BLOCK_SIZE_0),), x, out, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return out
