This file is automatically generated by assertExpectedJournal calls in test_pallas.py.
Update expected outputs by running tests with the EXPECTTEST_ACCEPT=1 environment variable set.

--- assertExpectedJournal(TestPallasCodeGeneration.test_code_generation_patterns)
from __future__ import annotations

import torch
from helion.runtime import default_launcher as _default_launcher
from helion.runtime import pallas_launcher as _pallas_launcher

def _helion_add_kernel(x_ref, y_ref, out_ref):
    # src[test_pallas.py:N]: out[tile] = x[tile] + y[tile]
    load = x_ref[:]
    load_1 = y_ref[:]
    v_0 = load + load_1
    out_ref[:] = v_0

def add_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_pallas.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_pallas.py:N]: for tile in hl.tile(out.size()):
    _BLOCK_SIZE_0 = 16
    # src[test_pallas.py:N]: for tile in hl.tile(out.size()):
    # src[test_pallas.py:N]:     out[tile] = x[tile] + y[tile]
    _pallas_launcher(_helion_add_kernel, ((64 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0,), x, y, out, _BLOCK_SIZE_0)
    # src[test_pallas.py:N]: return out
    return out

--- assertExpectedJournal(TestPallasCodeGeneration.test_no_triton_cdiv)
from __future__ import annotations

import torch
from helion.runtime import default_launcher as _default_launcher
from helion.runtime import pallas_launcher as _pallas_launcher

def _helion_add_kernel(x_ref, y_ref, out_ref):
    # src[test_pallas.py:N]: out[tile] = x[tile] + y[tile]
    load = x_ref[:]
    load_1 = y_ref[:]
    v_0 = load + load_1
    out_ref[:] = v_0

def add_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_pallas.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_pallas.py:N]: for tile in hl.tile(out.size()):
    _BLOCK_SIZE_0 = 16
    # src[test_pallas.py:N]: for tile in hl.tile(out.size()):
    # src[test_pallas.py:N]:     out[tile] = x[tile] + y[tile]
    _pallas_launcher(_helion_add_kernel, ((100 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0,), x, y, out, _BLOCK_SIZE_0)
    # src[test_pallas.py:N]: return out
    return out

--- assertExpectedJournal(TestPallasDevice.test_add_kernel)
from __future__ import annotations

import torch
from helion.runtime import default_launcher as _default_launcher
from helion.runtime import pallas_launcher as _pallas_launcher

def _helion_add_kernel(x_ref, y_ref, out_ref):
    # src[test_pallas.py:N]: out[tile] = x[tile] + y[tile]
    load = x_ref[:]
    load_1 = y_ref[:]
    v_0 = load + load_1
    out_ref[:] = v_0

def add_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_pallas.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_pallas.py:N]: for tile in hl.tile(out.size()):
    _BLOCK_SIZE_0 = 128
    # src[test_pallas.py:N]: for tile in hl.tile(out.size()):
    # src[test_pallas.py:N]:     out[tile] = x[tile] + y[tile]
    _pallas_launcher(_helion_add_kernel, ((128 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0,), x, y, out, _BLOCK_SIZE_0)
    # src[test_pallas.py:N]: return out
    return out

--- assertExpectedJournal(TestPallasDevice.test_fused_add_mul_kernel)
from __future__ import annotations

import torch
from helion.runtime import default_launcher as _default_launcher
from helion.runtime import pallas_launcher as _pallas_launcher

def _helion_fused_kernel(x_ref, y_ref, z_ref, out_ref):
    # src[test_pallas.py:N]: out[tile] = (x[tile] + y[tile]) * z[tile]
    load = x_ref[:]
    load_1 = y_ref[:]
    v_0 = load + load_1
    load_2 = z_ref[:]
    v_1 = v_0 * load_2
    out_ref[:] = v_1

def fused_kernel(x: torch.Tensor, y: torch.Tensor, z: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_pallas.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_pallas.py:N]: for tile in hl.tile(out.size()):
    _BLOCK_SIZE_0 = 128
    # src[test_pallas.py:N]: for tile in hl.tile(out.size()):
    # src[test_pallas.py:N]:     out[tile] = (x[tile] + y[tile]) * z[tile]
    _pallas_launcher(_helion_fused_kernel, ((128 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0,), x, y, z, out, _BLOCK_SIZE_0)
    # src[test_pallas.py:N]: return out
    return out

--- assertExpectedJournal(TestPallasDevice.test_mul_kernel)
from __future__ import annotations

import torch
from helion.runtime import default_launcher as _default_launcher
from helion.runtime import pallas_launcher as _pallas_launcher

def _helion_mul_kernel(x_ref, out_ref):
    # src[test_pallas.py:N]: out[tile] = x[tile] * 2.0
    load = x_ref[:]
    v_0 = 2.0
    v_1 = load * v_0
    out_ref[:] = v_1

def mul_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_pallas.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_pallas.py:N]: for tile in hl.tile(out.size()):
    _BLOCK_SIZE_0 = 128
    # src[test_pallas.py:N]: for tile in hl.tile(out.size()):
    # src[test_pallas.py:N]:     out[tile] = x[tile] * 2.0
    _pallas_launcher(_helion_mul_kernel, ((128 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0,), x, out, _BLOCK_SIZE_0)
    # src[test_pallas.py:N]: return out
    return out

--- assertExpectedJournal(TestPallasDevice.test_sub_kernel)
from __future__ import annotations

import torch
from helion.runtime import default_launcher as _default_launcher
from helion.runtime import pallas_launcher as _pallas_launcher

def _helion_sub_kernel(x_ref, y_ref, out_ref):
    # src[test_pallas.py:N]: out[tile] = x[tile] - y[tile]
    load = x_ref[:]
    load_1 = y_ref[:]
    v_0 = load - load_1
    out_ref[:] = v_0

def sub_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_pallas.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_pallas.py:N]: for tile in hl.tile(out.size()):
    _BLOCK_SIZE_0 = 128
    # src[test_pallas.py:N]: for tile in hl.tile(out.size()):
    # src[test_pallas.py:N]:     out[tile] = x[tile] - y[tile]
    _pallas_launcher(_helion_sub_kernel, ((128 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0,), x, y, out, _BLOCK_SIZE_0)
    # src[test_pallas.py:N]: return out
    return out
