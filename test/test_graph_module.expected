This file is automatically generated by assertExpectedJournal calls in test_graph_module.py.
Update expected outputs by running tests with the EXPECTTEST_ACCEPT=1 environment variable set.

--- assertExpectedJournal(TestGraphModule.test_graph_module_arg)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from torch._inductor.runtime.triton_helpers import math as tl_math
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_apply_graph_module(x, out, x_size_0, out_stride_0, x_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < x_size_0
    load = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_0 = 1.0
    v_1 = load + v_0
    v_2 = tl_math.sin(v_1)
    tl.store(out + indices_0 * out_stride_0, v_2, mask_0)

def apply_graph_module(func_m, x, *, _launcher=_default_launcher):
    """Kernel that applies a GraphModule function to tensor elements."""
    out = torch.empty_like(x)
    _BLOCK_SIZE_0 = 1024
    _launcher(_helion_apply_graph_module, (triton.cdiv(x.size(0), _BLOCK_SIZE_0),), x, out, x.size(0), out.stride(0), x.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return out

--- assertExpectedJournal(TestGraphModule.test_graph_module_with_multiple_ops)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from torch._inductor.runtime import triton_helpers
from torch._inductor.runtime.triton_helpers import math as tl_math
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_apply_graph_module(x, out, x_size_0, out_stride_0, x_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < x_size_0
    load = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    v_0 = 2.0
    v_1 = load * v_0
    v_2 = tl.full([], 0, tl.int32)
    v_3 = triton_helpers.maximum(v_2, v_1)
    v_4 = 1.0
    v_5 = v_3 + v_4
    v_6 = tl_math.cos(v_5)
    tl.store(out + indices_0 * out_stride_0, v_6, mask_0)

def apply_graph_module(func_m, x, *, _launcher=_default_launcher):
    """Kernel that applies a GraphModule function to tensor elements."""
    out = torch.empty_like(x)
    _BLOCK_SIZE_0 = 512
    _launcher(_helion_apply_graph_module, (triton.cdiv(x.size(0), _BLOCK_SIZE_0),), x, out, x.size(0), out.stride(0), x.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return out
