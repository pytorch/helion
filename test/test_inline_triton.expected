This file is automatically generated by assertExpectedJournal calls in test_inline_triton.py.
Update expected outputs by running tests with the EXPECTTEST_ACCEPT=1 environment variable set.

--- assertExpectedJournal(TestInlineTriton.test_inline_ctx)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_kernel(x, out, y, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr, _BLOCK_SIZE_4: tl.constexpr):
    # src[test_inline_triton.py:N]: for tile_m in hl.tile(M):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_inline_triton.py:N]: with hl.inline_ctx("tlx.async_tasks()"):
    # src[test_inline_triton.py:N]:     # Allocate barriers for inter-task communication
    # src[test_inline_triton.py:N]:     hl.inline_triton(
    # src[test_inline_triton.py:N-N]: ...
    with tlx.async_tasks():
        # src[test_inline_triton.py:N]: @helion.kernel(autotune_effort="none")
        data_full = tlx.alloc_barrier(1)
        data_empty = tlx.alloc_barrier(1)
        acc_full = tlx.alloc_barrier(1)
        o_full = tlx.alloc_barrier(1)
        o_empty = tlx.alloc_barrier(1)
        # src[test_inline_triton.py:N]: with hl.inline_ctx(
        # src[test_inline_triton.py:N]:     "tlx.async_task(num_warps={num_warps}, registers={registers})",
        # src[test_inline_triton.py:N]:     args={"num_warps": 1, "registers": 24},
        # src[test_inline_triton.py:N-N]: ...
        with tlx.async_task(num_warps=1, registers=24):
            # src[test_inline_triton.py:N]: for tile_n in hl.tile(N):
            # src[test_inline_triton.py:N]:     hl.inline_triton(
            # src[test_inline_triton.py:N]:         "tlx.barrier_wait({barrier}[0], 0)\n",
            # src[test_inline_triton.py:N-N]: ...
            for offset_1 in tl.range(0, 32, _BLOCK_SIZE_1):
                indices_1 = offset_1 + tl.arange(0, _BLOCK_SIZE_1).to(tl.int32)
                # src[test_inline_triton.py:N]: hl.inline_triton(
                # src[test_inline_triton.py:N]:     "tlx.barrier_wait({barrier}[0], 0)\n",
                # src[test_inline_triton.py:N]:     args={"barrier": "data_empty"},
                # src[test_inline_triton.py:N-N]: ...
                tlx.barrier_wait(data_empty[0], 0)
                # src[test_inline_triton.py:N]: out[tile_m, tile_n] = x[tile_m, tile_n]
                load = tl.load(x + (indices_0[:, None] * 32 + indices_1[None, :] * 1), None)
                tl.store(out + (indices_0[:, None] * 32 + indices_1[None, :] * 1), load, None)
                # src[test_inline_triton.py:N]: hl.inline_triton(
                # src[test_inline_triton.py:N]:     "tlx.barrier_arrive({barrier}[0])\n",
                # src[test_inline_triton.py:N]:     args={"barrier": "data_full"},
                # src[test_inline_triton.py:N-N]: ...
                tlx.barrier_arrive(data_full[0])
        # src[test_inline_triton.py:N]: with hl.inline_ctx(
        # src[test_inline_triton.py:N]:     "tlx.async_task(num_warps={num_warps}, registers={registers}, replicate={replicate})",
        # src[test_inline_triton.py:N]:     args={
        # src[test_inline_triton.py:N-N]: ...
        with tlx.async_task(num_warps=4, registers=168, replicate=2):
            # src[test_inline_triton.py:N]: for tile_n in hl.tile(N):
            # src[test_inline_triton.py:N]:     hl.inline_triton(
            # src[test_inline_triton.py:N]:         "tlx.barrier_wait({barrier}[0], 0)\n",
            # src[test_inline_triton.py:N-N]: ...
            for offset_2 in tl.range(0, 32, _BLOCK_SIZE_2):
                indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
                # src[test_inline_triton.py:N]: hl.inline_triton(
                # src[test_inline_triton.py:N]:     "tlx.barrier_wait({barrier}[0], 0)\n",
                # src[test_inline_triton.py:N]:     args={"barrier": "data_full"},
                # src[test_inline_triton.py:N-N]: ...
                tlx.barrier_wait(data_full[0], 0)
                # src[test_inline_triton.py:N]: staged = out[tile_m, tile_n]
                staged = tl.load(out + (indices_0[:, None] * 32 + indices_2[None, :] * 1), None)
                # src[test_inline_triton.py:N]: y_val = y[tile_m, tile_n]
                y_val = tl.load(y + (indices_0[:, None] * 32 + indices_2[None, :] * 1), None)
                # src[test_inline_triton.py:N]: out[tile_m, tile_n] = staged + y_val
                v_0 = staged + y_val
                tl.store(out + (indices_0[:, None] * 32 + indices_2[None, :] * 1), v_0, None)
                # src[test_inline_triton.py:N]: @helion.kernel(autotune_effort="none")
                tlx.barrier_arrive(acc_full[0])
                # src[test_inline_triton.py:N]: hl.inline_triton(
                # src[test_inline_triton.py:N]:     "tlx.barrier_arrive({barrier1}[0])\ntlx.barrier_arrive({barrier2}[0])\n",
                # src[test_inline_triton.py:N]:     args={"barrier1": "acc_full", "barrier2": "data_empty"},
                # src[test_inline_triton.py:N-N]: ...
                tlx.barrier_arrive(data_empty[0])
        # src[test_inline_triton.py:N]: with hl.inline_ctx("tlx.async_task('default')"):
        # src[test_inline_triton.py:N]:     for tile_n in hl.tile(N):
        # src[test_inline_triton.py:N]:         hl.inline_triton(
        # src[test_inline_triton.py:N-N]: ...
        with tlx.async_task('default'):
            # src[test_inline_triton.py:N]: for tile_n in hl.tile(N):
            # src[test_inline_triton.py:N]:     hl.inline_triton(
            # src[test_inline_triton.py:N]:         "tlx.barrier_wait({barrier}[0], 0)\n",
            # src[test_inline_triton.py:N-N]: ...
            for offset_3 in tl.range(0, 32, _BLOCK_SIZE_3):
                indices_3 = offset_3 + tl.arange(0, _BLOCK_SIZE_3).to(tl.int32)
                # src[test_inline_triton.py:N]: hl.inline_triton(
                # src[test_inline_triton.py:N]:     "tlx.barrier_wait({barrier}[0], 0)\n",
                # src[test_inline_triton.py:N]:     args={"barrier": "acc_full"},
                # src[test_inline_triton.py:N-N]: ...
                tlx.barrier_wait(acc_full[0], 0)
                # src[test_inline_triton.py:N]: acc = out[tile_m, tile_n]
                acc = tl.load(out + (indices_0[:, None] * 32 + indices_3[None, :] * 1), None)
                # src[test_inline_triton.py:N]: out[tile_m, tile_n] = acc * 2.0
                v_1 = 2.0
                v_2 = acc * v_1
                tl.store(out + (indices_0[:, None] * 32 + indices_3[None, :] * 1), v_2, None)
                # src[test_inline_triton.py:N]: hl.inline_triton(
                # src[test_inline_triton.py:N]:     "tlx.barrier_arrive({barrier}[0])\n",
                # src[test_inline_triton.py:N]:     args={"barrier": "o_full"},
                # src[test_inline_triton.py:N-N]: ...
                tlx.barrier_arrive(o_full[0])
        # src[test_inline_triton.py:N]: with hl.inline_ctx(
        # src[test_inline_triton.py:N]:     "tlx.async_task(num_warps={num_warps}, registers={registers})",
        # src[test_inline_triton.py:N]:     args={"num_warps": 1, "registers": 24},
        # src[test_inline_triton.py:N-N]: ...
        with tlx.async_task(num_warps=1, registers=24):
            # src[test_inline_triton.py:N]: for tile_n in hl.tile(N):
            # src[test_inline_triton.py:N]:     hl.inline_triton(
            # src[test_inline_triton.py:N]:         "tlx.barrier_wait({barrier}[0], 0)\n",
            # src[test_inline_triton.py:N-N]: ...
            for offset_4 in tl.range(0, 32, _BLOCK_SIZE_4):
                indices_4 = offset_4 + tl.arange(0, _BLOCK_SIZE_4).to(tl.int32)
                # src[test_inline_triton.py:N]: hl.inline_triton(
                # src[test_inline_triton.py:N]:     "tlx.barrier_wait({barrier}[0], 0)\n",
                # src[test_inline_triton.py:N]:     args={"barrier": "o_full"},
                # src[test_inline_triton.py:N-N]: ...
                tlx.barrier_wait(o_full[0], 0)
                # src[test_inline_triton.py:N]: result = out[tile_m, tile_n]
                result = tl.load(out + (indices_0[:, None] * 32 + indices_4[None, :] * 1), None)
                # src[test_inline_triton.py:N]: out[tile_m, tile_n] = result + 1.0
                v_3 = 1.0
                v_4 = result + v_3
                tl.store(out + (indices_0[:, None] * 32 + indices_4[None, :] * 1), v_4, None)
                # src[test_inline_triton.py:N]: hl.inline_triton(
                # src[test_inline_triton.py:N]:     "tlx.barrier_arrive({barrier}[0])\n",
                # src[test_inline_triton.py:N]:     args={"barrier": "o_empty"},
                # src[test_inline_triton.py:N-N]: ...
                tlx.barrier_arrive(o_empty[0])

def kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_inline_triton.py:N]: M, N = x.shape
    M, N = x.shape
    # src[test_inline_triton.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_inline_triton.py:N]: for tile_m in hl.tile(M):
    _BLOCK_SIZE_0 = 4
    # src[test_inline_triton.py:N]: for tile_n in hl.tile(N):
    # src[test_inline_triton.py:N]:     hl.inline_triton(
    # src[test_inline_triton.py:N]:         "tlx.barrier_wait({barrier}[0], 0)\n",
    # src[test_inline_triton.py:N-N]: ...
    _BLOCK_SIZE_1 = 16
    # src[test_inline_triton.py:N]: for tile_n in hl.tile(N):
    # src[test_inline_triton.py:N]:     hl.inline_triton(
    # src[test_inline_triton.py:N]:         "tlx.barrier_wait({barrier}[0], 0)\n",
    # src[test_inline_triton.py:N-N]: ...
    _BLOCK_SIZE_2 = 16
    # src[test_inline_triton.py:N]: for tile_n in hl.tile(N):
    # src[test_inline_triton.py:N]:     hl.inline_triton(
    # src[test_inline_triton.py:N]:         "tlx.barrier_wait({barrier}[0], 0)\n",
    # src[test_inline_triton.py:N-N]: ...
    _BLOCK_SIZE_3 = 16
    # src[test_inline_triton.py:N]: for tile_n in hl.tile(N):
    # src[test_inline_triton.py:N]:     hl.inline_triton(
    # src[test_inline_triton.py:N]:         "tlx.barrier_wait({barrier}[0], 0)\n",
    # src[test_inline_triton.py:N-N]: ...
    _BLOCK_SIZE_4 = 16
    # src[test_inline_triton.py:N]: for tile_m in hl.tile(M):
    # src[test_inline_triton.py:N]:     with hl.inline_ctx("tlx.async_tasks()"):
    # src[test_inline_triton.py:N]:         # Allocate barriers for inter-task communication
    # src[test_inline_triton.py:N-N]: ...
    _launcher(_helion_kernel, (triton.cdiv(4, _BLOCK_SIZE_0),), x, out, y, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3, _BLOCK_SIZE_4, num_warps=4, num_stages=1)
    # src[test_inline_triton.py:N]: return out
    return out

--- assertExpectedJournal(TestInlineTriton.test_inline_triton_list_args_reuse)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

_BLOCK_SIZE_0 = tl.constexpr(16)

@triton.jit
def _helion_kernel(x, y, out):
    # src[test_inline_triton.py:N]: for tile in hl.tile(x.shape):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_inline_triton.py:N]: x_val = x[tile]
    x_val = tl.load(x + indices_0 * 1, None)
    # src[test_inline_triton.py:N]: y_val = y[tile]
    y_val = tl.load(y + indices_0 * 1, None)
    # src[test_inline_triton.py:N]: @helion.kernel(autotune_effort="none")
    triple = x_val + x_val + x_val
    # src[test_inline_triton.py:N]: out[tile] = hl.inline_triton(
    # src[test_inline_triton.py:N]:     """
    # src[test_inline_triton.py:N]:     triple = {0} + {0} + {0}
    # src[test_inline_triton.py:N-N]: ...
    inline_triton_result = triple + y_val
    tl.static_assert(inline_triton_result.dtype == tl.float32, 'inline_triton output dtype mismatch; expected torch.float32')
    tl.static_assert(inline_triton_result.shape == x_val.shape, 'inline_triton output shape mismatch')
    tl.store(out + indices_0 * 1, inline_triton_result, None)

def kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_inline_triton.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_inline_triton.py:N]: for tile in hl.tile(x.shape):
    _BLOCK_SIZE_0 = 16
    # src[test_inline_triton.py:N]: for tile in hl.tile(x.shape):
    # src[test_inline_triton.py:N]:     x_val = x[tile]
    # src[test_inline_triton.py:N]:     y_val = y[tile]
    # src[test_inline_triton.py:N-N]: ...
    _launcher(_helion_kernel, (triton.cdiv(16, _BLOCK_SIZE_0),), x, y, out, num_warps=4, num_stages=1)
    # src[test_inline_triton.py:N]: return out
    return out

--- assertExpectedJournal(TestInlineTriton.test_inline_triton_multi_output)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

_BLOCK_SIZE_0 = tl.constexpr(32)

@triton.jit
def _helion_kernel(a, b, sum_out, diff_out):
    # src[test_inline_triton.py:N]: for tile in hl.tile(a.shape):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_inline_triton.py:N]: a_val = a[tile]
    a_val = tl.load(a + indices_0 * 1, None)
    # src[test_inline_triton.py:N]: b_val = b[tile]
    b_val = tl.load(b + indices_0 * 1, None)
    # src[test_inline_triton.py:N]: @helion.kernel(autotune_effort="none")
    sum_val = a_val + b_val
    # src[test_inline_triton.py:N]: def kernel(
    diff_val = a_val - b_val
    # src[test_inline_triton.py:N]: sum_val, diff_val = hl.inline_triton(
    # src[test_inline_triton.py:N]:     """
    # src[test_inline_triton.py:N]:     sum_val = {0} + {1}
    # src[test_inline_triton.py:N-N]: ...
    inline_triton_result = (sum_val, diff_val)
    tl.static_assert(len(inline_triton_result) == 2, 'inline_triton expected 2 outputs')
    tl.static_assert(inline_triton_result[0].dtype == tl.float32, 'inline_triton output 0 dtype mismatch; expected torch.float32')
    tl.static_assert(inline_triton_result[0].shape == a_val.shape, 'inline_triton output 0 shape mismatch')
    tl.static_assert(inline_triton_result[1].dtype == tl.float32, 'inline_triton output 1 dtype mismatch; expected torch.float32')
    tl.static_assert(inline_triton_result[1].shape == a_val.shape, 'inline_triton output 1 shape mismatch')
    sum_val = inline_triton_result[0]
    diff_val = inline_triton_result[1]
    # src[test_inline_triton.py:N]: sum_out[tile] = sum_val
    tl.store(sum_out + indices_0 * 1, sum_val, None)
    # src[test_inline_triton.py:N]: diff_out[tile] = diff_val
    tl.store(diff_out + indices_0 * 1, diff_val, None)

def kernel(a: torch.Tensor, b: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_inline_triton.py:N]: sum_out = torch.empty_like(a)
    sum_out = torch.empty_like(a)
    # src[test_inline_triton.py:N]: diff_out = torch.empty_like(a)
    diff_out = torch.empty_like(a)
    # src[test_inline_triton.py:N]: for tile in hl.tile(a.shape):
    _BLOCK_SIZE_0 = 32
    # src[test_inline_triton.py:N]: for tile in hl.tile(a.shape):
    # src[test_inline_triton.py:N]:     a_val = a[tile]
    # src[test_inline_triton.py:N]:     b_val = b[tile]
    # src[test_inline_triton.py:N-N]: ...
    _launcher(_helion_kernel, (triton.cdiv(64, _BLOCK_SIZE_0),), a, b, sum_out, diff_out, num_warps=4, num_stages=1)
    # src[test_inline_triton.py:N]: return sum_out, diff_out
    return (sum_out, diff_out)

--- assertExpectedJournal(TestInlineTriton.test_inline_triton_simple)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

_BLOCK_SIZE_0 = tl.constexpr(32)

@triton.jit
def _helion_kernel(x, y, out):
    # src[test_inline_triton.py:N]: for tile in hl.tile(x.shape):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_inline_triton.py:N]: x_val = x[tile]
    x_val = tl.load(x + indices_0 * 1, None)
    # src[test_inline_triton.py:N]: y_val = y[tile]
    y_val = tl.load(y + indices_0 * 1, None)
    # src[test_inline_triton.py:N]: @helion.kernel(autotune_effort="none")
    tmp = x_val + y_val
    # src[test_inline_triton.py:N]: result = hl.inline_triton(
    # src[test_inline_triton.py:N]:     """
    # src[test_inline_triton.py:N]:     tmp = {lhs} + {rhs}
    # src[test_inline_triton.py:N-N]: ...
    inline_triton_result = tmp
    tl.static_assert(inline_triton_result.dtype == tl.float32, 'inline_triton output dtype mismatch; expected torch.float32')
    tl.static_assert(inline_triton_result.shape == x_val.shape, 'inline_triton output shape mismatch')
    # src[test_inline_triton.py:N]: out[tile] = result
    tl.store(out + indices_0 * 1, inline_triton_result, None)

def kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_inline_triton.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_inline_triton.py:N]: for tile in hl.tile(x.shape):
    _BLOCK_SIZE_0 = 32
    # src[test_inline_triton.py:N]: for tile in hl.tile(x.shape):
    # src[test_inline_triton.py:N]:     x_val = x[tile]
    # src[test_inline_triton.py:N]:     y_val = y[tile]
    # src[test_inline_triton.py:N-N]: ...
    _launcher(_helion_kernel, (triton.cdiv(128, _BLOCK_SIZE_0),), x, y, out, num_warps=4, num_stages=1)
    # src[test_inline_triton.py:N]: return out
    return out
