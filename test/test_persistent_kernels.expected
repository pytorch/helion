This file is automatically generated by assertExpectedJournal calls in test_persistent_kernels.py.
Update expected outputs by running tests with the EXPECTTEST_ACCEPT=1 environment variable set.

--- assertExpectedJournal(TestPersistentKernels.test_multi_loop_persistent_with_shared_program_id)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_kernel(x, result1, y, result2, x_size_0, x_size_1, y_size_0, y_size_1, result1_stride_0, result1_stride_1, result2_stride_0, result2_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1) + tl.cdiv(y_size_0, _BLOCK_SIZE_2) * tl.cdiv(y_size_1, _BLOCK_SIZE_3)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        pid_shared = virtual_pid
        if pid_shared < tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1):
            num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
            pid_0 = pid_shared % num_blocks_0
            pid_1 = pid_shared // num_blocks_0
            offset_0 = pid_0 * _BLOCK_SIZE_0
            indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
            mask_0 = indices_0 < x_size_0
            offset_1 = pid_1 * _BLOCK_SIZE_1
            indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
            mask_1 = indices_1 < x_size_1
            load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
            v_0 = 2.0
            v_1 = load * v_0
            tl.store(result1 + (indices_0[:, None] * result1_stride_0 + indices_1[None, :] * result1_stride_1), v_1, mask_0[:, None] & mask_1[None, :])
        else:
            pid_shared -= tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
            num_blocks_1 = tl.cdiv(y_size_0, _BLOCK_SIZE_2)
            pid_2 = pid_shared % num_blocks_1
            pid_3 = pid_shared // num_blocks_1
            offset_2 = pid_2 * _BLOCK_SIZE_2
            indices_2 = (offset_2 + tl.arange(0, _BLOCK_SIZE_2)).to(tl.int32)
            mask_2 = indices_2 < y_size_0
            offset_3 = pid_3 * _BLOCK_SIZE_3
            indices_3 = (offset_3 + tl.arange(0, _BLOCK_SIZE_3)).to(tl.int32)
            mask_3 = indices_3 < y_size_1
            load_1 = tl.load(y + (indices_2[:, None] * y_stride_0 + indices_3[None, :] * y_stride_1), mask_2[:, None] & mask_3[None, :], other=0)
            v_2 = 3.0
            v_3 = load_1 * v_2
            tl.store(result2 + (indices_2[:, None] * result2_stride_0 + indices_3[None, :] * result2_stride_1), v_3, mask_2[:, None] & mask_3[None, :])

def multi_loop_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result1 = x.new_empty(x.size())
    result2 = y.new_empty(y.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 8
    _BLOCK_SIZE_2 = 16
    _BLOCK_SIZE_3 = 8
    _launcher(_helion_multi_loop_kernel, (_NUM_SM,), x, result1, y, result2, x.size(0), x.size(1), y.size(0), y.size(1), result1.stride(0), result1.stride(1), result2.stride(0), result2.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3, num_warps=4, num_stages=3)
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_multi_loop_persistent_with_shared_program_id)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_kernel(x, result1, y, result2, x_size_0, x_size_1, y_size_0, y_size_1, result1_stride_0, result1_stride_1, result2_stride_0, result2_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1) + tl.cdiv(y_size_0, _BLOCK_SIZE_2) * tl.cdiv(y_size_1, _BLOCK_SIZE_3)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        pid_shared = virtual_pid
        if pid_shared < tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1):
            num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
            pid_0 = pid_shared % num_blocks_0
            pid_1 = pid_shared // num_blocks_0
            offset_0 = pid_0 * _BLOCK_SIZE_0
            indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
            mask_0 = indices_0 < x_size_0
            offset_1 = pid_1 * _BLOCK_SIZE_1
            indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
            mask_1 = indices_1 < x_size_1
            load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
            v_0 = 2.0
            v_1 = load * v_0
            tl.store(result1 + (indices_0[:, None] * result1_stride_0 + indices_1[None, :] * result1_stride_1), v_1, mask_0[:, None] & mask_1[None, :])
        else:
            pid_shared -= tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
            num_blocks_1 = tl.cdiv(y_size_0, _BLOCK_SIZE_2)
            pid_2 = pid_shared % num_blocks_1
            pid_3 = pid_shared // num_blocks_1
            offset_2 = pid_2 * _BLOCK_SIZE_2
            indices_2 = (offset_2 + tl.arange(0, _BLOCK_SIZE_2)).to(tl.int32)
            mask_2 = indices_2 < y_size_0
            offset_3 = pid_3 * _BLOCK_SIZE_3
            indices_3 = (offset_3 + tl.arange(0, _BLOCK_SIZE_3)).to(tl.int32)
            mask_3 = indices_3 < y_size_1
            load_1 = tl.load(y + (indices_2[:, None] * y_stride_0 + indices_3[None, :] * y_stride_1), mask_2[:, None] & mask_3[None, :], other=0)
            v_2 = 3.0
            v_3 = load_1 * v_2
            tl.store(result2 + (indices_2[:, None] * result2_stride_0 + indices_3[None, :] * result2_stride_1), v_3, mask_2[:, None] & mask_3[None, :])

def multi_loop_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result1 = x.new_empty(x.size())
    result2 = y.new_empty(y.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 8
    _BLOCK_SIZE_2 = 16
    _BLOCK_SIZE_3 = 8
    _launcher(_helion_multi_loop_kernel, (_NUM_SM,), x, result1, y, result2, x.size(0), x.size(1), y.size(0), y.size(1), result1.stride(0), result1.stride(1), result2.stride(0), result2.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3, num_warps=4, num_stages=3)
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_1d_tiling)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_vector_add_1d(x, y, result, x_size_0, result_stride_0, x_stride_0, y_stride_0, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        pid_0 = virtual_pid
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        load = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
        load_1 = tl.load(y + indices_0 * y_stride_0, mask_0, other=0)
        v_0 = load + load_1
        tl.store(result + indices_0 * result_stride_0, v_0, mask_0)

def vector_add_1d(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 128
    _launcher(_helion_vector_add_1d, (_NUM_SM,), x, y, result, x.size(0), result.stride(0), x.stride(0), y.stride(0), _NUM_SM, _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_1d_tiling)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_vector_add_1d(x, y, result, x_size_0, result_stride_0, x_stride_0, y_stride_0, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        pid_0 = virtual_pid
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        load = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
        load_1 = tl.load(y + indices_0 * y_stride_0, mask_0, other=0)
        v_0 = load + load_1
        tl.store(result + indices_0 * result_stride_0, v_0, mask_0)

def vector_add_1d(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 128
    _launcher(_helion_vector_add_1d, (_NUM_SM,), x, y, result, x.size(0), result.stride(0), x.stride(0), y.stride(0), _NUM_SM, _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_1d_tiling)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_vector_add_1d(x, y, result, x_size_0, result_stride_0, x_stride_0, y_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < x_size_0
    load = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
    load_1 = tl.load(y + indices_0 * y_stride_0, mask_0, other=0)
    v_0 = load + load_1
    tl.store(result + indices_0 * result_stride_0, v_0, mask_0)

def vector_add_1d(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _BLOCK_SIZE_0 = 128
    _launcher(_helion_vector_add_1d, (triton.cdiv(x.size(0), _BLOCK_SIZE_0),), x, y, result, x.size(0), result.stride(0), x.stride(0), y.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_blocked_3d)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_3d_kernel(x, y, result, x_size_0, x_size_1, x_size_2, result_stride_0, result_stride_1, result_stride_2, x_stride_0, x_stride_1, x_stride_2, y_stride_0, y_stride_1, y_stride_2, _NUM_SM: tl.constexpr):
    total_pids = x_size_0 * x_size_1 * x_size_2
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        num_blocks_0 = x_size_0
        num_blocks_1 = x_size_1
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0 % num_blocks_1
        pid_2 = virtual_pid // (num_blocks_0 * num_blocks_1)
        offset_0 = pid_0
        offset_1 = pid_1
        offset_2 = pid_2
        load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1 + offset_2 * x_stride_2), None)
        load_1 = tl.load(y + (offset_0 * y_stride_0 + offset_1 * y_stride_1 + offset_2 * y_stride_2), None)
        v_0 = load + load_1
        tl.store(result + (offset_0 * result_stride_0 + offset_1 * result_stride_1 + offset_2 * result_stride_2), v_0, None)

def add_3d_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _launcher(_helion_add_3d_kernel, (_NUM_SM,), x, y, result, x.size(0), x.size(1), x.size(2), result.stride(0), result.stride(1), result.stride(2), x.stride(0), x.stride(1), x.stride(2), y.stride(0), y.stride(1), y.stride(2), _NUM_SM, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_blocked_3d)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_3d_kernel(x, y, result, x_size_0, x_size_1, result_stride_0, result_stride_1, result_stride_2, x_stride_0, x_stride_1, x_stride_2, y_stride_0, y_stride_1, y_stride_2):
    num_blocks_0 = x_size_0
    num_blocks_1 = x_size_1
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0 % num_blocks_1
    pid_2 = tl.program_id(0) // (num_blocks_0 * num_blocks_1)
    offset_0 = pid_0
    offset_1 = pid_1
    offset_2 = pid_2
    load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1 + offset_2 * x_stride_2), None)
    load_1 = tl.load(y + (offset_0 * y_stride_0 + offset_1 * y_stride_1 + offset_2 * y_stride_2), None)
    v_0 = load + load_1
    tl.store(result + (offset_0 * result_stride_0 + offset_1 * result_stride_1 + offset_2 * result_stride_2), v_0, None)

def add_3d_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _launcher(_helion_add_3d_kernel, (x.size(0) * x.size(1) * x.size(2),), x, y, result, x.size(0), x.size(1), result.stride(0), result.stride(1), result.stride(2), x.stride(0), x.stride(1), x.stride(2), y.stride(0), y.stride(1), y.stride(2), num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_blocked_matmul)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_matmul_kernel(A, B, result, A_stride_0, A_stride_1, B_stride_0, B_stride_1, result_stride_0, result_stride_1, M, N, K, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    total_pids = tl.cdiv(M, _BLOCK_SIZE_0) * tl.cdiv(N, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        num_blocks_0 = tl.cdiv(M, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < M
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < N
        acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
        for offset_2 in tl.range(0, K.to(tl.int32), _BLOCK_SIZE_2):
            indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
            mask_2 = indices_2 < K
            acc_copy = acc
            acc_copy_0 = acc_copy
            load = tl.load(A + (indices_0[:, None] * A_stride_0 + indices_2[None, :] * A_stride_1), mask_0[:, None] & mask_2[None, :], other=0)
            load_1 = tl.load(B + (indices_2[:, None] * B_stride_0 + indices_1[None, :] * B_stride_1), mask_2[:, None] & mask_1[None, :], other=0)
            mm = tl.dot(load, load_1, input_precision='tf32')
            acc = acc_copy_0 + mm
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), acc, mask_0[:, None] & mask_1[None, :])

def matmul_kernel(A: torch.Tensor, B: torch.Tensor, *, _launcher=_default_launcher):
    M, K = A.size()
    K2, N = B.size()
    assert K == K2
    result = A.new_empty([M, N])
    _NUM_SM = helion.runtime.get_num_sm(A.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    _BLOCK_SIZE_2 = 32
    _launcher(_helion_matmul_kernel, (_NUM_SM,), A, B, result, A.stride(0), A.stride(1), B.stride(0), B.stride(1), result.stride(0), result.stride(1), M, N, K, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_blocked_matmul)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_matmul_kernel(A, B, result, A_stride_0, A_stride_1, B_stride_0, B_stride_1, result_stride_0, result_stride_1, M, N, K, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    num_blocks_0 = tl.cdiv(M, _BLOCK_SIZE_0)
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < M
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    mask_1 = indices_1 < N
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    for offset_2 in tl.range(0, K.to(tl.int32), _BLOCK_SIZE_2):
        indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
        mask_2 = indices_2 < K
        acc_copy = acc
        acc_copy_0 = acc_copy
        load = tl.load(A + (indices_0[:, None] * A_stride_0 + indices_2[None, :] * A_stride_1), mask_0[:, None] & mask_2[None, :], other=0)
        load_1 = tl.load(B + (indices_2[:, None] * B_stride_0 + indices_1[None, :] * B_stride_1), mask_2[:, None] & mask_1[None, :], other=0)
        mm = tl.dot(load, load_1, input_precision='tf32')
        acc = acc_copy_0 + mm
    tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), acc, mask_0[:, None] & mask_1[None, :])

def matmul_kernel(A: torch.Tensor, B: torch.Tensor, *, _launcher=_default_launcher):
    M, K = A.size()
    K2, N = B.size()
    assert K == K2
    result = A.new_empty([M, N])
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    _BLOCK_SIZE_2 = 32
    _launcher(_helion_matmul_kernel, (triton.cdiv(M, _BLOCK_SIZE_0) * triton.cdiv(N, _BLOCK_SIZE_1),), A, B, result, A.stride(0), A.stride(1), B.stride(0), B.stride(1), result.stride(0), result.stride(1), M, N, K, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_blocked_simple_add)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_kernel(x, y, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _NUM_SM: tl.constexpr):
    total_pids = x_size_0 * x_size_1
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        num_blocks_0 = x_size_0
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0
        offset_1 = pid_1
        load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1), None)
        load_1 = tl.load(y + (offset_0 * y_stride_0 + offset_1 * y_stride_1), None)
        v_0 = load + load_1
        tl.store(result + (offset_0 * result_stride_0 + offset_1 * result_stride_1), v_0, None)

def add_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _launcher(_helion_add_kernel, (_NUM_SM,), x, y, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _NUM_SM, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_blocked_with_l2_grouping)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_kernel(x, y, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _NUM_SM: tl.constexpr):
    total_pids = x_size_0 * x_size_1
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        num_pid_m = x_size_0
        num_pid_n = x_size_1
        inner_2d_pid = virtual_pid
        num_pid_in_group = 8 * num_pid_n
        group_id = inner_2d_pid // num_pid_in_group
        first_pid_m = group_id * 8
        group_size_m = min(num_pid_m - first_pid_m, 8)
        pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
        pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
        offset_0 = pid_0
        offset_1 = pid_1
        load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1), None)
        load_1 = tl.load(y + (offset_0 * y_stride_0 + offset_1 * y_stride_1), None)
        v_0 = load + load_1
        tl.store(result + (offset_0 * result_stride_0 + offset_1 * result_stride_1), v_0, None)

def add_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _launcher(_helion_add_kernel, (_NUM_SM,), x, y, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _NUM_SM, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_blocked_with_l2_grouping)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_kernel(x, y, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1):
    num_pid_m = x_size_0
    num_pid_n = x_size_1
    inner_2d_pid = tl.program_id(0)
    num_pid_in_group = 8 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 8
    group_size_m = min(num_pid_m - first_pid_m, 8)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    offset_0 = pid_0
    offset_1 = pid_1
    load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1), None)
    load_1 = tl.load(y + (offset_0 * y_stride_0 + offset_1 * y_stride_1), None)
    v_0 = load + load_1
    tl.store(result + (offset_0 * result_stride_0 + offset_1 * result_stride_1), v_0, None)

def add_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _launcher(_helion_add_kernel, (x.size(0) * x.size(1),), x, y, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_blocked_with_l2_grouping)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_kernel(x, y, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _NUM_SM: tl.constexpr):
    total_pids = x_size_0 * x_size_1
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        num_blocks_0 = x_size_0
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0
        offset_1 = pid_1
        load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1), None)
        load_1 = tl.load(y + (offset_0 * y_stride_0 + offset_1 * y_stride_1), None)
        v_0 = load + load_1
        tl.store(result + (offset_0 * result_stride_0 + offset_1 * result_stride_1), v_0, None)

def add_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _launcher(_helion_add_kernel, (_NUM_SM,), x, y, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _NUM_SM, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_grid_size_correctness)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < x_size_0
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    mask_1 = indices_1 < x_size_1
    load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
    v_0 = 1.0
    v_1 = load + v_0
    tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    _launcher(_helion_test_kernel, (triton.cdiv(x.size(0), _BLOCK_SIZE_0) * triton.cdiv(x.size(1), _BLOCK_SIZE_1),), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_grid_size_correctness)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_grid_size_correctness)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_3d)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_3d_kernel(x, y, result, x_size_0, x_size_1, x_size_2, result_stride_0, result_stride_1, result_stride_2, x_stride_0, x_stride_1, x_stride_2, y_stride_0, y_stride_1, y_stride_2, _NUM_SM: tl.constexpr):
    total_pids = x_size_0 * x_size_1 * x_size_2
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        num_blocks_0 = x_size_0
        num_blocks_1 = x_size_1
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0 % num_blocks_1
        pid_2 = virtual_pid // (num_blocks_0 * num_blocks_1)
        offset_0 = pid_0
        offset_1 = pid_1
        offset_2 = pid_2
        load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1 + offset_2 * x_stride_2), None)
        load_1 = tl.load(y + (offset_0 * y_stride_0 + offset_1 * y_stride_1 + offset_2 * y_stride_2), None)
        v_0 = load + load_1
        tl.store(result + (offset_0 * result_stride_0 + offset_1 * result_stride_1 + offset_2 * result_stride_2), v_0, None)

def add_3d_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _launcher(_helion_add_3d_kernel, (_NUM_SM,), x, y, result, x.size(0), x.size(1), x.size(2), result.stride(0), result.stride(1), result.stride(2), x.stride(0), x.stride(1), x.stride(2), y.stride(0), y.stride(1), y.stride(2), _NUM_SM, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_3d)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_3d_kernel(x, y, result, x_size_0, x_size_1, result_stride_0, result_stride_1, result_stride_2, x_stride_0, x_stride_1, x_stride_2, y_stride_0, y_stride_1, y_stride_2):
    num_blocks_0 = x_size_0
    num_blocks_1 = x_size_1
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0 % num_blocks_1
    pid_2 = tl.program_id(0) // (num_blocks_0 * num_blocks_1)
    offset_0 = pid_0
    offset_1 = pid_1
    offset_2 = pid_2
    load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1 + offset_2 * x_stride_2), None)
    load_1 = tl.load(y + (offset_0 * y_stride_0 + offset_1 * y_stride_1 + offset_2 * y_stride_2), None)
    v_0 = load + load_1
    tl.store(result + (offset_0 * result_stride_0 + offset_1 * result_stride_1 + offset_2 * result_stride_2), v_0, None)

def add_3d_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _launcher(_helion_add_3d_kernel, (x.size(0) * x.size(1) * x.size(2),), x, y, result, x.size(0), x.size(1), result.stride(0), result.stride(1), result.stride(2), x.stride(0), x.stride(1), x.stride(2), y.stride(0), y.stride(1), y.stride(2), num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_matmul)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_matmul_kernel(A, B, result, A_stride_0, A_stride_1, B_stride_0, B_stride_1, result_stride_0, result_stride_1, M, N, K, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    total_pids = tl.cdiv(M, _BLOCK_SIZE_0) * tl.cdiv(N, _BLOCK_SIZE_1)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        num_blocks_0 = tl.cdiv(M, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < M
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < N
        acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
        for offset_2 in tl.range(0, K.to(tl.int32), _BLOCK_SIZE_2):
            indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
            mask_2 = indices_2 < K
            acc_copy = acc
            acc_copy_0 = acc_copy
            load = tl.load(A + (indices_0[:, None] * A_stride_0 + indices_2[None, :] * A_stride_1), mask_0[:, None] & mask_2[None, :], other=0)
            load_1 = tl.load(B + (indices_2[:, None] * B_stride_0 + indices_1[None, :] * B_stride_1), mask_2[:, None] & mask_1[None, :], other=0)
            mm = tl.dot(load, load_1, input_precision='tf32')
            acc = acc_copy_0 + mm
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), acc, mask_0[:, None] & mask_1[None, :])

def matmul_kernel(A: torch.Tensor, B: torch.Tensor, *, _launcher=_default_launcher):
    M, K = A.size()
    K2, N = B.size()
    assert K == K2
    result = A.new_empty([M, N])
    _NUM_SM = helion.runtime.get_num_sm(A.device)
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 16
    _BLOCK_SIZE_2 = 32
    _launcher(_helion_matmul_kernel, (_NUM_SM,), A, B, result, A.stride(0), A.stride(1), B.stride(0), B.stride(1), result.stride(0), result.stride(1), M, N, K, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_matmul)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_matmul_kernel(A, B, result, A_stride_0, A_stride_1, B_stride_0, B_stride_1, result_stride_0, result_stride_1, M, N, K, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    num_blocks_0 = tl.cdiv(M, _BLOCK_SIZE_0)
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < M
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    mask_1 = indices_1 < N
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    for offset_2 in tl.range(0, K.to(tl.int32), _BLOCK_SIZE_2):
        indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
        mask_2 = indices_2 < K
        acc_copy = acc
        acc_copy_0 = acc_copy
        load = tl.load(A + (indices_0[:, None] * A_stride_0 + indices_2[None, :] * A_stride_1), mask_0[:, None] & mask_2[None, :], other=0)
        load_1 = tl.load(B + (indices_2[:, None] * B_stride_0 + indices_1[None, :] * B_stride_1), mask_2[:, None] & mask_1[None, :], other=0)
        mm = tl.dot(load, load_1, input_precision='tf32')
        acc = acc_copy_0 + mm
    tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), acc, mask_0[:, None] & mask_1[None, :])

def matmul_kernel(A: torch.Tensor, B: torch.Tensor, *, _launcher=_default_launcher):
    M, K = A.size()
    K2, N = B.size()
    assert K == K2
    result = A.new_empty([M, N])
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 16
    _BLOCK_SIZE_2 = 32
    _launcher(_helion_matmul_kernel, (triton.cdiv(M, _BLOCK_SIZE_0) * triton.cdiv(N, _BLOCK_SIZE_1),), A, B, result, A.stride(0), A.stride(1), B.stride(0), B.stride(1), result.stride(0), result.stride(1), M, N, K, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_multiple_loops_with_l2_grouping)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_l2_kernel(x, result1, y, result2, result3, x_size_0, x_size_1, y_size_0, y_size_1, result1_stride_0, result1_stride_1, result2_stride_0, result2_stride_1, result3_stride_0, result3_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr, _BLOCK_SIZE_4: tl.constexpr, _BLOCK_SIZE_5: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1) + tl.cdiv(y_size_0, _BLOCK_SIZE_2) * tl.cdiv(y_size_1, _BLOCK_SIZE_3) + tl.cdiv(y_size_0, _BLOCK_SIZE_4) * tl.cdiv(y_size_1, _BLOCK_SIZE_5)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        pid_shared = virtual_pid
        if pid_shared < tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1):
            num_pid_m = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
            num_pid_n = tl.cdiv(x_size_1, _BLOCK_SIZE_1)
            inner_2d_pid = pid_shared
            num_pid_in_group = 2 * num_pid_n
            group_id = inner_2d_pid // num_pid_in_group
            first_pid_m = group_id * 2
            group_size_m = min(num_pid_m - first_pid_m, 2)
            pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
            pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
            offset_0 = pid_0 * _BLOCK_SIZE_0
            indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
            mask_0 = indices_0 < x_size_0
            offset_1 = pid_1 * _BLOCK_SIZE_1
            indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
            mask_1 = indices_1 < x_size_1
            load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
            v_0 = 2.0
            v_1 = load * v_0
            tl.store(result1 + (indices_0[:, None] * result1_stride_0 + indices_1[None, :] * result1_stride_1), v_1, mask_0[:, None] & mask_1[None, :])
        elif pid_shared < tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1) + tl.cdiv(y_size_0, _BLOCK_SIZE_2) * tl.cdiv(y_size_1, _BLOCK_SIZE_3):
            pid_shared -= tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
            num_pid_m_1 = tl.cdiv(y_size_0, _BLOCK_SIZE_2)
            num_pid_n_1 = tl.cdiv(y_size_1, _BLOCK_SIZE_3)
            inner_2d_pid_1 = pid_shared
            num_pid_in_group_1 = 4 * num_pid_n_1
            group_id_1 = inner_2d_pid_1 // num_pid_in_group_1
            first_pid_m_1 = group_id_1 * 4
            group_size_m_1 = min(num_pid_m_1 - first_pid_m_1, 4)
            pid_2 = first_pid_m_1 + inner_2d_pid_1 % num_pid_in_group_1 % group_size_m_1
            pid_3 = inner_2d_pid_1 % num_pid_in_group_1 // group_size_m_1
            offset_2 = pid_2 * _BLOCK_SIZE_2
            indices_2 = (offset_2 + tl.arange(0, _BLOCK_SIZE_2)).to(tl.int32)
            mask_2 = indices_2 < y_size_0
            offset_3 = pid_3 * _BLOCK_SIZE_3
            indices_3 = (offset_3 + tl.arange(0, _BLOCK_SIZE_3)).to(tl.int32)
            mask_3 = indices_3 < y_size_1
            load_1 = tl.load(y + (indices_2[:, None] * y_stride_0 + indices_3[None, :] * y_stride_1), mask_2[:, None] & mask_3[None, :], other=0)
            v_2 = 1.0
            v_3 = load_1 + v_2
            tl.store(result2 + (indices_2[:, None] * result2_stride_0 + indices_3[None, :] * result2_stride_1), v_3, mask_2[:, None] & mask_3[None, :])
        else:
            pid_shared -= tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1) + tl.cdiv(y_size_0, _BLOCK_SIZE_2) * tl.cdiv(y_size_1, _BLOCK_SIZE_3)
            num_pid_m_2 = tl.cdiv(y_size_0, _BLOCK_SIZE_4)
            num_pid_n_2 = tl.cdiv(y_size_1, _BLOCK_SIZE_5)
            inner_2d_pid_2 = pid_shared
            num_pid_in_group_2 = 2 * num_pid_n_2
            group_id_2 = inner_2d_pid_2 // num_pid_in_group_2
            first_pid_m_2 = group_id_2 * 2
            group_size_m_2 = min(num_pid_m_2 - first_pid_m_2, 2)
            pid_4 = first_pid_m_2 + inner_2d_pid_2 % num_pid_in_group_2 % group_size_m_2
            pid_5 = inner_2d_pid_2 % num_pid_in_group_2 // group_size_m_2
            offset_4 = pid_4 * _BLOCK_SIZE_4
            indices_4 = (offset_4 + tl.arange(0, _BLOCK_SIZE_4)).to(tl.int32)
            mask_4 = indices_4 < y_size_0
            offset_5 = pid_5 * _BLOCK_SIZE_5
            indices_5 = (offset_5 + tl.arange(0, _BLOCK_SIZE_5)).to(tl.int32)
            mask_5 = indices_5 < y_size_1
            load_2 = tl.load(y + (indices_4[:, None] * y_stride_0 + indices_5[None, :] * y_stride_1), mask_4[:, None] & mask_5[None, :], other=0)
            v_4 = 2.0
            v_5 = load_2 + v_4
            tl.store(result3 + (indices_4[:, None] * result3_stride_0 + indices_5[None, :] * result3_stride_1), v_5, mask_4[:, None] & mask_5[None, :])

def multi_loop_l2_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result1 = x.new_empty(x.size())
    result2 = y.new_empty(y.size())
    result3 = y.new_empty(y.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 16
    _BLOCK_SIZE_2 = 16
    _BLOCK_SIZE_3 = 16
    _BLOCK_SIZE_4 = 16
    _BLOCK_SIZE_5 = 16
    _launcher(_helion_multi_loop_l2_kernel, (_NUM_SM,), x, result1, y, result2, result3, x.size(0), x.size(1), y.size(0), y.size(1), result1.stride(0), result1.stride(1), result2.stride(0), result2.stride(1), result3.stride(0), result3.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3, _BLOCK_SIZE_4, _BLOCK_SIZE_5, num_warps=4, num_stages=3)
    return (result1, result2, result3)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_multiple_loops_with_l2_grouping)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_l2_kernel(x, result1, y, result2, result3, x_size_0, x_size_1, y_size_0, y_size_1, result1_stride_0, result1_stride_1, result2_stride_0, result2_stride_1, result3_stride_0, result3_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr, _BLOCK_SIZE_4: tl.constexpr, _BLOCK_SIZE_5: tl.constexpr):
    pid_shared = tl.program_id(0)
    if pid_shared < tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1):
        num_pid_m = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        num_pid_n = tl.cdiv(x_size_1, _BLOCK_SIZE_1)
        inner_2d_pid = pid_shared
        num_pid_in_group = 4 * num_pid_n
        group_id = inner_2d_pid // num_pid_in_group
        first_pid_m = group_id * 4
        group_size_m = min(num_pid_m - first_pid_m, 4)
        pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
        pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 2.0
        v_1 = load * v_0
        tl.store(result1 + (indices_0[:, None] * result1_stride_0 + indices_1[None, :] * result1_stride_1), v_1, mask_0[:, None] & mask_1[None, :])
    elif pid_shared < tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1) + tl.cdiv(y_size_0, _BLOCK_SIZE_2) * tl.cdiv(y_size_1, _BLOCK_SIZE_3):
        pid_shared -= tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
        num_blocks_1 = tl.cdiv(y_size_0, _BLOCK_SIZE_2)
        pid_2 = pid_shared % num_blocks_1
        pid_3 = pid_shared // num_blocks_1
        offset_2 = pid_2 * _BLOCK_SIZE_2
        indices_2 = (offset_2 + tl.arange(0, _BLOCK_SIZE_2)).to(tl.int32)
        mask_2 = indices_2 < y_size_0
        offset_3 = pid_3 * _BLOCK_SIZE_3
        indices_3 = (offset_3 + tl.arange(0, _BLOCK_SIZE_3)).to(tl.int32)
        mask_3 = indices_3 < y_size_1
        load_1 = tl.load(y + (indices_2[:, None] * y_stride_0 + indices_3[None, :] * y_stride_1), mask_2[:, None] & mask_3[None, :], other=0)
        v_2 = 1.0
        v_3 = load_1 + v_2
        tl.store(result2 + (indices_2[:, None] * result2_stride_0 + indices_3[None, :] * result2_stride_1), v_3, mask_2[:, None] & mask_3[None, :])
    else:
        pid_shared -= tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1) + tl.cdiv(y_size_0, _BLOCK_SIZE_2) * tl.cdiv(y_size_1, _BLOCK_SIZE_3)
        num_blocks_2 = tl.cdiv(y_size_0, _BLOCK_SIZE_4)
        pid_4 = pid_shared % num_blocks_2
        pid_5 = pid_shared // num_blocks_2
        offset_4 = pid_4 * _BLOCK_SIZE_4
        indices_4 = (offset_4 + tl.arange(0, _BLOCK_SIZE_4)).to(tl.int32)
        mask_4 = indices_4 < y_size_0
        offset_5 = pid_5 * _BLOCK_SIZE_5
        indices_5 = (offset_5 + tl.arange(0, _BLOCK_SIZE_5)).to(tl.int32)
        mask_5 = indices_5 < y_size_1
        load_2 = tl.load(y + (indices_4[:, None] * y_stride_0 + indices_5[None, :] * y_stride_1), mask_4[:, None] & mask_5[None, :], other=0)
        v_4 = 2.0
        v_5 = load_2 + v_4
        tl.store(result3 + (indices_4[:, None] * result3_stride_0 + indices_5[None, :] * result3_stride_1), v_5, mask_4[:, None] & mask_5[None, :])

def multi_loop_l2_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result1 = x.new_empty(x.size())
    result2 = y.new_empty(y.size())
    result3 = y.new_empty(y.size())
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 16
    _BLOCK_SIZE_2 = 16
    _BLOCK_SIZE_3 = 16
    _BLOCK_SIZE_4 = 16
    _BLOCK_SIZE_5 = 16
    _launcher(_helion_multi_loop_l2_kernel, (triton.cdiv(x.size(0), _BLOCK_SIZE_0) * triton.cdiv(x.size(1), _BLOCK_SIZE_1) + triton.cdiv(y.size(0), _BLOCK_SIZE_2) * triton.cdiv(y.size(1), _BLOCK_SIZE_3) + triton.cdiv(y.size(0), _BLOCK_SIZE_4) * triton.cdiv(y.size(1), _BLOCK_SIZE_5),), x, result1, y, result2, result3, x.size(0), x.size(1), y.size(0), y.size(1), result1.stride(0), result1.stride(1), result2.stride(0), result2.stride(1), result3.stride(0), result3.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3, _BLOCK_SIZE_4, _BLOCK_SIZE_5, num_warps=4, num_stages=3)
    return (result1, result2, result3)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_multiple_loops_without_l2_grouping)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_kernel(x, result1, y, result2, x_size_0, x_size_1, y_size_0, y_size_1, result1_stride_0, result1_stride_1, result2_stride_0, result2_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1) + tl.cdiv(y_size_0, _BLOCK_SIZE_2) * tl.cdiv(y_size_1, _BLOCK_SIZE_3)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        pid_shared = virtual_pid
        if pid_shared < tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1):
            num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
            pid_0 = pid_shared % num_blocks_0
            pid_1 = pid_shared // num_blocks_0
            offset_0 = pid_0 * _BLOCK_SIZE_0
            indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
            mask_0 = indices_0 < x_size_0
            offset_1 = pid_1 * _BLOCK_SIZE_1
            indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
            mask_1 = indices_1 < x_size_1
            load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
            v_0 = 2.0
            v_1 = load * v_0
            tl.store(result1 + (indices_0[:, None] * result1_stride_0 + indices_1[None, :] * result1_stride_1), v_1, mask_0[:, None] & mask_1[None, :])
        else:
            pid_shared -= tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
            num_blocks_1 = tl.cdiv(y_size_0, _BLOCK_SIZE_2)
            pid_2 = pid_shared % num_blocks_1
            pid_3 = pid_shared // num_blocks_1
            offset_2 = pid_2 * _BLOCK_SIZE_2
            indices_2 = (offset_2 + tl.arange(0, _BLOCK_SIZE_2)).to(tl.int32)
            mask_2 = indices_2 < y_size_0
            offset_3 = pid_3 * _BLOCK_SIZE_3
            indices_3 = (offset_3 + tl.arange(0, _BLOCK_SIZE_3)).to(tl.int32)
            mask_3 = indices_3 < y_size_1
            load_1 = tl.load(y + (indices_2[:, None] * y_stride_0 + indices_3[None, :] * y_stride_1), mask_2[:, None] & mask_3[None, :], other=0)
            v_2 = 1.0
            v_3 = load_1 + v_2
            tl.store(result2 + (indices_2[:, None] * result2_stride_0 + indices_3[None, :] * result2_stride_1), v_3, mask_2[:, None] & mask_3[None, :])

def multi_loop_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result1 = x.new_empty(x.size())
    result2 = y.new_empty(y.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 16
    _BLOCK_SIZE_2 = 16
    _BLOCK_SIZE_3 = 16
    _launcher(_helion_multi_loop_kernel, (_NUM_SM,), x, result1, y, result2, x.size(0), x.size(1), y.size(0), y.size(1), result1.stride(0), result1.stride(1), result2.stride(0), result2.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3, num_warps=4, num_stages=3)
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_multiple_loops_without_l2_grouping)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_kernel(x, result1, y, result2, x_size_0, x_size_1, y_size_0, y_size_1, result1_stride_0, result1_stride_1, result2_stride_0, result2_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    pid_shared = tl.program_id(0)
    if pid_shared < tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = pid_shared % num_blocks_0
        pid_1 = pid_shared // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 2.0
        v_1 = load * v_0
        tl.store(result1 + (indices_0[:, None] * result1_stride_0 + indices_1[None, :] * result1_stride_1), v_1, mask_0[:, None] & mask_1[None, :])
    else:
        pid_shared -= tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
        num_blocks_1 = tl.cdiv(y_size_0, _BLOCK_SIZE_2)
        pid_2 = pid_shared % num_blocks_1
        pid_3 = pid_shared // num_blocks_1
        offset_2 = pid_2 * _BLOCK_SIZE_2
        indices_2 = (offset_2 + tl.arange(0, _BLOCK_SIZE_2)).to(tl.int32)
        mask_2 = indices_2 < y_size_0
        offset_3 = pid_3 * _BLOCK_SIZE_3
        indices_3 = (offset_3 + tl.arange(0, _BLOCK_SIZE_3)).to(tl.int32)
        mask_3 = indices_3 < y_size_1
        load_1 = tl.load(y + (indices_2[:, None] * y_stride_0 + indices_3[None, :] * y_stride_1), mask_2[:, None] & mask_3[None, :], other=0)
        v_2 = 1.0
        v_3 = load_1 + v_2
        tl.store(result2 + (indices_2[:, None] * result2_stride_0 + indices_3[None, :] * result2_stride_1), v_3, mask_2[:, None] & mask_3[None, :])

def multi_loop_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result1 = x.new_empty(x.size())
    result2 = y.new_empty(y.size())
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 16
    _BLOCK_SIZE_2 = 16
    _BLOCK_SIZE_3 = 16
    _launcher(_helion_multi_loop_kernel, (triton.cdiv(x.size(0), _BLOCK_SIZE_0) * triton.cdiv(x.size(1), _BLOCK_SIZE_1) + triton.cdiv(y.size(0), _BLOCK_SIZE_2) * triton.cdiv(y.size(1), _BLOCK_SIZE_3),), x, result1, y, result2, x.size(0), x.size(1), y.size(0), y.size(1), result1.stride(0), result1.stride(1), result2.stride(0), result2.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3, num_warps=4, num_stages=3)
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_simple_add)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_kernel(x, y, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _NUM_SM: tl.constexpr):
    total_pids = x_size_0 * x_size_1
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        num_blocks_0 = x_size_0
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0
        offset_1 = pid_1
        load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1), None)
        load_1 = tl.load(y + (offset_0 * y_stride_0 + offset_1 * y_stride_1), None)
        v_0 = load + load_1
        tl.store(result + (offset_0 * result_stride_0 + offset_1 * result_stride_1), v_0, None)

def add_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _launcher(_helion_add_kernel, (_NUM_SM,), x, y, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _NUM_SM, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_with_l2_grouping_single_loop)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_single_loop_l2_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        num_pid_m = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        num_pid_n = tl.cdiv(x_size_1, _BLOCK_SIZE_1)
        inner_2d_pid = virtual_pid
        num_pid_in_group = 4 * num_pid_n
        group_id = inner_2d_pid // num_pid_in_group
        first_pid_m = group_id * 4
        group_size_m = min(num_pid_m - first_pid_m, 4)
        pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
        pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 2.0
        v_1 = load * v_0
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def single_loop_l2_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 16
    _launcher(_helion_single_loop_l2_kernel, (_NUM_SM,), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_with_l2_grouping_single_loop)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_single_loop_l2_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    num_pid_m = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
    num_pid_n = tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    inner_2d_pid = tl.program_id(0)
    num_pid_in_group = 4 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 4
    group_size_m = min(num_pid_m - first_pid_m, 4)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < x_size_0
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    mask_1 = indices_1 < x_size_1
    load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
    v_0 = 2.0
    v_1 = load * v_0
    tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def single_loop_l2_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 16
    _launcher(_helion_single_loop_l2_kernel, (triton.cdiv(x.size(0), _BLOCK_SIZE_0) * triton.cdiv(x.size(1), _BLOCK_SIZE_1),), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_complex_shared_scenario)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_complex_shared_kernel(x, y, result1, z, result2, x_size_0, x_size_1, y_size_0, y_size_1, result1_stride_0, result1_stride_1, result2_stride_0, result2_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, z_stride_0, z_stride_1, _NUM_SM: tl.constexpr):
    total_pids = x_size_0 * x_size_1 + y_size_0 * y_size_1
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        pid_shared = virtual_pid
        if pid_shared < x_size_0 * x_size_1:
            num_blocks_0 = x_size_0
            pid_0 = pid_shared % num_blocks_0
            pid_1 = pid_shared // num_blocks_0
            offset_0 = pid_0
            offset_1 = pid_1
            load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1), None)
            load_1 = tl.load(y + (offset_0 * y_stride_0 + offset_1 * y_stride_1), None)
            v_0 = load + load_1
            tl.store(result1 + (offset_0 * result1_stride_0 + offset_1 * result1_stride_1), v_0, None)
        else:
            pid_shared -= x_size_0 * x_size_1
            num_blocks_1 = y_size_0
            pid_2 = pid_shared % num_blocks_1
            pid_3 = pid_shared // num_blocks_1
            offset_2 = pid_2
            offset_3 = pid_3
            load_2 = tl.load(y + (offset_2 * y_stride_0 + offset_3 * y_stride_1), None)
            load_3 = tl.load(z + (offset_2 * z_stride_0 + offset_3 * z_stride_1), None)
            v_1 = load_2 * load_3
            tl.store(result2 + (offset_2 * result2_stride_0 + offset_3 * result2_stride_1), v_1, None)

def complex_shared_kernel(x: torch.Tensor, y: torch.Tensor, z: torch.Tensor, *, _launcher=_default_launcher):
    result1 = x.new_empty(x.size())
    result2 = y.new_empty(y.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _launcher(_helion_complex_shared_kernel, (_NUM_SM,), x, y, result1, z, result2, x.size(0), x.size(1), y.size(0), y.size(1), result1.stride(0), result1.stride(1), result2.stride(0), result2.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), z.stride(0), z.stride(1), _NUM_SM, num_warps=4, num_stages=3)
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_complex_shared_scenario)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_complex_shared_kernel(x, y, result1, z, result2, x_size_0, x_size_1, y_size_0, y_size_1, result1_stride_0, result1_stride_1, result2_stride_0, result2_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, z_stride_0, z_stride_1, _NUM_SM: tl.constexpr):
    total_pids = x_size_0 * x_size_1 + y_size_0 * y_size_1
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        pid_shared = virtual_pid
        if pid_shared < x_size_0 * x_size_1:
            num_blocks_0 = x_size_0
            pid_0 = pid_shared % num_blocks_0
            pid_1 = pid_shared // num_blocks_0
            offset_0 = pid_0
            offset_1 = pid_1
            load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1), None)
            load_1 = tl.load(y + (offset_0 * y_stride_0 + offset_1 * y_stride_1), None)
            v_0 = load + load_1
            tl.store(result1 + (offset_0 * result1_stride_0 + offset_1 * result1_stride_1), v_0, None)
        else:
            pid_shared -= x_size_0 * x_size_1
            num_blocks_1 = y_size_0
            pid_2 = pid_shared % num_blocks_1
            pid_3 = pid_shared // num_blocks_1
            offset_2 = pid_2
            offset_3 = pid_3
            load_2 = tl.load(y + (offset_2 * y_stride_0 + offset_3 * y_stride_1), None)
            load_3 = tl.load(z + (offset_2 * z_stride_0 + offset_3 * z_stride_1), None)
            v_1 = load_2 * load_3
            tl.store(result2 + (offset_2 * result2_stride_0 + offset_3 * result2_stride_1), v_1, None)

def complex_shared_kernel(x: torch.Tensor, y: torch.Tensor, z: torch.Tensor, *, _launcher=_default_launcher):
    result1 = x.new_empty(x.size())
    result2 = y.new_empty(y.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _launcher(_helion_complex_shared_kernel, (_NUM_SM,), x, y, result1, z, result2, x.size(0), x.size(1), y.size(0), y.size(1), result1.stride(0), result1.stride(1), result2.stride(0), result2.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), z.stride(0), z.stride(1), _NUM_SM, num_warps=4, num_stages=3)
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_complex_shared_scenario)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_complex_shared_kernel(x, y, result1, z, result2, x_size_0, x_size_1, y_size_0, result1_stride_0, result1_stride_1, result2_stride_0, result2_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, z_stride_0, z_stride_1):
    pid_shared = tl.program_id(0)
    if pid_shared < x_size_0 * x_size_1:
        num_blocks_0 = x_size_0
        pid_0 = pid_shared % num_blocks_0
        pid_1 = pid_shared // num_blocks_0
        offset_0 = pid_0
        offset_1 = pid_1
        load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1), None)
        load_1 = tl.load(y + (offset_0 * y_stride_0 + offset_1 * y_stride_1), None)
        v_0 = load + load_1
        tl.store(result1 + (offset_0 * result1_stride_0 + offset_1 * result1_stride_1), v_0, None)
    else:
        pid_shared -= x_size_0 * x_size_1
        num_blocks_1 = y_size_0
        pid_2 = pid_shared % num_blocks_1
        pid_3 = pid_shared // num_blocks_1
        offset_2 = pid_2
        offset_3 = pid_3
        load_2 = tl.load(y + (offset_2 * y_stride_0 + offset_3 * y_stride_1), None)
        load_3 = tl.load(z + (offset_2 * z_stride_0 + offset_3 * z_stride_1), None)
        v_1 = load_2 * load_3
        tl.store(result2 + (offset_2 * result2_stride_0 + offset_3 * result2_stride_1), v_1, None)

def complex_shared_kernel(x: torch.Tensor, y: torch.Tensor, z: torch.Tensor, *, _launcher=_default_launcher):
    result1 = x.new_empty(x.size())
    result2 = y.new_empty(y.size())
    _launcher(_helion_complex_shared_kernel, (x.size(0) * x.size(1) + y.size(0) * y.size(1),), x, y, result1, z, result2, x.size(0), x.size(1), y.size(0), result1.stride(0), result1.stride(1), result2.stride(0), result2.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), z.stride(0), z.stride(1), num_warps=4, num_stages=3)
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_range_config_options)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid, loop_unroll_factor=2):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_range_config_options)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM, num_stages=3):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_range_config_options)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid, disallow_acc_multi_buffer=True):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_range_config_options)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM, flatten=True):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_range_config_options)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid, loop_unroll_factor=2, num_stages=3, disallow_acc_multi_buffer=False, flatten=False):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_shared_program_id)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_kernel(x, result1, y, result2, x_size_0, x_size_1, y_size_0, y_size_1, result1_stride_0, result1_stride_1, result2_stride_0, result2_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _NUM_SM: tl.constexpr):
    total_pids = x_size_0 * x_size_1 + y_size_0 * y_size_1
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        pid_shared = virtual_pid
        if pid_shared < x_size_0 * x_size_1:
            num_blocks_0 = x_size_0
            pid_0 = pid_shared % num_blocks_0
            pid_1 = pid_shared // num_blocks_0
            offset_0 = pid_0
            offset_1 = pid_1
            load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1), None)
            v_0 = 2.0
            v_1 = load * v_0
            tl.store(result1 + (offset_0 * result1_stride_0 + offset_1 * result1_stride_1), v_1, None)
        else:
            pid_shared -= x_size_0 * x_size_1
            num_blocks_1 = y_size_0
            pid_2 = pid_shared % num_blocks_1
            pid_3 = pid_shared // num_blocks_1
            offset_2 = pid_2
            offset_3 = pid_3
            load_1 = tl.load(y + (offset_2 * y_stride_0 + offset_3 * y_stride_1), None)
            v_2 = 3.0
            v_3 = load_1 * v_2
            tl.store(result2 + (offset_2 * result2_stride_0 + offset_3 * result2_stride_1), v_3, None)

def multi_loop_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result1 = x.new_empty(x.size())
    result2 = y.new_empty(y.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _launcher(_helion_multi_loop_kernel, (_NUM_SM,), x, result1, y, result2, x.size(0), x.size(1), y.size(0), y.size(1), result1.stride(0), result1.stride(1), result2.stride(0), result2.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _NUM_SM, num_warps=4, num_stages=3)
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_shared_program_id)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_kernel(x, result1, y, result2, x_size_0, x_size_1, y_size_0, y_size_1, result1_stride_0, result1_stride_1, result2_stride_0, result2_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _NUM_SM: tl.constexpr):
    total_pids = x_size_0 * x_size_1 + y_size_0 * y_size_1
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        pid_shared = virtual_pid
        if pid_shared < x_size_0 * x_size_1:
            num_blocks_0 = x_size_0
            pid_0 = pid_shared % num_blocks_0
            pid_1 = pid_shared // num_blocks_0
            offset_0 = pid_0
            offset_1 = pid_1
            load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1), None)
            v_0 = 2.0
            v_1 = load * v_0
            tl.store(result1 + (offset_0 * result1_stride_0 + offset_1 * result1_stride_1), v_1, None)
        else:
            pid_shared -= x_size_0 * x_size_1
            num_blocks_1 = y_size_0
            pid_2 = pid_shared % num_blocks_1
            pid_3 = pid_shared // num_blocks_1
            offset_2 = pid_2
            offset_3 = pid_3
            load_1 = tl.load(y + (offset_2 * y_stride_0 + offset_3 * y_stride_1), None)
            v_2 = 3.0
            v_3 = load_1 * v_2
            tl.store(result2 + (offset_2 * result2_stride_0 + offset_3 * result2_stride_1), v_3, None)

def multi_loop_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result1 = x.new_empty(x.size())
    result2 = y.new_empty(y.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _launcher(_helion_multi_loop_kernel, (_NUM_SM,), x, result1, y, result2, x.size(0), x.size(1), y.size(0), y.size(1), result1.stride(0), result1.stride(1), result2.stride(0), result2.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _NUM_SM, num_warps=4, num_stages=3)
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_shared_program_id)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_kernel(x, result1, y, result2, x_size_0, x_size_1, y_size_0, result1_stride_0, result1_stride_1, result2_stride_0, result2_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1):
    pid_shared = tl.program_id(0)
    if pid_shared < x_size_0 * x_size_1:
        num_blocks_0 = x_size_0
        pid_0 = pid_shared % num_blocks_0
        pid_1 = pid_shared // num_blocks_0
        offset_0 = pid_0
        offset_1 = pid_1
        load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1), None)
        v_0 = 2.0
        v_1 = load * v_0
        tl.store(result1 + (offset_0 * result1_stride_0 + offset_1 * result1_stride_1), v_1, None)
    else:
        pid_shared -= x_size_0 * x_size_1
        num_blocks_1 = y_size_0
        pid_2 = pid_shared % num_blocks_1
        pid_3 = pid_shared // num_blocks_1
        offset_2 = pid_2
        offset_3 = pid_3
        load_1 = tl.load(y + (offset_2 * y_stride_0 + offset_3 * y_stride_1), None)
        v_2 = 3.0
        v_3 = load_1 * v_2
        tl.store(result2 + (offset_2 * result2_stride_0 + offset_3 * result2_stride_1), v_3, None)

def multi_loop_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result1 = x.new_empty(x.size())
    result2 = y.new_empty(y.size())
    _launcher(_helion_multi_loop_kernel, (x.size(0) * x.size(1) + y.size(0) * y.size(1),), x, result1, y, result2, x.size(0), x.size(1), y.size(0), result1.stride(0), result1.stride(1), result2.stride(0), result2.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), num_warps=4, num_stages=3)
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_tensor_descriptor_indexing)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

helion.runtime.set_triton_allocator()

@triton.jit
def _helion_tensor_descriptor_kernel(x, y, result, result_size_0, result_size_1, x_size_0, x_size_1, y_size_0, y_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    x_desc = tl.make_tensor_descriptor(x, [x_size_0, x_size_1], [x_stride_0, x_stride_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1])
    y_desc = tl.make_tensor_descriptor(y, [y_size_0, y_size_1], [y_stride_0, y_stride_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1])
    result_desc = tl.make_tensor_descriptor(result, [result_size_0, result_size_1], [result_stride_0, result_stride_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1])
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        load = x_desc.load([offset_0, offset_1])
        load_1 = y_desc.load([offset_0, offset_1])
        v_0 = load + load_1
        result_desc.store([offset_0, offset_1], v_0)

def tensor_descriptor_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    _launcher(_helion_tensor_descriptor_kernel, (_NUM_SM,), x, y, result, result.size(0), result.size(1), x.size(0), x.size(1), y.size(0), y.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_tensor_descriptor_indexing)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

helion.runtime.set_triton_allocator()

@triton.jit
def _helion_tensor_descriptor_kernel(x, y, result, result_size_0, result_size_1, x_size_0, x_size_1, y_size_0, y_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    x_desc = tl.make_tensor_descriptor(x, [x_size_0, x_size_1], [x_stride_0, x_stride_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1])
    y_desc = tl.make_tensor_descriptor(y, [y_size_0, y_size_1], [y_stride_0, y_stride_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1])
    result_desc = tl.make_tensor_descriptor(result, [result_size_0, result_size_1], [result_stride_0, result_stride_1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1])
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        load = x_desc.load([offset_0, offset_1])
        load_1 = y_desc.load([offset_0, offset_1])
        v_0 = load + load_1
        result_desc.store([offset_0, offset_1], v_0)

def tensor_descriptor_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    _launcher(_helion_tensor_descriptor_kernel, (_NUM_SM,), x, y, result, result.size(0), result.size(1), x.size(0), x.size(1), y.size(0), y.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_warp_specialize)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid, warp_specialize=True):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_loop_variable_names)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_loop_variable_names)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_shared_program_id_with_persistent_basic_functionality)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_add_kernel(x, result1, y, result2, x_size_0, x_size_1, y_size_0, y_size_1, result1_stride_0, result1_stride_1, result2_stride_0, result2_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _NUM_SM: tl.constexpr):
    total_pids = x_size_0 * x_size_1 + y_size_0 * y_size_1
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        pid_shared = virtual_pid
        if pid_shared < x_size_0 * x_size_1:
            num_blocks_0 = x_size_0
            pid_0 = pid_shared % num_blocks_0
            pid_1 = pid_shared // num_blocks_0
            offset_0 = pid_0
            offset_1 = pid_1
            load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1), None)
            v_0 = 1.0
            v_1 = load + v_0
            tl.store(result1 + (offset_0 * result1_stride_0 + offset_1 * result1_stride_1), v_1, None)
        else:
            pid_shared -= x_size_0 * x_size_1
            num_blocks_1 = y_size_0
            pid_2 = pid_shared % num_blocks_1
            pid_3 = pid_shared // num_blocks_1
            offset_2 = pid_2
            offset_3 = pid_3
            load_1 = tl.load(y + (offset_2 * y_stride_0 + offset_3 * y_stride_1), None)
            v_2 = 2.0
            v_3 = load_1 * v_2
            tl.store(result2 + (offset_2 * result2_stride_0 + offset_3 * result2_stride_1), v_3, None)

def multi_add_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result1 = x.new_empty(x.size())
    result2 = y.new_empty(y.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _launcher(_helion_multi_add_kernel, (_NUM_SM,), x, result1, y, result2, x.size(0), x.size(1), y.size(0), y.size(1), result1.stride(0), result1.stride(1), result2.stride(0), result2.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _NUM_SM, num_warps=4, num_stages=3)
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_simple_persistent_kernels_work)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_simple_add(x, y, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        load_1 = tl.load(y + (indices_0[:, None] * y_stride_0 + indices_1[None, :] * y_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = load + load_1
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_0, mask_0[:, None] & mask_1[None, :])

def simple_add(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    _launcher(_helion_simple_add, (_NUM_SM,), x, y, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return result

--- assertExpectedJournal(TestPersistentKernels.test_simple_persistent_kernels_work)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_simple_add(x, y, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        load_1 = tl.load(y + (indices_0[:, None] * y_stride_0 + indices_1[None, :] * y_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = load + load_1
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_0, mask_0[:, None] & mask_1[None, :])

def simple_add(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    result = x.new_empty(x.size())
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    _launcher(_helion_simple_add, (_NUM_SM,), x, y, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return result
