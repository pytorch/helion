This file is automatically generated by assertExpectedJournal calls in test_persistent_kernels.py.
Update expected outputs by running tests with the EXPECTTEST_ACCEPT=1 environment variable set.

--- assertExpectedJournal(TestPersistentKernels.test_multi_loop_persistent_with_shared_program_id)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_kernel(x, result1, y, result2, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 8]):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] * 3
    total_pids = tl.cdiv(4, _BLOCK_SIZE_0) * tl.cdiv(6, _BLOCK_SIZE_1) + tl.cdiv(4, _BLOCK_SIZE_2) * tl.cdiv(6, _BLOCK_SIZE_3)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        pid_shared = virtual_pid
        # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 8]):
        # src[test_persistent_kernels.py:N]:     result1[tile1] = x[tile1] * 2
        if pid_shared < tl.cdiv(4, _BLOCK_SIZE_0) * tl.cdiv(6, _BLOCK_SIZE_1):
            # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 8]):
            num_blocks_0 = tl.cdiv(4, _BLOCK_SIZE_0)
            pid_0 = pid_shared % num_blocks_0
            pid_1 = pid_shared // num_blocks_0
            offset_0 = pid_0 * _BLOCK_SIZE_0
            indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
            mask_0 = indices_0 < 4
            offset_1 = pid_1 * _BLOCK_SIZE_1
            indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
            mask_1 = indices_1 < 6
            # src[test_persistent_kernels.py:N]: result1[tile1] = x[tile1] * 2
            load = tl.load(x + (indices_0[:, None] * 6 + indices_1[None, :] * 1), mask_0[:, None] & mask_1[None, :], other=0)
            v_0 = 2.0
            v_1 = load * v_0
            tl.store(result1 + (indices_0[:, None] * 6 + indices_1[None, :] * 1), v_1, mask_0[:, None] & mask_1[None, :])
        else:
            # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 8]):
            pid_shared -= tl.cdiv(4, _BLOCK_SIZE_0) * tl.cdiv(6, _BLOCK_SIZE_1)
            num_blocks_1 = tl.cdiv(4, _BLOCK_SIZE_2)
            pid_2 = pid_shared % num_blocks_1
            pid_3 = pid_shared // num_blocks_1
            offset_2 = pid_2 * _BLOCK_SIZE_2
            indices_2 = (offset_2 + tl.arange(0, _BLOCK_SIZE_2)).to(tl.int32)
            mask_2 = indices_2 < 4
            offset_3 = pid_3 * _BLOCK_SIZE_3
            indices_3 = (offset_3 + tl.arange(0, _BLOCK_SIZE_3)).to(tl.int32)
            mask_3 = indices_3 < 6
            # src[test_persistent_kernels.py:N]: result2[tile2] = y[tile2] * 3
            load_1 = tl.load(y + (indices_2[:, None] * 6 + indices_3[None, :] * 1), mask_2[:, None] & mask_3[None, :], other=0)
            v_2 = 3.0
            v_3 = load_1 * v_2
            tl.store(result2 + (indices_2[:, None] * 6 + indices_3[None, :] * 1), v_3, mask_2[:, None] & mask_3[None, :])

def multi_loop_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result1 = x.new_empty(x.size())
    result1 = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: result2 = y.new_empty(y.size())
    result2 = y.new_empty(y.size())
    # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 8]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 8
    # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 8]):
    _BLOCK_SIZE_2 = 16
    _BLOCK_SIZE_3 = 8
    # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 8]):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] * 3
    _launcher(_helion_multi_loop_kernel, (_NUM_SM,), x, result1, y, result2, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result1, result2
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_multi_loop_persistent_with_shared_program_id)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_kernel(x, result1, y, result2, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 8]):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] * 3
    total_pids = tl.cdiv(4, _BLOCK_SIZE_0) * tl.cdiv(6, _BLOCK_SIZE_1) + tl.cdiv(4, _BLOCK_SIZE_2) * tl.cdiv(6, _BLOCK_SIZE_3)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        pid_shared = virtual_pid
        # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 8]):
        # src[test_persistent_kernels.py:N]:     result1[tile1] = x[tile1] * 2
        if pid_shared < tl.cdiv(4, _BLOCK_SIZE_0) * tl.cdiv(6, _BLOCK_SIZE_1):
            # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 8]):
            num_blocks_0 = tl.cdiv(4, _BLOCK_SIZE_0)
            pid_0 = pid_shared % num_blocks_0
            pid_1 = pid_shared // num_blocks_0
            offset_0 = pid_0 * _BLOCK_SIZE_0
            indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
            mask_0 = indices_0 < 4
            offset_1 = pid_1 * _BLOCK_SIZE_1
            indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
            mask_1 = indices_1 < 6
            # src[test_persistent_kernels.py:N]: result1[tile1] = x[tile1] * 2
            load = tl.load(x + (indices_0[:, None] * 6 + indices_1[None, :] * 1), mask_0[:, None] & mask_1[None, :], other=0)
            v_0 = 2.0
            v_1 = load * v_0
            tl.store(result1 + (indices_0[:, None] * 6 + indices_1[None, :] * 1), v_1, mask_0[:, None] & mask_1[None, :])
        else:
            # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 8]):
            pid_shared -= tl.cdiv(4, _BLOCK_SIZE_0) * tl.cdiv(6, _BLOCK_SIZE_1)
            num_blocks_1 = tl.cdiv(4, _BLOCK_SIZE_2)
            pid_2 = pid_shared % num_blocks_1
            pid_3 = pid_shared // num_blocks_1
            offset_2 = pid_2 * _BLOCK_SIZE_2
            indices_2 = (offset_2 + tl.arange(0, _BLOCK_SIZE_2)).to(tl.int32)
            mask_2 = indices_2 < 4
            offset_3 = pid_3 * _BLOCK_SIZE_3
            indices_3 = (offset_3 + tl.arange(0, _BLOCK_SIZE_3)).to(tl.int32)
            mask_3 = indices_3 < 6
            # src[test_persistent_kernels.py:N]: result2[tile2] = y[tile2] * 3
            load_1 = tl.load(y + (indices_2[:, None] * 6 + indices_3[None, :] * 1), mask_2[:, None] & mask_3[None, :], other=0)
            v_2 = 3.0
            v_3 = load_1 * v_2
            tl.store(result2 + (indices_2[:, None] * 6 + indices_3[None, :] * 1), v_3, mask_2[:, None] & mask_3[None, :])

def multi_loop_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result1 = x.new_empty(x.size())
    result1 = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: result2 = y.new_empty(y.size())
    result2 = y.new_empty(y.size())
    # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 8]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 8
    # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 8]):
    _BLOCK_SIZE_2 = 16
    _BLOCK_SIZE_3 = 8
    # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 8]):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] * 3
    _launcher(_helion_multi_loop_kernel, (_NUM_SM,), x, result1, y, result2, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result1, result2
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_1d_tiling)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_vector_add_1d(x, y, result, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[128]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    total_pids = tl.cdiv(1024, _BLOCK_SIZE_0)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[128]):
        pid_0 = virtual_pid
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
        load = tl.load(x + indices_0 * 1, None)
        load_1 = tl.load(y + indices_0 * 1, None)
        v_0 = load + load_1
        tl.store(result + indices_0 * 1, v_0, None)

def vector_add_1d(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[128]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 128
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[128]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_vector_add_1d, (_NUM_SM,), x, y, result, _NUM_SM, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_1d_tiling)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_vector_add_1d(x, y, result, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[128]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    total_pids = tl.cdiv(1024, _BLOCK_SIZE_0)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[128]):
        pid_0 = virtual_pid
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
        load = tl.load(x + indices_0 * 1, None)
        load_1 = tl.load(y + indices_0 * 1, None)
        v_0 = load + load_1
        tl.store(result + indices_0 * 1, v_0, None)

def vector_add_1d(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[128]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 128
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[128]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_vector_add_1d, (_NUM_SM,), x, y, result, _NUM_SM, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_1d_tiling)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_vector_add_1d(x, y, result, _BLOCK_SIZE_0: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[128]):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
    load = tl.load(x + indices_0 * 1, None)
    load_1 = tl.load(y + indices_0 * 1, None)
    v_0 = load + load_1
    tl.store(result + indices_0 * 1, v_0, None)

def vector_add_1d(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[128]):
    _BLOCK_SIZE_0 = 128
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[128]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_vector_add_1d, (triton.cdiv(1024, _BLOCK_SIZE_0),), x, y, result, _BLOCK_SIZE_0, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_blocked_3d)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_3d_kernel(x, y, result, _NUM_SM: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    total_pids = 32 * 64 * 48
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
        num_blocks_0 = 32
        num_blocks_1 = 64
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0 % num_blocks_1
        pid_2 = virtual_pid // (num_blocks_0 * num_blocks_1)
        offset_0 = pid_0
        offset_1 = pid_1
        offset_2 = pid_2
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
        load = tl.load(x + (offset_0 * 3072 + offset_1 * 48 + offset_2 * 1), None)
        load_1 = tl.load(y + (offset_0 * 3072 + offset_1 * 48 + offset_2 * 1), None)
        v_0 = load + load_1
        tl.store(result + (offset_0 * 3072 + offset_1 * 48 + offset_2 * 1), v_0, None)

def add_3d_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_add_3d_kernel, (_NUM_SM,), x, y, result, _NUM_SM, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_blocked_3d)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_3d_kernel(x, y, result):
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    num_blocks_0 = 32
    num_blocks_1 = 64
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0 % num_blocks_1
    pid_2 = tl.program_id(0) // (num_blocks_0 * num_blocks_1)
    offset_0 = pid_0
    offset_1 = pid_1
    offset_2 = pid_2
    # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
    load = tl.load(x + (offset_0 * 3072 + offset_1 * 48 + offset_2 * 1), None)
    load_1 = tl.load(y + (offset_0 * 3072 + offset_1 * 48 + offset_2 * 1), None)
    v_0 = load + load_1
    tl.store(result + (offset_0 * 3072 + offset_1 * 48 + offset_2 * 1), v_0, None)

def add_3d_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_add_3d_kernel, (32 * 64 * 48,), x, y, result, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_blocked_matmul)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_matmul_kernel(A, B, result, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile_m, tile_n in hl.tile([M, N]):
    # src[test_persistent_kernels.py:N]:     acc = hl.zeros([tile_m, tile_n], dtype=torch.float32)
    # src[test_persistent_kernels.py:N]:     for tile_k in hl.tile(K):
    # src[test_persistent_kernels.py:N-N]: ...
    total_pids = tl.cdiv(64, _BLOCK_SIZE_0) * tl.cdiv(96, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        # src[test_persistent_kernels.py:N]: for tile_m, tile_n in hl.tile([M, N]):
        num_blocks_0 = tl.cdiv(64, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        # src[test_persistent_kernels.py:N]: acc = hl.zeros([tile_m, tile_n], dtype=torch.float32)
        acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
        # src[test_persistent_kernels.py:N]: for tile_k in hl.tile(K):
        # src[test_persistent_kernels.py:N]:     acc += A[tile_m, tile_k] @ B[tile_k, tile_n]
        for offset_2 in tl.range(0, 128, _BLOCK_SIZE_2):
            indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
            acc_copy = acc
            acc_copy_0 = acc_copy
            # src[test_persistent_kernels.py:N]: acc += A[tile_m, tile_k] @ B[tile_k, tile_n]
            load = tl.load(A + (indices_0[:, None] * 128 + indices_2[None, :] * 1), None)
            load_1 = tl.load(B + (indices_2[:, None] * 96 + indices_1[None, :] * 1), None)
            mm = tl.dot(tl.cast(load, tl.float32), tl.cast(load_1, tl.float32), input_precision='tf32', out_dtype=tl.float32)
            acc = acc_copy_0 + mm
        # src[test_persistent_kernels.py:N]: result[tile_m, tile_n] = acc
        tl.store(result + (indices_0[:, None] * 96 + indices_1[None, :] * 1), acc, None)

def matmul_kernel(A: torch.Tensor, B: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: M, K = A.size()
    M, K = A.size()
    # src[test_persistent_kernels.py:N]: K2, N = B.size()
    K2, N = B.size()
    # src[test_persistent_kernels.py:N]: assert K == K2
    assert K == K2
    # src[test_persistent_kernels.py:N]: result = A.new_empty([M, N])
    result = A.new_empty([M, N])
    # src[test_persistent_kernels.py:N]: for tile_m, tile_n in hl.tile([M, N]):
    _NUM_SM = helion.runtime.get_num_sm(A.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    # src[test_persistent_kernels.py:N]: for tile_k in hl.tile(K):
    # src[test_persistent_kernels.py:N]:     acc += A[tile_m, tile_k] @ B[tile_k, tile_n]
    _BLOCK_SIZE_2 = 32
    # src[test_persistent_kernels.py:N]: for tile_m, tile_n in hl.tile([M, N]):
    # src[test_persistent_kernels.py:N]:     acc = hl.zeros([tile_m, tile_n], dtype=torch.float32)
    # src[test_persistent_kernels.py:N]:     for tile_k in hl.tile(K):
    # src[test_persistent_kernels.py:N-N]: ...
    _launcher(_helion_matmul_kernel, (_NUM_SM,), A, B, result, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_blocked_matmul)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_matmul_kernel(A, B, result, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile_m, tile_n in hl.tile([M, N]):
    num_blocks_0 = tl.cdiv(64, _BLOCK_SIZE_0)
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    # src[test_persistent_kernels.py:N]: acc = hl.zeros([tile_m, tile_n], dtype=torch.float32)
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    # src[test_persistent_kernels.py:N]: for tile_k in hl.tile(K):
    # src[test_persistent_kernels.py:N]:     acc += A[tile_m, tile_k] @ B[tile_k, tile_n]
    for offset_2 in tl.range(0, 128, _BLOCK_SIZE_2):
        indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
        acc_copy = acc
        acc_copy_0 = acc_copy
        # src[test_persistent_kernels.py:N]: acc += A[tile_m, tile_k] @ B[tile_k, tile_n]
        load = tl.load(A + (indices_0[:, None] * 128 + indices_2[None, :] * 1), None)
        load_1 = tl.load(B + (indices_2[:, None] * 96 + indices_1[None, :] * 1), None)
        mm = tl.dot(tl.cast(load, tl.float32), tl.cast(load_1, tl.float32), input_precision='tf32', out_dtype=tl.float32)
        acc = acc_copy_0 + mm
    # src[test_persistent_kernels.py:N]: result[tile_m, tile_n] = acc
    tl.store(result + (indices_0[:, None] * 96 + indices_1[None, :] * 1), acc, None)

def matmul_kernel(A: torch.Tensor, B: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: M, K = A.size()
    M, K = A.size()
    # src[test_persistent_kernels.py:N]: K2, N = B.size()
    K2, N = B.size()
    # src[test_persistent_kernels.py:N]: assert K == K2
    assert K == K2
    # src[test_persistent_kernels.py:N]: result = A.new_empty([M, N])
    result = A.new_empty([M, N])
    # src[test_persistent_kernels.py:N]: for tile_m, tile_n in hl.tile([M, N]):
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    # src[test_persistent_kernels.py:N]: for tile_k in hl.tile(K):
    # src[test_persistent_kernels.py:N]:     acc += A[tile_m, tile_k] @ B[tile_k, tile_n]
    _BLOCK_SIZE_2 = 32
    # src[test_persistent_kernels.py:N]: for tile_m, tile_n in hl.tile([M, N]):
    # src[test_persistent_kernels.py:N]:     acc = hl.zeros([tile_m, tile_n], dtype=torch.float32)
    # src[test_persistent_kernels.py:N]:     for tile_k in hl.tile(K):
    # src[test_persistent_kernels.py:N-N]: ...
    _launcher(_helion_matmul_kernel, (triton.cdiv(64, _BLOCK_SIZE_0) * triton.cdiv(96, _BLOCK_SIZE_1),), A, B, result, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_blocked_simple_add)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_kernel(x, y, result, _NUM_SM: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    total_pids = 128 * 256
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
        num_blocks_0 = 128
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0
        offset_1 = pid_1
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
        load = tl.load(x + (offset_0 * 256 + offset_1 * 1), None)
        load_1 = tl.load(y + (offset_0 * 256 + offset_1 * 1), None)
        v_0 = load + load_1
        tl.store(result + (offset_0 * 256 + offset_1 * 1), v_0, None)

def add_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_add_kernel, (_NUM_SM,), x, y, result, _NUM_SM, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_blocked_with_l2_grouping)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_kernel(x, y, result, _NUM_SM: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    total_pids = 64 * 128
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
        num_pid_m = 64
        num_pid_n = 128
        inner_2d_pid = virtual_pid
        num_pid_in_group = 8 * num_pid_n
        group_id = inner_2d_pid // num_pid_in_group
        first_pid_m = group_id * 8
        group_size_m = min(num_pid_m - first_pid_m, 8)
        pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
        pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
        offset_0 = pid_0
        offset_1 = pid_1
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
        load = tl.load(x + (offset_0 * 128 + offset_1 * 1), None)
        load_1 = tl.load(y + (offset_0 * 128 + offset_1 * 1), None)
        v_0 = load + load_1
        tl.store(result + (offset_0 * 128 + offset_1 * 1), v_0, None)

def add_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_add_kernel, (_NUM_SM,), x, y, result, _NUM_SM, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_blocked_with_l2_grouping)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_kernel(x, y, result):
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    num_pid_m = 64
    num_pid_n = 128
    inner_2d_pid = tl.program_id(0)
    num_pid_in_group = 8 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 8
    group_size_m = min(num_pid_m - first_pid_m, 8)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    offset_0 = pid_0
    offset_1 = pid_1
    # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
    load = tl.load(x + (offset_0 * 128 + offset_1 * 1), None)
    load_1 = tl.load(y + (offset_0 * 128 + offset_1 * 1), None)
    v_0 = load + load_1
    tl.store(result + (offset_0 * 128 + offset_1 * 1), v_0, None)

def add_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_add_kernel, (64 * 128,), x, y, result, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_blocked_with_l2_grouping)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_kernel(x, y, result, _NUM_SM: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    total_pids = 64 * 128
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
        num_blocks_0 = 64
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0
        offset_1 = pid_1
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
        load = tl.load(x + (offset_0 * 128 + offset_1 * 1), None)
        load_1 = tl.load(y + (offset_0 * 128 + offset_1 * 1), None)
        v_0 = load + load_1
        tl.store(result + (offset_0 * 128 + offset_1 * 1), v_0, None)

def add_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_add_kernel, (_NUM_SM,), x, y, result, _NUM_SM, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_grid_size_correctness)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    num_blocks_0 = tl.cdiv(64, _BLOCK_SIZE_0)
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + 1
    load = tl.load(x + (indices_0[:, None] * 96 + indices_1[None, :] * 1), None)
    v_0 = 1.0
    v_1 = load + v_0
    tl.store(result + (indices_0[:, None] * 96 + indices_1[None, :] * 1), v_1, None)

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    _launcher(_helion_test_kernel, (triton.cdiv(64, _BLOCK_SIZE_0) * triton.cdiv(96, _BLOCK_SIZE_1),), x, result, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_grid_size_correctness)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    total_pids = tl.cdiv(64, _BLOCK_SIZE_0) * tl.cdiv(96, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
        num_blocks_0 = tl.cdiv(64, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + 1
        load = tl.load(x + (indices_0[:, None] * 96 + indices_1[None, :] * 1), None)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * 96 + indices_1[None, :] * 1), v_1, None)

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_grid_size_correctness)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    total_pids = tl.cdiv(64, _BLOCK_SIZE_0) * tl.cdiv(96, _BLOCK_SIZE_1)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
        num_blocks_0 = tl.cdiv(64, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + 1
        load = tl.load(x + (indices_0[:, None] * 96 + indices_1[None, :] * 1), None)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * 96 + indices_1[None, :] * 1), v_1, None)

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_3d)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_3d_kernel(x, y, result, _NUM_SM: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    total_pids = 32 * 64 * 48
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
        num_blocks_0 = 32
        num_blocks_1 = 64
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0 % num_blocks_1
        pid_2 = virtual_pid // (num_blocks_0 * num_blocks_1)
        offset_0 = pid_0
        offset_1 = pid_1
        offset_2 = pid_2
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
        load = tl.load(x + (offset_0 * 3072 + offset_1 * 48 + offset_2 * 1), None)
        load_1 = tl.load(y + (offset_0 * 3072 + offset_1 * 48 + offset_2 * 1), None)
        v_0 = load + load_1
        tl.store(result + (offset_0 * 3072 + offset_1 * 48 + offset_2 * 1), v_0, None)

def add_3d_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_add_3d_kernel, (_NUM_SM,), x, y, result, _NUM_SM, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_3d)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_3d_kernel(x, y, result):
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    num_blocks_0 = 32
    num_blocks_1 = 64
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0 % num_blocks_1
    pid_2 = tl.program_id(0) // (num_blocks_0 * num_blocks_1)
    offset_0 = pid_0
    offset_1 = pid_1
    offset_2 = pid_2
    # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
    load = tl.load(x + (offset_0 * 3072 + offset_1 * 48 + offset_2 * 1), None)
    load_1 = tl.load(y + (offset_0 * 3072 + offset_1 * 48 + offset_2 * 1), None)
    v_0 = load + load_1
    tl.store(result + (offset_0 * 3072 + offset_1 * 48 + offset_2 * 1), v_0, None)

def add_3d_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_add_3d_kernel, (32 * 64 * 48,), x, y, result, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_matmul)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_matmul_kernel(A, B, result, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile_m, tile_n in hl.tile([M, N]):
    # src[test_persistent_kernels.py:N]:     acc = hl.zeros([tile_m, tile_n], dtype=torch.float32)
    # src[test_persistent_kernels.py:N]:     for tile_k in hl.tile(K):
    # src[test_persistent_kernels.py:N-N]: ...
    total_pids = tl.cdiv(64, _BLOCK_SIZE_0) * tl.cdiv(96, _BLOCK_SIZE_1)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        # src[test_persistent_kernels.py:N]: for tile_m, tile_n in hl.tile([M, N]):
        num_blocks_0 = tl.cdiv(64, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        # src[test_persistent_kernels.py:N]: acc = hl.zeros([tile_m, tile_n], dtype=torch.float32)
        acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
        # src[test_persistent_kernels.py:N]: for tile_k in hl.tile(K):
        # src[test_persistent_kernels.py:N]:     acc += A[tile_m, tile_k] @ B[tile_k, tile_n]
        for offset_2 in tl.range(0, 128, _BLOCK_SIZE_2):
            indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
            acc_copy = acc
            acc_copy_0 = acc_copy
            # src[test_persistent_kernels.py:N]: acc += A[tile_m, tile_k] @ B[tile_k, tile_n]
            load = tl.load(A + (indices_0[:, None] * 128 + indices_2[None, :] * 1), None)
            load_1 = tl.load(B + (indices_2[:, None] * 96 + indices_1[None, :] * 1), None)
            mm = tl.dot(tl.cast(load, tl.float32), tl.cast(load_1, tl.float32), input_precision='tf32', out_dtype=tl.float32)
            acc = acc_copy_0 + mm
        # src[test_persistent_kernels.py:N]: result[tile_m, tile_n] = acc
        tl.store(result + (indices_0[:, None] * 96 + indices_1[None, :] * 1), acc, None)

def matmul_kernel(A: torch.Tensor, B: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: M, K = A.size()
    M, K = A.size()
    # src[test_persistent_kernels.py:N]: K2, N = B.size()
    K2, N = B.size()
    # src[test_persistent_kernels.py:N]: assert K == K2
    assert K == K2
    # src[test_persistent_kernels.py:N]: result = A.new_empty([M, N])
    result = A.new_empty([M, N])
    # src[test_persistent_kernels.py:N]: for tile_m, tile_n in hl.tile([M, N]):
    _NUM_SM = helion.runtime.get_num_sm(A.device)
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile_k in hl.tile(K):
    # src[test_persistent_kernels.py:N]:     acc += A[tile_m, tile_k] @ B[tile_k, tile_n]
    _BLOCK_SIZE_2 = 32
    # src[test_persistent_kernels.py:N]: for tile_m, tile_n in hl.tile([M, N]):
    # src[test_persistent_kernels.py:N]:     acc = hl.zeros([tile_m, tile_n], dtype=torch.float32)
    # src[test_persistent_kernels.py:N]:     for tile_k in hl.tile(K):
    # src[test_persistent_kernels.py:N-N]: ...
    _launcher(_helion_matmul_kernel, (_NUM_SM,), A, B, result, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_matmul)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_matmul_kernel(A, B, result, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile_m, tile_n in hl.tile([M, N]):
    num_blocks_0 = tl.cdiv(64, _BLOCK_SIZE_0)
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    # src[test_persistent_kernels.py:N]: acc = hl.zeros([tile_m, tile_n], dtype=torch.float32)
    acc = tl.full([_BLOCK_SIZE_0, _BLOCK_SIZE_1], 0.0, tl.float32)
    # src[test_persistent_kernels.py:N]: for tile_k in hl.tile(K):
    # src[test_persistent_kernels.py:N]:     acc += A[tile_m, tile_k] @ B[tile_k, tile_n]
    for offset_2 in tl.range(0, 128, _BLOCK_SIZE_2):
        indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
        acc_copy = acc
        acc_copy_0 = acc_copy
        # src[test_persistent_kernels.py:N]: acc += A[tile_m, tile_k] @ B[tile_k, tile_n]
        load = tl.load(A + (indices_0[:, None] * 128 + indices_2[None, :] * 1), None)
        load_1 = tl.load(B + (indices_2[:, None] * 96 + indices_1[None, :] * 1), None)
        mm = tl.dot(tl.cast(load, tl.float32), tl.cast(load_1, tl.float32), input_precision='tf32', out_dtype=tl.float32)
        acc = acc_copy_0 + mm
    # src[test_persistent_kernels.py:N]: result[tile_m, tile_n] = acc
    tl.store(result + (indices_0[:, None] * 96 + indices_1[None, :] * 1), acc, None)

def matmul_kernel(A: torch.Tensor, B: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: M, K = A.size()
    M, K = A.size()
    # src[test_persistent_kernels.py:N]: K2, N = B.size()
    K2, N = B.size()
    # src[test_persistent_kernels.py:N]: assert K == K2
    assert K == K2
    # src[test_persistent_kernels.py:N]: result = A.new_empty([M, N])
    result = A.new_empty([M, N])
    # src[test_persistent_kernels.py:N]: for tile_m, tile_n in hl.tile([M, N]):
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile_k in hl.tile(K):
    # src[test_persistent_kernels.py:N]:     acc += A[tile_m, tile_k] @ B[tile_k, tile_n]
    _BLOCK_SIZE_2 = 32
    # src[test_persistent_kernels.py:N]: for tile_m, tile_n in hl.tile([M, N]):
    # src[test_persistent_kernels.py:N]:     acc = hl.zeros([tile_m, tile_n], dtype=torch.float32)
    # src[test_persistent_kernels.py:N]:     for tile_k in hl.tile(K):
    # src[test_persistent_kernels.py:N-N]: ...
    _launcher(_helion_matmul_kernel, (triton.cdiv(64, _BLOCK_SIZE_0) * triton.cdiv(96, _BLOCK_SIZE_1),), A, B, result, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_multiple_loops_with_l2_grouping)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_l2_kernel(x, result1, y, result2, result3, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr, _BLOCK_SIZE_4: tl.constexpr, _BLOCK_SIZE_5: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile3 in hl.tile(y.size(), block_size=[16, 16]):
    # src[test_persistent_kernels.py:N]:     result3[tile3] = y[tile3] + 2.0
    total_pids = tl.cdiv(32, _BLOCK_SIZE_0) * tl.cdiv(64, _BLOCK_SIZE_1) + tl.cdiv(32, _BLOCK_SIZE_2) * tl.cdiv(64, _BLOCK_SIZE_3) + tl.cdiv(32, _BLOCK_SIZE_4) * tl.cdiv(64, _BLOCK_SIZE_5)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        pid_shared = virtual_pid
        # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 16]):
        # src[test_persistent_kernels.py:N]:     result1[tile1] = x[tile1] * 2.0
        if pid_shared < tl.cdiv(32, _BLOCK_SIZE_0) * tl.cdiv(64, _BLOCK_SIZE_1):
            # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 16]):
            num_pid_m = tl.cdiv(32, _BLOCK_SIZE_0)
            num_pid_n = tl.cdiv(64, _BLOCK_SIZE_1)
            inner_2d_pid = pid_shared
            num_pid_in_group = 2 * num_pid_n
            group_id = inner_2d_pid // num_pid_in_group
            first_pid_m = group_id * 2
            group_size_m = min(num_pid_m - first_pid_m, 2)
            pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
            pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
            offset_0 = pid_0 * _BLOCK_SIZE_0
            indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
            offset_1 = pid_1 * _BLOCK_SIZE_1
            indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
            # src[test_persistent_kernels.py:N]: result1[tile1] = x[tile1] * 2.0
            load = tl.load(x + (indices_0[:, None] * 64 + indices_1[None, :] * 1), None)
            v_0 = 2.0
            v_1 = load * v_0
            tl.store(result1 + (indices_0[:, None] * 64 + indices_1[None, :] * 1), v_1, None)
        elif pid_shared < tl.cdiv(32, _BLOCK_SIZE_0) * tl.cdiv(64, _BLOCK_SIZE_1) + tl.cdiv(32, _BLOCK_SIZE_2) * tl.cdiv(64, _BLOCK_SIZE_3):
            # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 16]):
            pid_shared -= tl.cdiv(32, _BLOCK_SIZE_0) * tl.cdiv(64, _BLOCK_SIZE_1)
            num_pid_m_1 = tl.cdiv(32, _BLOCK_SIZE_2)
            num_pid_n_1 = tl.cdiv(64, _BLOCK_SIZE_3)
            inner_2d_pid_1 = pid_shared
            num_pid_in_group_1 = 4 * num_pid_n_1
            group_id_1 = inner_2d_pid_1 // num_pid_in_group_1
            first_pid_m_1 = group_id_1 * 4
            group_size_m_1 = min(num_pid_m_1 - first_pid_m_1, 4)
            pid_2 = first_pid_m_1 + inner_2d_pid_1 % num_pid_in_group_1 % group_size_m_1
            pid_3 = inner_2d_pid_1 % num_pid_in_group_1 // group_size_m_1
            offset_2 = pid_2 * _BLOCK_SIZE_2
            indices_2 = (offset_2 + tl.arange(0, _BLOCK_SIZE_2)).to(tl.int32)
            offset_3 = pid_3 * _BLOCK_SIZE_3
            indices_3 = (offset_3 + tl.arange(0, _BLOCK_SIZE_3)).to(tl.int32)
            # src[test_persistent_kernels.py:N]: result2[tile2] = y[tile2] + 1.0
            load_1 = tl.load(y + (indices_2[:, None] * 64 + indices_3[None, :] * 1), None)
            v_2 = 1.0
            v_3 = load_1 + v_2
            tl.store(result2 + (indices_2[:, None] * 64 + indices_3[None, :] * 1), v_3, None)
        else:
            # src[test_persistent_kernels.py:N]: for tile3 in hl.tile(y.size(), block_size=[16, 16]):
            pid_shared -= tl.cdiv(32, _BLOCK_SIZE_0) * tl.cdiv(64, _BLOCK_SIZE_1) + tl.cdiv(32, _BLOCK_SIZE_2) * tl.cdiv(64, _BLOCK_SIZE_3)
            num_pid_m_2 = tl.cdiv(32, _BLOCK_SIZE_4)
            num_pid_n_2 = tl.cdiv(64, _BLOCK_SIZE_5)
            inner_2d_pid_2 = pid_shared
            num_pid_in_group_2 = 2 * num_pid_n_2
            group_id_2 = inner_2d_pid_2 // num_pid_in_group_2
            first_pid_m_2 = group_id_2 * 2
            group_size_m_2 = min(num_pid_m_2 - first_pid_m_2, 2)
            pid_4 = first_pid_m_2 + inner_2d_pid_2 % num_pid_in_group_2 % group_size_m_2
            pid_5 = inner_2d_pid_2 % num_pid_in_group_2 // group_size_m_2
            offset_4 = pid_4 * _BLOCK_SIZE_4
            indices_4 = (offset_4 + tl.arange(0, _BLOCK_SIZE_4)).to(tl.int32)
            offset_5 = pid_5 * _BLOCK_SIZE_5
            indices_5 = (offset_5 + tl.arange(0, _BLOCK_SIZE_5)).to(tl.int32)
            # src[test_persistent_kernels.py:N]: result3[tile3] = y[tile3] + 2.0
            load_2 = tl.load(y + (indices_4[:, None] * 64 + indices_5[None, :] * 1), None)
            v_4 = 2.0
            v_5 = load_2 + v_4
            tl.store(result3 + (indices_4[:, None] * 64 + indices_5[None, :] * 1), v_5, None)

def multi_loop_l2_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result1 = x.new_empty(x.size())
    result1 = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: result2 = y.new_empty(y.size())
    result2 = y.new_empty(y.size())
    # src[test_persistent_kernels.py:N]: result3 = y.new_empty(y.size())
    result3 = y.new_empty(y.size())
    # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 16]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 16]):
    _BLOCK_SIZE_2 = 16
    _BLOCK_SIZE_3 = 16
    # src[test_persistent_kernels.py:N]: for tile3 in hl.tile(y.size(), block_size=[16, 16]):
    _BLOCK_SIZE_4 = 16
    _BLOCK_SIZE_5 = 16
    # src[test_persistent_kernels.py:N]: for tile3 in hl.tile(y.size(), block_size=[16, 16]):
    # src[test_persistent_kernels.py:N]:     result3[tile3] = y[tile3] + 2.0
    _launcher(_helion_multi_loop_l2_kernel, (_NUM_SM,), x, result1, y, result2, result3, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3, _BLOCK_SIZE_4, _BLOCK_SIZE_5, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result1, result2, result3
    return (result1, result2, result3)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_multiple_loops_with_l2_grouping)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_l2_kernel(x, result1, y, result2, result3, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr, _BLOCK_SIZE_4: tl.constexpr, _BLOCK_SIZE_5: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 16]):
    # src[test_persistent_kernels.py:N]:     result1[tile1] = x[tile1] * 2.0
    pid_shared = tl.program_id(0)
    if pid_shared < tl.cdiv(32, _BLOCK_SIZE_0) * tl.cdiv(64, _BLOCK_SIZE_1):
        # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 16]):
        num_pid_m = tl.cdiv(32, _BLOCK_SIZE_0)
        num_pid_n = tl.cdiv(64, _BLOCK_SIZE_1)
        inner_2d_pid = pid_shared
        num_pid_in_group = 4 * num_pid_n
        group_id = inner_2d_pid // num_pid_in_group
        first_pid_m = group_id * 4
        group_size_m = min(num_pid_m - first_pid_m, 4)
        pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
        pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        # src[test_persistent_kernels.py:N]: result1[tile1] = x[tile1] * 2.0
        load = tl.load(x + (indices_0[:, None] * 64 + indices_1[None, :] * 1), None)
        v_0 = 2.0
        v_1 = load * v_0
        tl.store(result1 + (indices_0[:, None] * 64 + indices_1[None, :] * 1), v_1, None)
    elif pid_shared < tl.cdiv(32, _BLOCK_SIZE_0) * tl.cdiv(64, _BLOCK_SIZE_1) + tl.cdiv(32, _BLOCK_SIZE_2) * tl.cdiv(64, _BLOCK_SIZE_3):
        # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 16]):
        pid_shared -= tl.cdiv(32, _BLOCK_SIZE_0) * tl.cdiv(64, _BLOCK_SIZE_1)
        num_blocks_1 = tl.cdiv(32, _BLOCK_SIZE_2)
        pid_2 = pid_shared % num_blocks_1
        pid_3 = pid_shared // num_blocks_1
        offset_2 = pid_2 * _BLOCK_SIZE_2
        indices_2 = (offset_2 + tl.arange(0, _BLOCK_SIZE_2)).to(tl.int32)
        offset_3 = pid_3 * _BLOCK_SIZE_3
        indices_3 = (offset_3 + tl.arange(0, _BLOCK_SIZE_3)).to(tl.int32)
        # src[test_persistent_kernels.py:N]: result2[tile2] = y[tile2] + 1.0
        load_1 = tl.load(y + (indices_2[:, None] * 64 + indices_3[None, :] * 1), None)
        v_2 = 1.0
        v_3 = load_1 + v_2
        tl.store(result2 + (indices_2[:, None] * 64 + indices_3[None, :] * 1), v_3, None)
    else:
        # src[test_persistent_kernels.py:N]: for tile3 in hl.tile(y.size(), block_size=[16, 16]):
        pid_shared -= tl.cdiv(32, _BLOCK_SIZE_0) * tl.cdiv(64, _BLOCK_SIZE_1) + tl.cdiv(32, _BLOCK_SIZE_2) * tl.cdiv(64, _BLOCK_SIZE_3)
        num_blocks_2 = tl.cdiv(32, _BLOCK_SIZE_4)
        pid_4 = pid_shared % num_blocks_2
        pid_5 = pid_shared // num_blocks_2
        offset_4 = pid_4 * _BLOCK_SIZE_4
        indices_4 = (offset_4 + tl.arange(0, _BLOCK_SIZE_4)).to(tl.int32)
        offset_5 = pid_5 * _BLOCK_SIZE_5
        indices_5 = (offset_5 + tl.arange(0, _BLOCK_SIZE_5)).to(tl.int32)
        # src[test_persistent_kernels.py:N]: result3[tile3] = y[tile3] + 2.0
        load_2 = tl.load(y + (indices_4[:, None] * 64 + indices_5[None, :] * 1), None)
        v_4 = 2.0
        v_5 = load_2 + v_4
        tl.store(result3 + (indices_4[:, None] * 64 + indices_5[None, :] * 1), v_5, None)

def multi_loop_l2_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result1 = x.new_empty(x.size())
    result1 = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: result2 = y.new_empty(y.size())
    result2 = y.new_empty(y.size())
    # src[test_persistent_kernels.py:N]: result3 = y.new_empty(y.size())
    result3 = y.new_empty(y.size())
    # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 16]):
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 16]):
    _BLOCK_SIZE_2 = 16
    _BLOCK_SIZE_3 = 16
    # src[test_persistent_kernels.py:N]: for tile3 in hl.tile(y.size(), block_size=[16, 16]):
    _BLOCK_SIZE_4 = 16
    _BLOCK_SIZE_5 = 16
    # src[test_persistent_kernels.py:N]: for tile3 in hl.tile(y.size(), block_size=[16, 16]):
    # src[test_persistent_kernels.py:N]:     result3[tile3] = y[tile3] + 2.0
    _launcher(_helion_multi_loop_l2_kernel, (triton.cdiv(32, _BLOCK_SIZE_0) * triton.cdiv(64, _BLOCK_SIZE_1) + triton.cdiv(32, _BLOCK_SIZE_2) * triton.cdiv(64, _BLOCK_SIZE_3) + triton.cdiv(32, _BLOCK_SIZE_4) * triton.cdiv(64, _BLOCK_SIZE_5),), x, result1, y, result2, result3, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3, _BLOCK_SIZE_4, _BLOCK_SIZE_5, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result1, result2, result3
    return (result1, result2, result3)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_multiple_loops_without_l2_grouping)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_kernel(x, result1, y, result2, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 16]):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] + 1.0
    total_pids = tl.cdiv(32, _BLOCK_SIZE_0) * tl.cdiv(64, _BLOCK_SIZE_1) + tl.cdiv(32, _BLOCK_SIZE_2) * tl.cdiv(64, _BLOCK_SIZE_3)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        pid_shared = virtual_pid
        # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 16]):
        # src[test_persistent_kernels.py:N]:     result1[tile1] = x[tile1] * 2.0
        if pid_shared < tl.cdiv(32, _BLOCK_SIZE_0) * tl.cdiv(64, _BLOCK_SIZE_1):
            # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 16]):
            num_blocks_0 = tl.cdiv(32, _BLOCK_SIZE_0)
            pid_0 = pid_shared % num_blocks_0
            pid_1 = pid_shared // num_blocks_0
            offset_0 = pid_0 * _BLOCK_SIZE_0
            indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
            offset_1 = pid_1 * _BLOCK_SIZE_1
            indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
            # src[test_persistent_kernels.py:N]: result1[tile1] = x[tile1] * 2.0
            load = tl.load(x + (indices_0[:, None] * 64 + indices_1[None, :] * 1), None)
            v_0 = 2.0
            v_1 = load * v_0
            tl.store(result1 + (indices_0[:, None] * 64 + indices_1[None, :] * 1), v_1, None)
        else:
            # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 16]):
            pid_shared -= tl.cdiv(32, _BLOCK_SIZE_0) * tl.cdiv(64, _BLOCK_SIZE_1)
            num_blocks_1 = tl.cdiv(32, _BLOCK_SIZE_2)
            pid_2 = pid_shared % num_blocks_1
            pid_3 = pid_shared // num_blocks_1
            offset_2 = pid_2 * _BLOCK_SIZE_2
            indices_2 = (offset_2 + tl.arange(0, _BLOCK_SIZE_2)).to(tl.int32)
            offset_3 = pid_3 * _BLOCK_SIZE_3
            indices_3 = (offset_3 + tl.arange(0, _BLOCK_SIZE_3)).to(tl.int32)
            # src[test_persistent_kernels.py:N]: result2[tile2] = y[tile2] + 1.0
            load_1 = tl.load(y + (indices_2[:, None] * 64 + indices_3[None, :] * 1), None)
            v_2 = 1.0
            v_3 = load_1 + v_2
            tl.store(result2 + (indices_2[:, None] * 64 + indices_3[None, :] * 1), v_3, None)

def multi_loop_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result1 = x.new_empty(x.size())
    result1 = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: result2 = y.new_empty(y.size())
    result2 = y.new_empty(y.size())
    # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 16]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 16]):
    _BLOCK_SIZE_2 = 16
    _BLOCK_SIZE_3 = 16
    # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 16]):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] + 1.0
    _launcher(_helion_multi_loop_kernel, (_NUM_SM,), x, result1, y, result2, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result1, result2
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_multiple_loops_without_l2_grouping)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_kernel(x, result1, y, result2, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 16]):
    # src[test_persistent_kernels.py:N]:     result1[tile1] = x[tile1] * 2.0
    pid_shared = tl.program_id(0)
    if pid_shared < tl.cdiv(32, _BLOCK_SIZE_0) * tl.cdiv(64, _BLOCK_SIZE_1):
        # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 16]):
        num_blocks_0 = tl.cdiv(32, _BLOCK_SIZE_0)
        pid_0 = pid_shared % num_blocks_0
        pid_1 = pid_shared // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        # src[test_persistent_kernels.py:N]: result1[tile1] = x[tile1] * 2.0
        load = tl.load(x + (indices_0[:, None] * 64 + indices_1[None, :] * 1), None)
        v_0 = 2.0
        v_1 = load * v_0
        tl.store(result1 + (indices_0[:, None] * 64 + indices_1[None, :] * 1), v_1, None)
    else:
        # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 16]):
        pid_shared -= tl.cdiv(32, _BLOCK_SIZE_0) * tl.cdiv(64, _BLOCK_SIZE_1)
        num_blocks_1 = tl.cdiv(32, _BLOCK_SIZE_2)
        pid_2 = pid_shared % num_blocks_1
        pid_3 = pid_shared // num_blocks_1
        offset_2 = pid_2 * _BLOCK_SIZE_2
        indices_2 = (offset_2 + tl.arange(0, _BLOCK_SIZE_2)).to(tl.int32)
        offset_3 = pid_3 * _BLOCK_SIZE_3
        indices_3 = (offset_3 + tl.arange(0, _BLOCK_SIZE_3)).to(tl.int32)
        # src[test_persistent_kernels.py:N]: result2[tile2] = y[tile2] + 1.0
        load_1 = tl.load(y + (indices_2[:, None] * 64 + indices_3[None, :] * 1), None)
        v_2 = 1.0
        v_3 = load_1 + v_2
        tl.store(result2 + (indices_2[:, None] * 64 + indices_3[None, :] * 1), v_3, None)

def multi_loop_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result1 = x.new_empty(x.size())
    result1 = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: result2 = y.new_empty(y.size())
    result2 = y.new_empty(y.size())
    # src[test_persistent_kernels.py:N]: for tile1 in hl.tile(x.size(), block_size=[16, 16]):
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 16]):
    _BLOCK_SIZE_2 = 16
    _BLOCK_SIZE_3 = 16
    # src[test_persistent_kernels.py:N]: for tile2 in hl.tile(y.size(), block_size=[16, 16]):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] + 1.0
    _launcher(_helion_multi_loop_kernel, (triton.cdiv(32, _BLOCK_SIZE_0) * triton.cdiv(64, _BLOCK_SIZE_1) + triton.cdiv(32, _BLOCK_SIZE_2) * triton.cdiv(64, _BLOCK_SIZE_3),), x, result1, y, result2, _BLOCK_SIZE_0, _BLOCK_SIZE_1, _BLOCK_SIZE_2, _BLOCK_SIZE_3, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result1, result2
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_simple_add)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_add_kernel(x, y, result, _NUM_SM: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    total_pids = 128 * 256
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
        num_blocks_0 = 128
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0
        offset_1 = pid_1
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
        load = tl.load(x + (offset_0 * 256 + offset_1 * 1), None)
        load_1 = tl.load(y + (offset_0 * 256 + offset_1 * 1), None)
        v_0 = load + load_1
        tl.store(result + (offset_0 * 256 + offset_1 * 1), v_0, None)

def add_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    # src[test_persistent_kernels.py:N]: for tile in hl.grid(x.size()):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_add_kernel, (_NUM_SM,), x, y, result, _NUM_SM, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_with_l2_grouping_single_loop)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_single_loop_l2_kernel(x, result, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[16, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] * 2.0
    total_pids = tl.cdiv(64, _BLOCK_SIZE_0) * tl.cdiv(128, _BLOCK_SIZE_1)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[16, 16]):
        num_pid_m = tl.cdiv(64, _BLOCK_SIZE_0)
        num_pid_n = tl.cdiv(128, _BLOCK_SIZE_1)
        inner_2d_pid = virtual_pid
        num_pid_in_group = 4 * num_pid_n
        group_id = inner_2d_pid // num_pid_in_group
        first_pid_m = group_id * 4
        group_size_m = min(num_pid_m - first_pid_m, 4)
        pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
        pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] * 2.0
        load = tl.load(x + (indices_0[:, None] * 128 + indices_1[None, :] * 1), None)
        v_0 = 2.0
        v_1 = load * v_0
        tl.store(result + (indices_0[:, None] * 128 + indices_1[None, :] * 1), v_1, None)

def single_loop_l2_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[16, 16]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[16, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] * 2.0
    _launcher(_helion_single_loop_l2_kernel, (_NUM_SM,), x, result, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_interleaved_with_l2_grouping_single_loop)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_single_loop_l2_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[16, 16]):
    num_pid_m = tl.cdiv(64, _BLOCK_SIZE_0)
    num_pid_n = tl.cdiv(128, _BLOCK_SIZE_1)
    inner_2d_pid = tl.program_id(0)
    num_pid_in_group = 4 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 4
    group_size_m = min(num_pid_m - first_pid_m, 4)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    # src[test_persistent_kernels.py:N]: result[tile] = x[tile] * 2.0
    load = tl.load(x + (indices_0[:, None] * 128 + indices_1[None, :] * 1), None)
    v_0 = 2.0
    v_1 = load * v_0
    tl.store(result + (indices_0[:, None] * 128 + indices_1[None, :] * 1), v_1, None)

def single_loop_l2_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[16, 16]):
    _BLOCK_SIZE_0 = 16
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[16, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] * 2.0
    _launcher(_helion_single_loop_l2_kernel, (triton.cdiv(64, _BLOCK_SIZE_0) * triton.cdiv(128, _BLOCK_SIZE_1),), x, result, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_complex_shared_scenario)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_complex_shared_kernel(x, y, result1, z, result2, _NUM_SM: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] * z[tile2]
    total_pids = 6 * 8 + 6 * 8
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        pid_shared = virtual_pid
        # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
        # src[test_persistent_kernels.py:N]:     result1[tile1] = x[tile1] + y[tile1]
        if pid_shared < 6 * 8:
            # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
            num_blocks_0 = 6
            pid_0 = pid_shared % num_blocks_0
            pid_1 = pid_shared // num_blocks_0
            offset_0 = pid_0
            offset_1 = pid_1
            # src[test_persistent_kernels.py:N]: result1[tile1] = x[tile1] + y[tile1]
            load = tl.load(x + (offset_0 * 8 + offset_1 * 1), None)
            load_1 = tl.load(y + (offset_0 * 8 + offset_1 * 1), None)
            v_0 = load + load_1
            tl.store(result1 + (offset_0 * 8 + offset_1 * 1), v_0, None)
        else:
            # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
            pid_shared -= 6 * 8
            num_blocks_1 = 6
            pid_2 = pid_shared % num_blocks_1
            pid_3 = pid_shared // num_blocks_1
            offset_2 = pid_2
            offset_3 = pid_3
            # src[test_persistent_kernels.py:N]: result2[tile2] = y[tile2] * z[tile2]
            load_2 = tl.load(y + (offset_2 * 8 + offset_3 * 1), None)
            load_3 = tl.load(z + (offset_2 * 8 + offset_3 * 1), None)
            v_1 = load_2 * load_3
            tl.store(result2 + (offset_2 * 8 + offset_3 * 1), v_1, None)

def complex_shared_kernel(x: torch.Tensor, y: torch.Tensor, z: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result1 = x.new_empty(x.size())
    result1 = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: result2 = y.new_empty(y.size())
    result2 = y.new_empty(y.size())
    # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] * z[tile2]
    _launcher(_helion_complex_shared_kernel, (_NUM_SM,), x, y, result1, z, result2, _NUM_SM, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result1, result2
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_complex_shared_scenario)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_complex_shared_kernel(x, y, result1, z, result2, _NUM_SM: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] * z[tile2]
    total_pids = 6 * 8 + 6 * 8
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        pid_shared = virtual_pid
        # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
        # src[test_persistent_kernels.py:N]:     result1[tile1] = x[tile1] + y[tile1]
        if pid_shared < 6 * 8:
            # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
            num_blocks_0 = 6
            pid_0 = pid_shared % num_blocks_0
            pid_1 = pid_shared // num_blocks_0
            offset_0 = pid_0
            offset_1 = pid_1
            # src[test_persistent_kernels.py:N]: result1[tile1] = x[tile1] + y[tile1]
            load = tl.load(x + (offset_0 * 8 + offset_1 * 1), None)
            load_1 = tl.load(y + (offset_0 * 8 + offset_1 * 1), None)
            v_0 = load + load_1
            tl.store(result1 + (offset_0 * 8 + offset_1 * 1), v_0, None)
        else:
            # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
            pid_shared -= 6 * 8
            num_blocks_1 = 6
            pid_2 = pid_shared % num_blocks_1
            pid_3 = pid_shared // num_blocks_1
            offset_2 = pid_2
            offset_3 = pid_3
            # src[test_persistent_kernels.py:N]: result2[tile2] = y[tile2] * z[tile2]
            load_2 = tl.load(y + (offset_2 * 8 + offset_3 * 1), None)
            load_3 = tl.load(z + (offset_2 * 8 + offset_3 * 1), None)
            v_1 = load_2 * load_3
            tl.store(result2 + (offset_2 * 8 + offset_3 * 1), v_1, None)

def complex_shared_kernel(x: torch.Tensor, y: torch.Tensor, z: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result1 = x.new_empty(x.size())
    result1 = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: result2 = y.new_empty(y.size())
    result2 = y.new_empty(y.size())
    # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] * z[tile2]
    _launcher(_helion_complex_shared_kernel, (_NUM_SM,), x, y, result1, z, result2, _NUM_SM, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result1, result2
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_complex_shared_scenario)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_complex_shared_kernel(x, y, result1, z, result2):
    # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
    # src[test_persistent_kernels.py:N]:     result1[tile1] = x[tile1] + y[tile1]
    pid_shared = tl.program_id(0)
    if pid_shared < 6 * 8:
        # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
        num_blocks_0 = 6
        pid_0 = pid_shared % num_blocks_0
        pid_1 = pid_shared // num_blocks_0
        offset_0 = pid_0
        offset_1 = pid_1
        # src[test_persistent_kernels.py:N]: result1[tile1] = x[tile1] + y[tile1]
        load = tl.load(x + (offset_0 * 8 + offset_1 * 1), None)
        load_1 = tl.load(y + (offset_0 * 8 + offset_1 * 1), None)
        v_0 = load + load_1
        tl.store(result1 + (offset_0 * 8 + offset_1 * 1), v_0, None)
    else:
        # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
        pid_shared -= 6 * 8
        num_blocks_1 = 6
        pid_2 = pid_shared % num_blocks_1
        pid_3 = pid_shared // num_blocks_1
        offset_2 = pid_2
        offset_3 = pid_3
        # src[test_persistent_kernels.py:N]: result2[tile2] = y[tile2] * z[tile2]
        load_2 = tl.load(y + (offset_2 * 8 + offset_3 * 1), None)
        load_3 = tl.load(z + (offset_2 * 8 + offset_3 * 1), None)
        v_1 = load_2 * load_3
        tl.store(result2 + (offset_2 * 8 + offset_3 * 1), v_1, None)

def complex_shared_kernel(x: torch.Tensor, y: torch.Tensor, z: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result1 = x.new_empty(x.size())
    result1 = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: result2 = y.new_empty(y.size())
    result2 = y.new_empty(y.size())
    # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] * z[tile2]
    _launcher(_helion_complex_shared_kernel, (6 * 8 + 6 * 8,), x, y, result1, z, result2, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result1, result2
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_range_config_options)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid, loop_unroll_factor=2):
        # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + 1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_range_config_options)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM, num_stages=3):
        # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + 1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_range_config_options)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid, disallow_acc_multi_buffer=True):
        # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + 1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_range_config_options)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM, flatten=True):
        # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + 1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_range_config_options)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, x_size_0, x_size_1, result_stride_0, result_stride_1, x_stride_0, x_stride_1, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    total_pids = tl.cdiv(x_size_0, _BLOCK_SIZE_0) * tl.cdiv(x_size_1, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid, loop_unroll_factor=2, num_stages=3, disallow_acc_multi_buffer=False, flatten=False):
        # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
        num_blocks_0 = tl.cdiv(x_size_0, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < x_size_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < x_size_1
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + 1
        load = tl.load(x + (indices_0[:, None] * x_stride_0 + indices_1[None, :] * x_stride_1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * result_stride_0 + indices_1[None, :] * result_stride_1), v_1, mask_0[:, None] & mask_1[None, :])

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, x.size(0), x.size(1), result.stride(0), result.stride(1), x.stride(0), x.stride(1), _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_shared_program_id)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_kernel(x, result1, y, result2, _NUM_SM: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] * 3
    total_pids = 8 * 12 + 8 * 12
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        pid_shared = virtual_pid
        # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
        # src[test_persistent_kernels.py:N]:     result1[tile1] = x[tile1] * 2
        if pid_shared < 8 * 12:
            # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
            num_blocks_0 = 8
            pid_0 = pid_shared % num_blocks_0
            pid_1 = pid_shared // num_blocks_0
            offset_0 = pid_0
            offset_1 = pid_1
            # src[test_persistent_kernels.py:N]: result1[tile1] = x[tile1] * 2
            load = tl.load(x + (offset_0 * 12 + offset_1 * 1), None)
            v_0 = 2.0
            v_1 = load * v_0
            tl.store(result1 + (offset_0 * 12 + offset_1 * 1), v_1, None)
        else:
            # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
            pid_shared -= 8 * 12
            num_blocks_1 = 8
            pid_2 = pid_shared % num_blocks_1
            pid_3 = pid_shared // num_blocks_1
            offset_2 = pid_2
            offset_3 = pid_3
            # src[test_persistent_kernels.py:N]: result2[tile2] = y[tile2] * 3
            load_1 = tl.load(y + (offset_2 * 12 + offset_3 * 1), None)
            v_2 = 3.0
            v_3 = load_1 * v_2
            tl.store(result2 + (offset_2 * 12 + offset_3 * 1), v_3, None)

def multi_loop_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result1 = x.new_empty(x.size())
    result1 = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: result2 = y.new_empty(y.size())
    result2 = y.new_empty(y.size())
    # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] * 3
    _launcher(_helion_multi_loop_kernel, (_NUM_SM,), x, result1, y, result2, _NUM_SM, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result1, result2
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_shared_program_id)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_kernel(x, result1, y, result2, _NUM_SM: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] * 3
    total_pids = 8 * 12 + 8 * 12
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        pid_shared = virtual_pid
        # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
        # src[test_persistent_kernels.py:N]:     result1[tile1] = x[tile1] * 2
        if pid_shared < 8 * 12:
            # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
            num_blocks_0 = 8
            pid_0 = pid_shared % num_blocks_0
            pid_1 = pid_shared // num_blocks_0
            offset_0 = pid_0
            offset_1 = pid_1
            # src[test_persistent_kernels.py:N]: result1[tile1] = x[tile1] * 2
            load = tl.load(x + (offset_0 * 12 + offset_1 * 1), None)
            v_0 = 2.0
            v_1 = load * v_0
            tl.store(result1 + (offset_0 * 12 + offset_1 * 1), v_1, None)
        else:
            # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
            pid_shared -= 8 * 12
            num_blocks_1 = 8
            pid_2 = pid_shared % num_blocks_1
            pid_3 = pid_shared // num_blocks_1
            offset_2 = pid_2
            offset_3 = pid_3
            # src[test_persistent_kernels.py:N]: result2[tile2] = y[tile2] * 3
            load_1 = tl.load(y + (offset_2 * 12 + offset_3 * 1), None)
            v_2 = 3.0
            v_3 = load_1 * v_2
            tl.store(result2 + (offset_2 * 12 + offset_3 * 1), v_3, None)

def multi_loop_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result1 = x.new_empty(x.size())
    result1 = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: result2 = y.new_empty(y.size())
    result2 = y.new_empty(y.size())
    # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] * 3
    _launcher(_helion_multi_loop_kernel, (_NUM_SM,), x, result1, y, result2, _NUM_SM, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result1, result2
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_shared_program_id)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_loop_kernel(x, result1, y, result2):
    # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
    # src[test_persistent_kernels.py:N]:     result1[tile1] = x[tile1] * 2
    pid_shared = tl.program_id(0)
    if pid_shared < 8 * 12:
        # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
        num_blocks_0 = 8
        pid_0 = pid_shared % num_blocks_0
        pid_1 = pid_shared // num_blocks_0
        offset_0 = pid_0
        offset_1 = pid_1
        # src[test_persistent_kernels.py:N]: result1[tile1] = x[tile1] * 2
        load = tl.load(x + (offset_0 * 12 + offset_1 * 1), None)
        v_0 = 2.0
        v_1 = load * v_0
        tl.store(result1 + (offset_0 * 12 + offset_1 * 1), v_1, None)
    else:
        # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
        pid_shared -= 8 * 12
        num_blocks_1 = 8
        pid_2 = pid_shared % num_blocks_1
        pid_3 = pid_shared // num_blocks_1
        offset_2 = pid_2
        offset_3 = pid_3
        # src[test_persistent_kernels.py:N]: result2[tile2] = y[tile2] * 3
        load_1 = tl.load(y + (offset_2 * 12 + offset_3 * 1), None)
        v_2 = 3.0
        v_3 = load_1 * v_2
        tl.store(result2 + (offset_2 * 12 + offset_3 * 1), v_3, None)

def multi_loop_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result1 = x.new_empty(x.size())
    result1 = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: result2 = y.new_empty(y.size())
    result2 = y.new_empty(y.size())
    # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] * 3
    _launcher(_helion_multi_loop_kernel, (8 * 12 + 8 * 12,), x, result1, y, result2, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result1, result2
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_tensor_descriptor_indexing)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

# src[test_persistent_kernels.py:N]: def tensor_descriptor_kernel(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:
# src[test_persistent_kernels.py:N]:     result = x.new_empty(x.size())
# src[test_persistent_kernels.py:N]:     for tile in hl.tile(x.size(), block_size=[32, 32]):
# src[test_persistent_kernels.py:N-N]: ...
helion.runtime.set_triton_allocator()

@triton.jit
def _helion_tensor_descriptor_kernel(x, y, result, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
    x_desc = tl.make_tensor_descriptor(x, [64, 128], [128, 1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1])
    y_desc = tl.make_tensor_descriptor(y, [64, 128], [128, 1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1])
    result_desc = tl.make_tensor_descriptor(result, [64, 128], [128, 1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1])
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 32]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    total_pids = tl.cdiv(64, _BLOCK_SIZE_0) * tl.cdiv(128, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 32]):
        num_blocks_0 = tl.cdiv(64, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
        load = x_desc.load([offset_0, offset_1])
        load_1 = y_desc.load([offset_0, offset_1])
        v_0 = load + load_1
        result_desc.store([offset_0, offset_1], v_0)

def tensor_descriptor_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 32]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 32]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_tensor_descriptor_kernel, (_NUM_SM,), x, y, result, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_tensor_descriptor_indexing)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

# src[test_persistent_kernels.py:N]: def tensor_descriptor_kernel(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:
# src[test_persistent_kernels.py:N]:     result = x.new_empty(x.size())
# src[test_persistent_kernels.py:N]:     for tile in hl.tile(x.size(), block_size=[32, 32]):
# src[test_persistent_kernels.py:N-N]: ...
helion.runtime.set_triton_allocator()

@triton.jit
def _helion_tensor_descriptor_kernel(x, y, result, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
    x_desc = tl.make_tensor_descriptor(x, [64, 128], [128, 1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1])
    y_desc = tl.make_tensor_descriptor(y, [64, 128], [128, 1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1])
    result_desc = tl.make_tensor_descriptor(result, [64, 128], [128, 1], [_BLOCK_SIZE_0, _BLOCK_SIZE_1])
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 32]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    total_pids = tl.cdiv(64, _BLOCK_SIZE_0) * tl.cdiv(128, _BLOCK_SIZE_1)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 32]):
        num_blocks_0 = tl.cdiv(64, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        offset_1 = pid_1 * _BLOCK_SIZE_1
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
        load = x_desc.load([offset_0, offset_1])
        load_1 = y_desc.load([offset_0, offset_1])
        v_0 = load + load_1
        result_desc.store([offset_0, offset_1], v_0)

def tensor_descriptor_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 32]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 32]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_tensor_descriptor_kernel, (_NUM_SM,), x, y, result, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_kernels_with_warp_specialize)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    total_pids = tl.cdiv(64, _BLOCK_SIZE_0) * tl.cdiv(96, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid, warp_specialize=True):
        # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
        num_blocks_0 = tl.cdiv(64, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + 1
        load = tl.load(x + (indices_0[:, None] * 96 + indices_1[None, :] * 1), None)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * 96 + indices_1[None, :] * 1), v_1, None)

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=2)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_loop_variable_names)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    total_pids = tl.cdiv(32, _BLOCK_SIZE_0) * tl.cdiv(48, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
        num_blocks_0 = tl.cdiv(32, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + 1
        load = tl.load(x + (indices_0[:, None] * 48 + indices_1[None, :] * 1), None)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * 48 + indices_1[None, :] * 1), v_1, None)

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_persistent_loop_variable_names)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_test_kernel(x, result, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    total_pids = tl.cdiv(32, _BLOCK_SIZE_0) * tl.cdiv(48, _BLOCK_SIZE_1)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
        num_blocks_0 = tl.cdiv(32, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + 1
        load = tl.load(x + (indices_0[:, None] * 48 + indices_1[None, :] * 1), None)
        v_0 = 1.0
        v_1 = load + v_0
        tl.store(result + (indices_0[:, None] * 48 + indices_1[None, :] * 1), v_1, None)

def test_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + 1
    _launcher(_helion_test_kernel, (_NUM_SM,), x, result, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_shared_program_id_with_persistent_basic_functionality)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_multi_add_kernel(x, result1, y, result2, x_size_0, x_size_1, y_size_0, y_size_1, result1_stride_0, result1_stride_1, result2_stride_0, result2_stride_1, x_stride_0, x_stride_1, y_stride_0, y_stride_1, _NUM_SM: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] * 2.0
    total_pids = x_size_0 * x_size_1 + y_size_0 * y_size_1
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        pid_shared = virtual_pid
        # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
        # src[test_persistent_kernels.py:N]:     result1[tile1] = x[tile1] + 1.0
        if pid_shared < x_size_0 * x_size_1:
            # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
            num_blocks_0 = x_size_0
            pid_0 = pid_shared % num_blocks_0
            pid_1 = pid_shared // num_blocks_0
            offset_0 = pid_0
            offset_1 = pid_1
            # src[test_persistent_kernels.py:N]: result1[tile1] = x[tile1] + 1.0
            load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1), None)
            v_0 = 1.0
            v_1 = load + v_0
            tl.store(result1 + (offset_0 * result1_stride_0 + offset_1 * result1_stride_1), v_1, None)
        else:
            # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
            pid_shared -= x_size_0 * x_size_1
            num_blocks_1 = y_size_0
            pid_2 = pid_shared % num_blocks_1
            pid_3 = pid_shared // num_blocks_1
            offset_2 = pid_2
            offset_3 = pid_3
            # src[test_persistent_kernels.py:N]: result2[tile2] = y[tile2] * 2.0
            load_1 = tl.load(y + (offset_2 * y_stride_0 + offset_3 * y_stride_1), None)
            v_2 = 2.0
            v_3 = load_1 * v_2
            tl.store(result2 + (offset_2 * result2_stride_0 + offset_3 * result2_stride_1), v_3, None)

def multi_add_kernel(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result1 = x.new_empty(x.size())
    result1 = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: result2 = y.new_empty(y.size())
    result2 = y.new_empty(y.size())
    # src[test_persistent_kernels.py:N]: for tile1 in hl.grid(x.size()):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    # src[test_persistent_kernels.py:N]: for tile2 in hl.grid(y.size()):
    # src[test_persistent_kernels.py:N]:     result2[tile2] = y[tile2] * 2.0
    _launcher(_helion_multi_add_kernel, (_NUM_SM,), x, result1, y, result2, x.size(0), x.size(1), y.size(0), y.size(1), result1.stride(0), result1.stride(1), result2.stride(0), result2.stride(1), x.stride(0), x.stride(1), y.stride(0), y.stride(1), _NUM_SM, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result1, result2
    return (result1, result2)

--- assertExpectedJournal(TestPersistentKernels.test_simple_persistent_kernels_work)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_simple_add(x, y, result, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    total_pids = tl.cdiv(8, _BLOCK_SIZE_0) * tl.cdiv(12, _BLOCK_SIZE_1)
    block_size = tl.cdiv(total_pids, _NUM_SM)
    start_pid = tl.program_id(0) * block_size
    end_pid = tl.minimum(start_pid + block_size, total_pids)
    for virtual_pid in tl.range(start_pid, end_pid):
        # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
        num_blocks_0 = tl.cdiv(8, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < 8
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < 12
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
        load = tl.load(x + (indices_0[:, None] * 12 + indices_1[None, :] * 1), mask_0[:, None] & mask_1[None, :], other=0)
        load_1 = tl.load(y + (indices_0[:, None] * 12 + indices_1[None, :] * 1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = load + load_1
        tl.store(result + (indices_0[:, None] * 12 + indices_1[None, :] * 1), v_0, mask_0[:, None] & mask_1[None, :])

def simple_add(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_simple_add, (_NUM_SM,), x, y, result, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result

--- assertExpectedJournal(TestPersistentKernels.test_simple_persistent_kernels_work)
from __future__ import annotations

import torch
import helion
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_simple_add(x, y, result, _NUM_SM: tl.constexpr, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    total_pids = tl.cdiv(8, _BLOCK_SIZE_0) * tl.cdiv(12, _BLOCK_SIZE_1)
    for virtual_pid in tl.range(tl.program_id(0), total_pids, _NUM_SM):
        # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
        num_blocks_0 = tl.cdiv(8, _BLOCK_SIZE_0)
        pid_0 = virtual_pid % num_blocks_0
        pid_1 = virtual_pid // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
        mask_0 = indices_0 < 8
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
        mask_1 = indices_1 < 12
        # src[test_persistent_kernels.py:N]: result[tile] = x[tile] + y[tile]
        load = tl.load(x + (indices_0[:, None] * 12 + indices_1[None, :] * 1), mask_0[:, None] & mask_1[None, :], other=0)
        load_1 = tl.load(y + (indices_0[:, None] * 12 + indices_1[None, :] * 1), mask_0[:, None] & mask_1[None, :], other=0)
        v_0 = load + load_1
        tl.store(result + (indices_0[:, None] * 12 + indices_1[None, :] * 1), v_0, mask_0[:, None] & mask_1[None, :])

def simple_add(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    # src[test_persistent_kernels.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    _NUM_SM = helion.runtime.get_num_sm(x.device)
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    # src[test_persistent_kernels.py:N]: for tile in hl.tile(x.size(), block_size=[32, 16]):
    # src[test_persistent_kernels.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_simple_add, (_NUM_SM,), x, y, result, _NUM_SM, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=1)
    # src[test_persistent_kernels.py:N]: return result
    return result
