This file is automatically generated by assertExpectedJournal calls in test_associative_scan.py.
Update expected outputs by running tests with the EXPECTTEST_ACCEPT=1 environment variable set.

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_argmax_tuple_format)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def argmax_combine_tuple_fn_0(param_0, param_1, param_2, param_3):
    v_0 = param_2 > param_0
    v_1 = tl.where(v_0, param_2, param_0)
    v_2 = tl.where(v_0, param_3, param_1)
    return (v_1, v_2)

@triton.jit
def _helion_cumulative_argmax_tuple_kernel(input_data, positions, max_values, max_indices, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    mask_1 = indices_1 < 3
    vals = tl.load(input_data + (indices_0[:, None] * 3 + indices_1[None, :] * 1), mask_1[None, :], other=0)
    load_1 = tl.load(positions + indices_1 * 1, mask_1, other=0)
    v_0 = tl.cast(load_1, tl.float32)
    unsqueeze = v_0[None, :]
    indices = tl.broadcast_to(unsqueeze, [_BLOCK_SIZE_0, _RDIM_SIZE_1])
    out_vals = tl.associative_scan((vals, indices), 1, argmax_combine_tuple_fn_0)[0]
    out_indices = tl.associative_scan((vals, indices), 1, argmax_combine_tuple_fn_0)[1]
    tl.store(max_values + (indices_0[:, None] * 3 + indices_1[None, :] * 1), out_vals, mask_1[None, :])
    v_1 = tl.cast(out_indices, tl.int32)
    tl.store(max_indices + (indices_0[:, None] * 3 + indices_1[None, :] * 1), v_1, mask_1[None, :])

def cumulative_argmax_tuple_kernel(input_data: torch.Tensor, positions: torch.Tensor, *, _launcher=_default_launcher):
    max_values = torch.zeros_like(input_data)
    max_indices = torch.zeros_like(input_data, dtype=torch.int32)
    _BLOCK_SIZE_0 = 4
    _RDIM_SIZE_1 = 4
    _launcher(_helion_cumulative_argmax_tuple_kernel, (triton.cdiv(4, _BLOCK_SIZE_0),), input_data, positions, max_values, max_indices, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return (max_values, max_indices)

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_basic_addition)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_scan_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < 3
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), mask_0[:, None], other=0)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, mask_0[:, None])

def test_scan_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 4
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_scan_kernel, (triton.cdiv(3, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_code_generation)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_codegen_kernel(x, result, _RDIM_SIZE_1: tl.constexpr):
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    mask_1 = indices_1 < 3
    row_data = tl.load(x + indices_1[None, :] * 1, mask_1[None, :], other=0)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(result + indices_1[None, :] * 1, _associative_scan, mask_1[None, :])

def test_codegen_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_codegen_kernel, (1,), x, result, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_cumulative_argmax)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def argmax_combine_fn_0(param_0, param_1, param_2, param_3):
    v_0 = param_2 > param_0
    v_1 = tl.where(v_0, param_2, param_0)
    v_2 = tl.where(v_0, param_3, param_1)
    return (v_1, v_2)

@triton.jit
def _helion_cumulative_argmax_kernel(input_data, positions, max_values, max_indices, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    mask_1 = indices_1 < 3
    vals = tl.load(input_data + (indices_0[:, None] * 3 + indices_1[None, :] * 1), mask_1[None, :], other=0)
    load_1 = tl.load(positions + indices_1 * 1, mask_1, other=0)
    v_0 = tl.cast(load_1, tl.float32)
    unsqueeze = v_0[None, :]
    indices = tl.broadcast_to(unsqueeze, [_BLOCK_SIZE_0, _RDIM_SIZE_1])
    out_vals = tl.associative_scan((vals, indices), 1, argmax_combine_fn_0)[0]
    out_indices = tl.associative_scan((vals, indices), 1, argmax_combine_fn_0)[1]
    tl.store(max_values + (indices_0[:, None] * 3 + indices_1[None, :] * 1), out_vals, mask_1[None, :])
    v_1 = tl.cast(out_indices, tl.int32)
    tl.store(max_indices + (indices_0[:, None] * 3 + indices_1[None, :] * 1), v_1, mask_1[None, :])

def cumulative_argmax_kernel(input_data: torch.Tensor, positions: torch.Tensor, *, _launcher=_default_launcher):
    max_values = torch.zeros_like(input_data)
    max_indices = torch.zeros_like(input_data, dtype=torch.int32)
    _BLOCK_SIZE_0 = 4
    _RDIM_SIZE_1 = 4
    _launcher(_helion_cumulative_argmax_kernel, (triton.cdiv(4, _BLOCK_SIZE_0),), input_data, positions, max_values, max_indices, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return (max_values, max_indices)

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_different_dtypes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_dtype_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, None)

def test_dtype_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_dtype_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_different_dtypes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_dtype_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, None)

def test_dtype_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_dtype_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_different_dtypes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_dtype_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, None)

def test_dtype_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_dtype_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_different_dtypes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_dtype_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, None)

def test_dtype_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_dtype_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_different_sizes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_size_kernel(x, result, _RDIM_SIZE_1: tl.constexpr):
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + indices_1[None, :] * 1, None)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(result + indices_1[None, :] * 1, _associative_scan, None)

def test_size_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_size_kernel, (1,), x, result, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_different_sizes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_size_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < 3
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 8 + indices_1[None, :] * 1), mask_0[:, None], other=0)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(result + (indices_0[:, None] * 8 + indices_1[None, :] * 1), _associative_scan, mask_0[:, None])

def test_size_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 4
    _RDIM_SIZE_1 = 8
    _launcher(_helion_test_size_kernel, (triton.cdiv(3, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_different_sizes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_size_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < 5
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 16 + indices_1[None, :] * 1), mask_0[:, None], other=0)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(result + (indices_0[:, None] * 16 + indices_1[None, :] * 1), _associative_scan, mask_0[:, None])

def test_size_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 8
    _RDIM_SIZE_1 = 16
    _launcher(_helion_test_size_kernel, (triton.cdiv(5, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_different_sizes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_size_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    row_data = tl.load(x + indices_0[:, None] * 1, None)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(result + indices_0[:, None] * 1, _associative_scan, None)

def test_size_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _launcher(_helion_test_size_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_different_sizes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_size_kernel(x, result, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0
    indices_0 = offset_0 + tl.zeros([1], tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 1024 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(result + (indices_0[:, None] * 1024 + indices_1[None, :] * 1), _associative_scan, None)

def test_size_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _RDIM_SIZE_1 = 1024
    _launcher(_helion_test_size_kernel, (4,), x, result, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_different_sizes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_size_kernel(x, result, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0
    indices_0 = offset_0 + tl.zeros([1], tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 1024 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(result + (indices_0[:, None] * 1024 + indices_1[None, :] * 1), _associative_scan, None)

def test_size_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _RDIM_SIZE_1 = 1024
    _launcher(_helion_test_size_kernel, (8,), x, result, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_edge_cases)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_single_element(x, result):
    row_data = tl.load(x + tl.zeros([1, 1], tl.int32), None)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(result + tl.zeros([1, 1], tl.int32), _associative_scan, None)

def test_single_element(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _launcher(_helion_test_single_element, (1,), x, result, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_edge_cases)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_single_element(x, result, _RDIM_SIZE_1: tl.constexpr):
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + indices_1[None, :] * 1, None)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(result + indices_1[None, :] * 1, _associative_scan, None)

def test_single_element(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _RDIM_SIZE_1 = 2
    _launcher(_helion_test_single_element, (1,), x, result, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_in_helper_function)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_helper_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    load = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(load, 0, add_combine_fn_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, None)

def test_helper_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_helper_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_jit_decorator_ignored)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def jit_add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_jit_kernel(x, result, _RDIM_SIZE_1: tl.constexpr):
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + indices_1[None, :] * 1, None)
    _associative_scan = tl.associative_scan(row_data, 1, jit_add_combine_fn_0)
    tl.store(result + indices_1[None, :] * 1, _associative_scan, None)

def test_jit_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_jit_kernel, (1,), x, result, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_large_scale)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_large_kernel(x, result, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0
    indices_0 = offset_0 + tl.zeros([1], tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 1024 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(result + (indices_0[:, None] * 1024 + indices_1[None, :] * 1), _associative_scan, None)

def test_large_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _RDIM_SIZE_1 = 1024
    _launcher(_helion_test_large_kernel, (32,), x, result, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_maximum)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from torch._inductor.runtime import triton_helpers
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def max_combine_fn_0(param_0, param_1):
    v_0 = triton_helpers.maximum(param_0, param_1)
    return v_0

@triton.jit
def _helion_test_max_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    mask_1 = indices_1 < 5
    row_data = tl.load(x + (indices_0[:, None] * 5 + indices_1[None, :] * 1), mask_1[None, :], other=0)
    _associative_scan = tl.associative_scan(row_data, 1, max_combine_fn_0)
    tl.store(result + (indices_0[:, None] * 5 + indices_1[None, :] * 1), _associative_scan, mask_1[None, :])

def test_max_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 8
    _launcher(_helion_test_max_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_minimum)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from torch._inductor.runtime import triton_helpers
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def min_combine_fn_0(param_0, param_1):
    v_0 = triton_helpers.minimum(param_0, param_1)
    return v_0

@triton.jit
def _helion_test_min_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    mask_1 = indices_1 < 5
    row_data = tl.load(x + (indices_0[:, None] * 5 + indices_1[None, :] * 1), mask_1[None, :], other=0)
    _associative_scan = tl.associative_scan(row_data, 1, min_combine_fn_0)
    tl.store(result + (indices_0[:, None] * 5 + indices_1[None, :] * 1), _associative_scan, mask_1[None, :])

def test_min_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 8
    _launcher(_helion_test_min_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_multiple_functions)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from torch._inductor.runtime import triton_helpers
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def max_combine_fn_1(param_0, param_1):
    v_0 = triton_helpers.maximum(param_0, param_1)
    return v_0

@triton.jit
def _helion_test_multi_kernel(x, sum_result, max_result, _RDIM_SIZE_1: tl.constexpr):
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + indices_1[None, :] * 1, None)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(sum_result + indices_1[None, :] * 1, _associative_scan, None)
    _associative_scan_1 = tl.associative_scan(_associative_scan, 1, max_combine_fn_1)
    tl.store(max_result + indices_1[None, :] * 1, _associative_scan_1, None)

def test_multi_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    sum_result = torch.empty_like(x)
    max_result = torch.empty_like(x)
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_multi_kernel, (1,), x, sum_result, max_result, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return sum_result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_multiplication)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def mul_combine_fn_0(param_0, param_1):
    v_0 = param_0 * param_1
    return v_0

@triton.jit
def _helion_test_mul_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, mul_combine_fn_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, None)

def test_mul_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_mul_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_reverse)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_reverse_kernel(x, result, _RDIM_SIZE_1: tl.constexpr):
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + indices_1[None, :] * 1, None)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0, reverse=True)
    tl.store(result + indices_1[None, :] * 1, _associative_scan, None)

def test_reverse_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_reverse_kernel, (1,), x, result, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_segmented_reduction)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def segmented_combine_fn_0(param_0, param_1, param_2, param_3):
    v_0 = param_1 == param_3
    v_1 = param_0 + param_2
    v_2 = tl.where(v_0, v_1, param_2)
    return (v_2, param_3)

@triton.jit
def _helion_segmented_scan_kernel(input_data, indices, output, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    num_blocks_0 = tl.cdiv(6, _BLOCK_SIZE_0)
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < 6
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    mask_1 = indices_1 < 3
    vals = tl.load(input_data + (indices_0[:, None] * 3 + indices_1[None, :] * 1), mask_0[:, None] & mask_1[None, :], other=0)
    load_1 = tl.load(indices + indices_0 * 1, mask_0, other=0)
    v_0 = tl.cast(load_1, tl.float32)
    unsqueeze = v_0[:, None]
    idxs = tl.broadcast_to(unsqueeze, [_BLOCK_SIZE_0, _BLOCK_SIZE_1])
    out_vals = tl.associative_scan((vals, idxs), 0, segmented_combine_fn_0)[0]
    tl.store(output + (indices_0[:, None] * 3 + indices_1[None, :] * 1), out_vals, mask_0[:, None] & mask_1[None, :])

def segmented_scan_kernel(indices: torch.Tensor, input_data: torch.Tensor, *, _launcher=_default_launcher):
    E, C = input_data.shape
    output = torch.zeros((E, C), dtype=input_data.dtype, device=input_data.device)
    _BLOCK_SIZE_0 = 8
    _BLOCK_SIZE_1 = 4
    _launcher(_helion_segmented_scan_kernel, (triton.cdiv(6, _BLOCK_SIZE_0) * triton.cdiv(3, _BLOCK_SIZE_1),), input_data, indices, output, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=2)
    return output

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_torch_hops_mapping)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_torch_hops_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, None)

def test_torch_hops_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_torch_hops_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_tuple_args)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def helion_combine_fn_0(param_0, param_1, param_2, param_3):
    v_0 = param_1 == param_3
    v_1 = param_0 + param_2
    v_2 = tl.where(v_0, v_1, param_2)
    return (v_2, param_3)

@triton.jit
def _helion_test_segmented_kernel(input_data, indices, output, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    num_blocks_0 = tl.cdiv(4, _BLOCK_SIZE_0)
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    vals = tl.load(input_data + (indices_0[:, None] * 2 + indices_1[None, :] * 1), None)
    load_1 = tl.load(indices + indices_0 * 1, None)
    unsqueeze = load_1[:, None]
    idxs = tl.broadcast_to(unsqueeze, [_BLOCK_SIZE_0, _BLOCK_SIZE_1])
    out_vals = tl.associative_scan((vals, idxs), 0, helion_combine_fn_0)[0]
    tl.store(output + (indices_0[:, None] * 2 + indices_1[None, :] * 1), out_vals, None)

def test_segmented_kernel(indices: torch.Tensor, input_data: torch.Tensor, *, _launcher=_default_launcher):
    E, C = input_data.shape
    output = torch.zeros((E, C), dtype=input_data.dtype, device=input_data.device)
    _BLOCK_SIZE_0 = 4
    _BLOCK_SIZE_1 = 2
    _launcher(_helion_test_segmented_kernel, (triton.cdiv(4, _BLOCK_SIZE_0) * triton.cdiv(2, _BLOCK_SIZE_1),), input_data, indices, output, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=2)
    return output

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_tuple_format)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def helion_combine_tuple_fn_0(param_0, param_1, param_2, param_3):
    v_0 = param_1 == param_3
    v_1 = param_0 + param_2
    v_2 = tl.where(v_0, v_1, param_2)
    return (v_2, param_3)

@triton.jit
def _helion_test_segmented_tuple_kernel(input_data, indices, output, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    num_blocks_0 = tl.cdiv(4, _BLOCK_SIZE_0)
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = (offset_1 + tl.arange(0, _BLOCK_SIZE_1)).to(tl.int32)
    vals = tl.load(input_data + (indices_0[:, None] * 2 + indices_1[None, :] * 1), None)
    load_1 = tl.load(indices + indices_0 * 1, None)
    unsqueeze = load_1[:, None]
    idxs = tl.broadcast_to(unsqueeze, [_BLOCK_SIZE_0, _BLOCK_SIZE_1])
    out_vals = tl.associative_scan((vals, idxs), 0, helion_combine_tuple_fn_0)[0]
    tl.store(output + (indices_0[:, None] * 2 + indices_1[None, :] * 1), out_vals, None)

def test_segmented_tuple_kernel(indices: torch.Tensor, input_data: torch.Tensor, *, _launcher=_default_launcher):
    E, C = input_data.shape
    output = torch.zeros((E, C), dtype=input_data.dtype, device=input_data.device)
    _BLOCK_SIZE_0 = 4
    _BLOCK_SIZE_1 = 2
    _launcher(_helion_test_segmented_tuple_kernel, (triton.cdiv(4, _BLOCK_SIZE_0) * triton.cdiv(2, _BLOCK_SIZE_1),), input_data, indices, output, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=2)
    return output

--- assertExpectedJournal(TestAssociativeScan.test_associative_scan_type_propagation)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

import test.test_associative_scan as _source_module

@triton.jit
def add_combine_fn_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_type_kernel(x, result, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0
    indices_0 = offset_0 + tl.zeros([1], tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 1024 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, add_combine_fn_0)
    tl.store(result + (indices_0[:, None] * 1024 + indices_1[None, :] * 1), _associative_scan, None)

def test_type_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _RDIM_SIZE_1 = 1024
    _launcher(_helion_test_type_kernel, (16,), x, result, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_cumprod_basic)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def mul_0(param_0, param_1):
    v_0 = param_0 * param_1
    return v_0

@triton.jit
def _helion_test_cumprod_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, mul_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, None)

def test_cumprod_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_cumprod_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_cumprod_different_dtypes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def mul_0(param_0, param_1):
    v_0 = param_0 * param_1
    return v_0

@triton.jit
def _helion_test_cumprod_dtype_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, mul_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, None)

def test_cumprod_dtype_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_cumprod_dtype_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_cumprod_different_dtypes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def mul_0(param_0, param_1):
    v_0 = param_0 * param_1
    return v_0

@triton.jit
def _helion_test_cumprod_dtype_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, mul_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, None)

def test_cumprod_dtype_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_cumprod_dtype_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_cumprod_different_dtypes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def mul_0(param_0, param_1):
    v_0 = param_0 * param_1
    return v_0

@triton.jit
def _helion_test_cumprod_dtype_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, mul_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, None)

def test_cumprod_dtype_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_cumprod_dtype_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_cumprod_different_dtypes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def mul_0(param_0, param_1):
    v_0 = param_0 * param_1
    return v_0

@triton.jit
def _helion_test_cumprod_dtype_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, mul_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, None)

def test_cumprod_dtype_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_cumprod_dtype_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_cumprod_reverse)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def mul_0(param_0, param_1):
    v_0 = param_0 * param_1
    return v_0

@triton.jit
def _helion_test_cumprod_reverse_kernel(x, result, _RDIM_SIZE_1: tl.constexpr):
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + indices_1[None, :] * 1, None)
    _associative_scan = tl.associative_scan(row_data, 1, mul_0, reverse=True)
    tl.store(result + indices_1[None, :] * 1, _associative_scan, None)

def test_cumprod_reverse_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_cumprod_reverse_kernel, (1,), x, result, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_cumsum_basic)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def add_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_cumsum_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, add_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, None)

def test_cumsum_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_cumsum_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_cumsum_cumprod_mixed)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def add_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def mul_1(param_0, param_1):
    v_0 = param_0 * param_1
    return v_0

@triton.jit
def _helion_test_mixed_kernel(x, sum_result, prod_result, _RDIM_SIZE_1: tl.constexpr):
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + indices_1[None, :] * 1, None)
    _associative_scan = tl.associative_scan(row_data, 1, add_0)
    tl.store(sum_result + indices_1[None, :] * 1, _associative_scan, None)
    _associative_scan_1 = tl.associative_scan(_associative_scan, 1, mul_1)
    tl.store(prod_result + indices_1[None, :] * 1, _associative_scan_1, None)

def test_mixed_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    sum_result = torch.empty_like(x)
    prod_result = torch.empty_like(x)
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_mixed_kernel, (1,), x, sum_result, prod_result, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return sum_result

--- assertExpectedJournal(TestAssociativeScan.test_cumsum_different_dtypes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def add_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_cumsum_dtype_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, add_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, None)

def test_cumsum_dtype_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_cumsum_dtype_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_cumsum_different_dtypes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def add_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_cumsum_dtype_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, add_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, None)

def test_cumsum_dtype_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_cumsum_dtype_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_cumsum_different_dtypes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def add_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_cumsum_dtype_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, add_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, None)

def test_cumsum_dtype_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_cumsum_dtype_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_cumsum_different_dtypes)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def add_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_cumsum_dtype_kernel(x, result, _BLOCK_SIZE_0: tl.constexpr, _RDIM_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + (indices_0[:, None] * 4 + indices_1[None, :] * 1), None)
    _associative_scan = tl.associative_scan(row_data, 1, add_0)
    tl.store(result + (indices_0[:, None] * 4 + indices_1[None, :] * 1), _associative_scan, None)

def test_cumsum_dtype_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _BLOCK_SIZE_0 = 2
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_cumsum_dtype_kernel, (triton.cdiv(2, _BLOCK_SIZE_0),), x, result, _BLOCK_SIZE_0, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result

--- assertExpectedJournal(TestAssociativeScan.test_cumsum_reverse)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def add_0(param_0, param_1):
    v_0 = param_0 + param_1
    return v_0

@triton.jit
def _helion_test_cumsum_reverse_kernel(x, result, _RDIM_SIZE_1: tl.constexpr):
    indices_1 = tl.arange(0, _RDIM_SIZE_1).to(tl.int32)
    row_data = tl.load(x + indices_1[None, :] * 1, None)
    _associative_scan = tl.associative_scan(row_data, 1, add_0, reverse=True)
    tl.store(result + indices_1[None, :] * 1, _associative_scan, None)

def test_cumsum_reverse_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    result = torch.empty_like(x)
    _RDIM_SIZE_1 = 4
    _launcher(_helion_test_cumsum_reverse_kernel, (1,), x, result, _RDIM_SIZE_1, num_warps=4, num_stages=2)
    return result
