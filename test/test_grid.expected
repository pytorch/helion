This file is automatically generated by assertExpectedJournal calls in test_grid.py.
Update expected outputs by running tests with the EXPECTTEST_ACCEPT=1 environment variable set.

--- assertExpectedJournal(TestGrid.test_grid_1d)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_grid_1d(x, y, out, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0
    for offset_1 in tl.range(0, 16, _BLOCK_SIZE_1):
        indices_1 = offset_1 + tl.arange(0, _BLOCK_SIZE_1).to(tl.int32)
        for offset_2 in tl.range(0, 4, _BLOCK_SIZE_2):
            indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
            mask_2 = indices_2 < 4
            acc = tl.full([_BLOCK_SIZE_1, _BLOCK_SIZE_2], 0.0, tl.float32)
            for offset_3 in tl.range(0, 32, _BLOCK_SIZE_3):
                indices_3 = offset_3 + tl.arange(0, _BLOCK_SIZE_3).to(tl.int32)
                acc_copy = acc
                acc_copy_0 = acc_copy
                load = tl.load(x + (offset_0 * 512 + indices_1[:, None] * 32 + indices_3[None, :] * 1), None)
                load_1 = tl.load(y + (indices_3[:, None] * 4 + indices_2[None, :] * 1), mask_2[None, :], other=0)
                acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
            v_0 = acc.to(tl.float16)
            tl.store(out + (offset_0 * 64 + indices_1[:, None] * 4 + indices_2[None, :] * 1), v_0, mask_2[None, :])

def grid_1d(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    b, m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.empty(b, m, n, dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    _BLOCK_SIZE_2 = 16
    _BLOCK_SIZE_1 = 16
    _BLOCK_SIZE_3 = 16
    _launcher(_helion_grid_1d, (8,), x, y, out, _BLOCK_SIZE_2, _BLOCK_SIZE_1, _BLOCK_SIZE_3, num_warps=4, num_stages=3)
    return out

--- assertExpectedJournal(TestGrid.test_grid_1d)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_grid_1d(x, y, out, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr, _BLOCK_SIZE_3: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0
    for offset_1 in tl.range(0, 16, _BLOCK_SIZE_1):
        for offset_2 in tl.range(0, 4, _BLOCK_SIZE_2):
            acc = tl.full([_BLOCK_SIZE_1, _BLOCK_SIZE_2], 0.0, tl.float32)
            for offset_3 in tl.range(0, 32, _BLOCK_SIZE_3):
                acc_copy = acc
                acc_copy_0 = acc_copy
                load = tl.reshape(tl.load(tl.make_block_ptr(x, [8, 16, 32], [512, 32, 1], [offset_0, offset_1, offset_3], [1, _BLOCK_SIZE_1, _BLOCK_SIZE_3], [2, 1, 0]), boundary_check=[1, 2], padding_option='zero'), [_BLOCK_SIZE_1, _BLOCK_SIZE_3])
                load_1 = tl.load(tl.make_block_ptr(y, [32, 4], [4, 1], [offset_3, offset_2], [_BLOCK_SIZE_3, _BLOCK_SIZE_2], [1, 0]), boundary_check=[0, 1], padding_option='zero')
                acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
            v_0 = acc.to(tl.float16)
            tl.store(tl.make_block_ptr(out, [8, 16, 4], [64, 4, 1], [offset_0, offset_1, offset_2], [1, _BLOCK_SIZE_1, _BLOCK_SIZE_2], [2, 1, 0]), tl.reshape(v_0, [1, _BLOCK_SIZE_1, _BLOCK_SIZE_2]), boundary_check=[1, 2])

def grid_1d(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    b, m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.empty(b, m, n, dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    _BLOCK_SIZE_2 = 16
    _BLOCK_SIZE_1 = 16
    _BLOCK_SIZE_3 = 16
    _launcher(_helion_grid_1d, (8,), x, y, out, _BLOCK_SIZE_2, _BLOCK_SIZE_1, _BLOCK_SIZE_3, num_warps=4, num_stages=3)
    return out

--- assertExpectedJournal(TestGrid.test_grid_2d_idx_list)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_grid_2d_idx_list(x, y, out, _BLOCK_SIZE_3: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_4: tl.constexpr):
    num_blocks_0 = 3
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0
    offset_0 = pid_0
    offset_1 = pid_1
    for offset_2 in tl.range(0, 64, _BLOCK_SIZE_2):
        indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
        for offset_3 in tl.range(0, 16, _BLOCK_SIZE_3):
            indices_3 = offset_3 + tl.arange(0, _BLOCK_SIZE_3).to(tl.int32)
            acc = tl.full([_BLOCK_SIZE_2, _BLOCK_SIZE_3], 0.0, tl.float32)
            for offset_4 in tl.range(0, 32, _BLOCK_SIZE_4):
                indices_4 = offset_4 + tl.arange(0, _BLOCK_SIZE_4).to(tl.int32)
                acc_copy = acc
                acc_copy_0 = acc_copy
                load = tl.load(x + (offset_0 * 8192 + offset_1 * 2048 + indices_2[:, None] * 32 + indices_4[None, :] * 1), None)
                load_1 = tl.load(y + (indices_4[:, None] * 16 + indices_3[None, :] * 1), None)
                acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
            v_0 = acc.to(tl.float16)
            tl.store(out + (offset_0 * 4096 + offset_1 * 1024 + indices_2[:, None] * 16 + indices_3[None, :] * 1), v_0, None)

def grid_2d_idx_list(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    bi, bj, m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.empty(bi, bj, m, n, dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    _BLOCK_SIZE_3 = 16
    _BLOCK_SIZE_2 = 16
    _BLOCK_SIZE_4 = 16
    _launcher(_helion_grid_2d_idx_list, (3 * 4,), x, y, out, _BLOCK_SIZE_3, _BLOCK_SIZE_2, _BLOCK_SIZE_4, num_warps=4, num_stages=3)
    return out

--- assertExpectedJournal(TestGrid.test_grid_2d_idx_list)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_grid_2d_idx_list(x, y, out, _BLOCK_SIZE_3: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_4: tl.constexpr):
    num_blocks_0 = 3
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0
    offset_0 = pid_0
    offset_1 = pid_1
    for offset_2 in tl.range(0, 64, _BLOCK_SIZE_2):
        for offset_3 in tl.range(0, 16, _BLOCK_SIZE_3):
            acc = tl.full([_BLOCK_SIZE_2, _BLOCK_SIZE_3], 0.0, tl.float32)
            for offset_4 in tl.range(0, 32, _BLOCK_SIZE_4):
                acc_copy = acc
                acc_copy_0 = acc_copy
                load = tl.reshape(tl.load(tl.make_block_ptr(x, [3, 4, 64, 32], [8192, 2048, 32, 1], [offset_0, offset_1, offset_2, offset_4], [1, 1, _BLOCK_SIZE_2, _BLOCK_SIZE_4], [3, 2, 1, 0]), boundary_check=[2, 3], padding_option='zero'), [_BLOCK_SIZE_2, _BLOCK_SIZE_4])
                load_1 = tl.load(tl.make_block_ptr(y, [32, 16], [16, 1], [offset_4, offset_3], [_BLOCK_SIZE_4, _BLOCK_SIZE_3], [1, 0]), boundary_check=[0, 1], padding_option='zero')
                acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
            v_0 = acc.to(tl.float16)
            tl.store(tl.make_block_ptr(out, [3, 4, 64, 16], [4096, 1024, 16, 1], [offset_0, offset_1, offset_2, offset_3], [1, 1, _BLOCK_SIZE_2, _BLOCK_SIZE_3], [3, 2, 1, 0]), tl.reshape(v_0, [1, 1, _BLOCK_SIZE_2, _BLOCK_SIZE_3]), boundary_check=[2, 3])

def grid_2d_idx_list(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    bi, bj, m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.empty(bi, bj, m, n, dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    _BLOCK_SIZE_3 = 32
    _BLOCK_SIZE_2 = 64
    _BLOCK_SIZE_4 = 16
    _launcher(_helion_grid_2d_idx_list, (3 * 4,), x, y, out, _BLOCK_SIZE_3, _BLOCK_SIZE_2, _BLOCK_SIZE_4, num_warps=4, num_stages=3)
    return out

--- assertExpectedJournal(TestGrid.test_grid_2d_idx_nested)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_grid_2d_idx_nested(x, y, out, _BLOCK_SIZE_3: tl.constexpr, _BLOCK_SIZE_2: tl.constexpr, _BLOCK_SIZE_4: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0
    for offset_1 in tl.range(0, 4):
        for offset_2 in tl.range(0, 64, _BLOCK_SIZE_2):
            indices_2 = offset_2 + tl.arange(0, _BLOCK_SIZE_2).to(tl.int32)
            for offset_3 in tl.range(0, 16, _BLOCK_SIZE_3):
                indices_3 = offset_3 + tl.arange(0, _BLOCK_SIZE_3).to(tl.int32)
                acc = tl.full([_BLOCK_SIZE_2, _BLOCK_SIZE_3], 0.0, tl.float32)
                for offset_4 in tl.range(0, 32, _BLOCK_SIZE_4):
                    indices_4 = offset_4 + tl.arange(0, _BLOCK_SIZE_4).to(tl.int32)
                    acc_copy = acc
                    acc_copy_0 = acc_copy
                    load = tl.load(x + (offset_0 * 8192 + offset_1 * 2048 + indices_2[:, None] * 32 + indices_4[None, :] * 1), None)
                    load_1 = tl.load(y + (indices_4[:, None] * 16 + indices_3[None, :] * 1), None)
                    acc = tl.dot(load, load_1, acc=acc_copy_0, input_precision='tf32')
                v_0 = acc.to(tl.float16)
                tl.store(out + (offset_0 * 4096 + offset_1 * 1024 + indices_2[:, None] * 16 + indices_3[None, :] * 1), v_0, None)

def grid_2d_idx_nested(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_launcher):
    bi, bj, m, k = x.size()
    k2, n = y.size()
    assert k == k2, f'size mismatch {k} != {k2}'
    out = torch.empty(bi, bj, m, n, dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    _BLOCK_SIZE_3 = 16
    _BLOCK_SIZE_2 = 16
    _BLOCK_SIZE_4 = 16
    _launcher(_helion_grid_2d_idx_nested, (3,), x, y, out, _BLOCK_SIZE_3, _BLOCK_SIZE_2, _BLOCK_SIZE_4, num_warps=4, num_stages=3)
    return out

--- assertExpectedJournal(TestGrid.test_grid_begin_end)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_grid_begin_end(x, out, out_stride_0, x_stride_0):
    pid_0 = tl.program_id(0)
    begin_0 = 2
    offset_0 = begin_0 + pid_0
    load = tl.load(x + offset_0 * x_stride_0, None)
    v_0 = 2.0
    v_1 = load * v_0
    tl.store(out + offset_0 * out_stride_0, v_1, None)

def grid_begin_end(x: torch.Tensor, *, _launcher=_default_launcher):
    n = x.size(0)
    out = torch.zeros_like(x)
    _launcher(_helion_grid_begin_end, (-4 + n,), x, out, out.stride(0), x.stride(0), num_warps=4, num_stages=3)
    return out

--- assertExpectedJournal(TestGrid.test_grid_begin_end_step)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_grid_begin_end_step(x, out, out_stride_0, x_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    load = tl.load(x + offset_0 * x_stride_0, None)
    v_0 = 2.0
    v_1 = load * v_0
    tl.store(out + offset_0 * out_stride_0, v_1, None)

def grid_begin_end_step(x: torch.Tensor, *, _launcher=_default_launcher):
    n = x.size(0)
    out = torch.zeros_like(x)
    _BLOCK_SIZE_0 = 2
    _launcher(_helion_grid_begin_end_step, (triton.cdiv(n, _BLOCK_SIZE_0),), x, out, out.stride(0), x.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return out

--- assertExpectedJournal(TestGrid.test_grid_end_step_kwarg)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_grid_end_step_kwarg(x, out, out_stride_0, x_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    load = tl.load(x + offset_0 * x_stride_0, None)
    v_0 = 2.0
    v_1 = load * v_0
    tl.store(out + offset_0 * out_stride_0, v_1, None)

def grid_end_step_kwarg(x: torch.Tensor, *, _launcher=_default_launcher):
    n = x.size(0)
    out = torch.zeros_like(x)
    _BLOCK_SIZE_0 = 2
    _launcher(_helion_grid_end_step_kwarg, (triton.cdiv(n, _BLOCK_SIZE_0),), x, out, out.stride(0), x.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return out

--- assertExpectedJournal(TestGrid.test_grid_multidim_begin_end)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_grid_multidim_begin_end(x, out, out_stride_0, out_stride_1, x_stride_0, x_stride_1, m):
    num_blocks_0 = -2 + m
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0
    begin_0 = 1
    offset_0 = begin_0 + pid_0
    begin_1 = 1
    offset_1 = begin_1 + pid_1
    load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1), None)
    v_0 = 2.0
    v_1 = load * v_0
    tl.store(out + (offset_0 * out_stride_0 + offset_1 * out_stride_1), v_1, None)

def grid_multidim_begin_end(x: torch.Tensor, *, _launcher=_default_launcher):
    m, n = x.size()
    out = torch.zeros_like(x)
    _launcher(_helion_grid_multidim_begin_end, ((-2 + m) * (-2 + n),), x, out, out.stride(0), out.stride(1), x.stride(0), x.stride(1), m, num_warps=4, num_stages=3)
    return out

--- assertExpectedJournal(TestGrid.test_grid_multidim_begin_end_step)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_grid_multidim_begin_end_step(x, out, out_stride_0, out_stride_1, x_stride_0, x_stride_1, m, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    num_blocks_0 = tl.cdiv(m, _BLOCK_SIZE_0)
    pid_0 = tl.program_id(0) % num_blocks_0
    pid_1 = tl.program_id(0) // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    offset_1 = pid_1 * _BLOCK_SIZE_1
    load = tl.load(x + (offset_0 * x_stride_0 + offset_1 * x_stride_1), None)
    v_0 = 2.0
    v_1 = load * v_0
    tl.store(out + (offset_0 * out_stride_0 + offset_1 * out_stride_1), v_1, None)

def grid_multidim_begin_end_step(x: torch.Tensor, *, _launcher=_default_launcher):
    m, n = x.size()
    out = torch.zeros_like(x)
    _BLOCK_SIZE_0 = 2
    _BLOCK_SIZE_1 = 3
    _launcher(_helion_grid_multidim_begin_end_step, (triton.cdiv(m, _BLOCK_SIZE_0) * triton.cdiv(n, _BLOCK_SIZE_1),), x, out, out.stride(0), out.stride(1), x.stride(0), x.stride(1), m, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return out

--- assertExpectedJournal(TestGrid.test_range_with_step)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_range_step_kernel(out, x, out_stride_0, x_stride_0, batch, _BLOCK_SIZE_0: tl.constexpr, _BLOCK_SIZE_1: tl.constexpr):
    pid_0 = tl.program_id(0)
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    mask_0 = indices_0 < batch
    for offset_1 in tl.range(1, 10, _BLOCK_SIZE_1):
        load = tl.load(out + indices_0 * out_stride_0, mask_0, other=0)
        load_1 = tl.load(x + indices_0 * x_stride_0, mask_0, other=0)
        v_0 = offset_1.to(tl.float32)
        v_1 = load_1 / v_0
        v_2 = load + v_1
        tl.store(out + indices_0 * out_stride_0, v_2, mask_0)

def range_step_kernel(x: torch.Tensor, *, _launcher=_default_launcher):
    batch = x.size(0)
    out = x.new_zeros(batch)
    _BLOCK_SIZE_0 = 8
    _BLOCK_SIZE_1 = 2
    _launcher(_helion_range_step_kernel, (triton.cdiv(batch, _BLOCK_SIZE_0),), out, x, out.stride(0), x.stride(0), batch, _BLOCK_SIZE_0, _BLOCK_SIZE_1, num_warps=4, num_stages=3)
    return out

--- assertExpectedJournal(TestGrid.test_tile_begin_end)
from __future__ import annotations

import torch
import triton
import triton.language as tl
from helion.runtime import default_launcher as _default_launcher

@triton.jit
def _helion_tile_begin_end(x, out, out_stride_0, x_stride_0, _BLOCK_SIZE_0: tl.constexpr):
    pid_0 = tl.program_id(0)
    begin_0 = 2
    offset_0 = begin_0 + pid_0 * _BLOCK_SIZE_0
    indices_0 = (offset_0 + tl.arange(0, _BLOCK_SIZE_0)).to(tl.int32)
    load = tl.load(x + indices_0 * x_stride_0, None)
    v_0 = 2.0
    v_1 = load * v_0
    tl.store(out + indices_0 * out_stride_0, v_1, None)

def tile_begin_end(x: torch.Tensor, *, _launcher=_default_launcher):
    out = torch.zeros_like(x)
    _BLOCK_SIZE_0 = 4
    _launcher(_helion_tile_begin_end, (triton.cdiv(8, _BLOCK_SIZE_0),), x, out, out.stride(0), x.stride(0), _BLOCK_SIZE_0, num_warps=4, num_stages=3)
    return out
