This file is automatically generated by assertExpectedJournal calls in test_loops.py.
Update expected outputs by running tests with the EXPECTTEST_ACCEPT=1 environment variable set.

--- assertExpectedJournal(TestLoops.test_3d_device_loop0)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_3 = 8
_BLOCK_SIZE_2 = 8
_BLOCK_SIZE_1 = 8

@cute.kernel
def _helion_device_loop_3d(x, out):
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    pid_0 = cute.arch.block_idx()[0]
    offset_0 = pid_0
    indices_0 = offset_0
    # src[test_loops.py:N]: for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:     out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N]:         x[tile_a, tile_b, tile_c, tile_d]
    # src[test_loops.py:N-N]: ...
    for offset_1 in range(cutlass.Int32(0), cutlass.Int32(128), cutlass.Int32(_BLOCK_SIZE_1)):
        indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[0])
        for offset_2 in range(cutlass.Int32(0), cutlass.Int32(128), cutlass.Int32(_BLOCK_SIZE_2)):
            indices_2 = offset_2 + cutlass.Int32(cute.arch.thread_idx()[1])
            for offset_3 in range(cutlass.Int32(0), cutlass.Int32(128), cutlass.Int32(_BLOCK_SIZE_3)):
                indices_3 = offset_3 + cutlass.Int32(cute.arch.thread_idx()[2])
                # src[test_loops.py:N]: x[tile_a, tile_b, tile_c, tile_d]
                load = x[indices_0, indices_1, indices_2, indices_3]
                # src[test_loops.py:N]: out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
                # src[test_loops.py:N]:     x[tile_a, tile_b, tile_c, tile_d]
                # src[test_loops.py:N]: )
                v_0 = cute.math.sin(load)
                out.__setitem__((indices_0, indices_1, indices_2, indices_3), v_0)

def device_loop_3d(x: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: a, b, c, d = x.shape
    a, b, c, d = x.shape
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    # src[test_loops.py:N]:     for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:         out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_device_loop_3d, (128,), x, out, block=(8, 8, 8))
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_3d_device_loop1)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 2
_BLOCK_SIZE_1 = 8
_BLOCK_SIZE_2 = 4

@cute.kernel
def _helion_device_loop_3d(x, out):
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    pid_0 = cute.arch.block_idx()[0]
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    # src[test_loops.py:N]: for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:     out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N]:         x[tile_a, tile_b, tile_c, tile_d]
    # src[test_loops.py:N-N]: ...
    for offset_2 in range(cutlass.Int32(0), cutlass.Int32(128), cutlass.Int32(_BLOCK_SIZE_2)):
        indices_2 = offset_2 + cutlass.Int32(cute.arch.thread_idx()[1])
        for offset_1 in range(cutlass.Int32(0), cutlass.Int32(128), cutlass.Int32(_BLOCK_SIZE_1)):
            indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[2])
            for offset_3 in range(cutlass.Int32(0), cutlass.Int32(128)):
                indices_3 = offset_3
                # src[test_loops.py:N]: x[tile_a, tile_b, tile_c, tile_d]
                load = x[indices_0, indices_1, indices_2, indices_3]
                # src[test_loops.py:N]: out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
                # src[test_loops.py:N]:     x[tile_a, tile_b, tile_c, tile_d]
                # src[test_loops.py:N]: )
                v_0 = cute.math.sin(load)
                out.__setitem__((indices_0, indices_1, indices_2, indices_3), v_0)

def device_loop_3d(x: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: a, b, c, d = x.shape
    a, b, c, d = x.shape
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    _BLOCK_SIZE_0 = 2
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    # src[test_loops.py:N]:     for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:         out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_device_loop_3d, ((128 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0,), x, out, block=(2, 4, 8))
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_3d_device_loop2)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 4
_BLOCK_SIZE_1 = 128

@cute.kernel
def _helion_device_loop_3d(x, out):
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    pid_0 = cute.arch.block_idx()[0]
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    # src[test_loops.py:N]: for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:     out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N]:         x[tile_a, tile_b, tile_c, tile_d]
    # src[test_loops.py:N-N]: ...
    for offset_3 in range(cutlass.Int32(0), cutlass.Int32(128)):
        indices_3 = offset_3
        for offset_1 in range(cutlass.Int32(0), cutlass.Int32(128), cutlass.Int32(_BLOCK_SIZE_1)):
            indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
            for offset_2 in range(cutlass.Int32(0), cutlass.Int32(128)):
                indices_2 = offset_2
                # src[test_loops.py:N]: x[tile_a, tile_b, tile_c, tile_d]
                load = x[indices_0, indices_1, indices_2, indices_3]
                # src[test_loops.py:N]: out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
                # src[test_loops.py:N]:     x[tile_a, tile_b, tile_c, tile_d]
                # src[test_loops.py:N]: )
                v_0 = cute.math.sin(load)
                out.__setitem__((indices_0, indices_1, indices_2, indices_3), v_0)

def device_loop_3d(x: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: a, b, c, d = x.shape
    a, b, c, d = x.shape
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    _BLOCK_SIZE_0 = 4
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    # src[test_loops.py:N]:     for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:         out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_device_loop_3d, ((128 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0,), x, out, block=(4, 128, 1))
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_3d_device_loop3)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 2
_BLOCK_SIZE_2 = 4
_BLOCK_SIZE_1 = 8

@cute.kernel
def _helion_device_loop_3d(x, out):
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    pid_0 = cute.arch.block_idx()[0]
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    # src[test_loops.py:N]: for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:     out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N]:         x[tile_a, tile_b, tile_c, tile_d]
    # src[test_loops.py:N-N]: ...
    for offset_3 in range(cutlass.Int32(0), cutlass.Int32(128)):
        indices_3 = offset_3
        for offset_1 in range(cutlass.Int32(0), cutlass.Int32(128), cutlass.Int32(_BLOCK_SIZE_1)):
            indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
            for offset_2 in range(cutlass.Int32(0), cutlass.Int32(128), cutlass.Int32(_BLOCK_SIZE_2)):
                indices_2 = offset_2 + cutlass.Int32(cute.arch.thread_idx()[2])
                # src[test_loops.py:N]: x[tile_a, tile_b, tile_c, tile_d]
                load = x[indices_0, indices_1, indices_2, indices_3]
                # src[test_loops.py:N]: out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
                # src[test_loops.py:N]:     x[tile_a, tile_b, tile_c, tile_d]
                # src[test_loops.py:N]: )
                v_0 = cute.math.sin(load)
                out.__setitem__((indices_0, indices_1, indices_2, indices_3), v_0)

def device_loop_3d(x: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: a, b, c, d = x.shape
    a, b, c, d = x.shape
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    _BLOCK_SIZE_0 = 2
    # src[test_loops.py:N]: for tile_a in hl.tile(a):
    # src[test_loops.py:N]:     for tile_b, tile_c, tile_d in hl.tile([b, c, d]):
    # src[test_loops.py:N]:         out[tile_a, tile_b, tile_c, tile_d] = torch.sin(
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_device_loop_3d, ((128 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0,), x, out, block=(2, 8, 4))
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_chebyshev_polynomials)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 32
_BLOCK_SIZE_1 = 32

@cute.kernel
def _helion_chebyshev_kernel(x, w, out):
    # src[test_loops.py:N]: for b_tile, c_tile in hl.tile([B, C]):
    num_blocks_0 = (123 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0
    pid_0 = cute.arch.block_idx()[0] % num_blocks_0
    pid_1 = cute.arch.block_idx()[0] // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    mask_0 = indices_0 < 123
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
    # src[test_loops.py:N]: in_x = x[b_tile, c_tile]
    in_x = x[indices_0, indices_1] if mask_0 else cutlass.Float32(0)
    # src[test_loops.py:N]: T0 = hl.full((b_tile, c_tile), 1.0, x.dtype)
    T0 = cutlass.Float32(1.0)
    # src[test_loops.py:N]: T1 = in_x
    in_x_0 = in_x
    # src[test_loops.py:N]: acc = w[0, c_tile][None, :] * T0 + w[1, c_tile][None, :] * T1
    load_1 = w[0, indices_1]
    v_0 = load_1 * T0
    load_2 = w[1, indices_1]
    v_1 = load_2 * in_x_0
    v_2 = v_0 + v_1
    # src[test_loops.py:N]: two_x = 2.0 * in_x
    v_3 = 2.0
    v_4 = in_x * v_3
    # src[test_loops.py:N]: for order in hl.tile(2, N, block_size=1):
    # src[test_loops.py:N]:     new_T = two_x * T1 - T0
    # src[test_loops.py:N]:     acc = acc + w[order, c_tile] * new_T
    # src[test_loops.py:N-N]: ...
    for offset_2 in range(cutlass.Int32(2), cutlass.Int32(5)):
        indices_2 = offset_2
        v_4_copy = v_4
        in_x_0_copy = in_x_0
        T0_copy = T0
        v_2_copy = v_2
        v_4_copy_0 = v_4_copy
        in_x_0_copy_0 = in_x_0_copy
        T0_copy_0 = T0_copy
        v_2_copy_0 = v_2_copy
        # src[test_loops.py:N]: new_T = two_x * T1 - T0
        v_5 = v_4_copy_0 * in_x_0_copy_0
        v_6 = v_5 - T0_copy_0
        # src[test_loops.py:N]: acc = acc + w[order, c_tile] * new_T
        load = w[indices_2, indices_1]
        v_7 = load * v_6
        v_2 = v_2_copy_0 + v_7
        # src[test_loops.py:N]: T0 = T1
        T0 = in_x_0_copy_0
        # src[test_loops.py:N]: T1 = new_T
        in_x_0 = v_6
    # src[test_loops.py:N]: out[b_tile, c_tile] = acc
    out.__setitem__((indices_0, indices_1), v_2) if mask_0 else None

def chebyshev_kernel(x: torch.Tensor, w: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: B, C = x.shape
    B, C = x.shape
    # src[test_loops.py:N]: N, C = w.shape
    N, C = w.shape
    # src[test_loops.py:N]: out = torch.zeros((B, C), device=x.device, dtype=x.dtype)
    out = torch.zeros((B, C), device=x.device, dtype=x.dtype)
    # src[test_loops.py:N]: assert N >= 2, "assume N>= 2 for simplicity"
    assert N >= 2, 'assume N>= 2 for simplicity'
    # src[test_loops.py:N]: for b_tile, c_tile in hl.tile([B, C]):
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    # src[test_loops.py:N]: for b_tile, c_tile in hl.tile([B, C]):
    # src[test_loops.py:N]:     in_x = x[b_tile, c_tile]
    # src[test_loops.py:N]:     T0 = hl.full((b_tile, c_tile), 1.0, x.dtype)
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_chebyshev_kernel, ((123 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((64 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1),), x, w, out, block=(32, 32, 1))
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_data_dependent_bounds1)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_1 = 32
_BLOCK_SIZE_0 = 32

@cute.kernel
def _helion_fn(end, x, out):
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    pid_0 = cute.arch.block_idx()[0]
    offset_1 = pid_0 * _BLOCK_SIZE_1
    indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[0])
    # src[test_loops.py:N]: acc = hl.zeros([tile0, bs])
    acc = cutlass.Float32(0.0)
    # src[test_loops.py:N]: for tile1 in hl.tile(end[0], block_size=bs):
    load = end[0]
    # src[test_loops.py:N]: for tile1 in hl.tile(end[0], block_size=bs):
    # src[test_loops.py:N]:     acc += x[tile0, tile1]
    for offset_0 in range(cutlass.Int32(0), cutlass.Int32(cutlass.Int32(load)), cutlass.Int32(_BLOCK_SIZE_0)):
        indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[1])
        mask_0 = indices_0 < load
        acc_copy = acc
        acc_copy_0 = acc_copy
        # src[test_loops.py:N]: acc += x[tile0, tile1]
        load_1 = x[indices_1, indices_0] if mask_0 else cutlass.Float32(0)
        acc = acc_copy_0 + load_1
    # src[test_loops.py:N]: out[tile0] = acc.sum(-1)
    sum_1 = cutlass.Float32(cute.arch.warp_reduction_sum(acc, threads_in_group=32))
    out.__setitem__((indices_1,), sum_1)

def fn(x: torch.Tensor, end: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: out = x.new_empty([x.size(0)])
    out = x.new_empty([x.size(0)])
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    _BLOCK_SIZE_1 = 32
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    # src[test_loops.py:N]:     acc = hl.zeros([tile0, bs])
    # src[test_loops.py:N]:     for tile1 in hl.tile(end[0], block_size=bs):
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_fn, ((512 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1,), end, x, out, block=(32, 32, 1))
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_data_dependent_bounds2)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 32
_BLOCK_SIZE_1 = 32

@cute.kernel
def _helion_fn(end, x, out):
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    pid_0 = cute.arch.block_idx()[0]
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    # src[test_loops.py:N]: acc = hl.zeros([tile0])
    acc = cutlass.Float32(0.0)
    # src[test_loops.py:N]: for tile1 in hl.tile(end[0]):
    load = end[0]
    # src[test_loops.py:N]: for tile1 in hl.tile(end[0]):
    # src[test_loops.py:N]:     acc += x[tile0, tile1].sum(-1)
    for offset_1 in range(cutlass.Int32(0), cutlass.Int32(cutlass.Int32(load)), cutlass.Int32(_BLOCK_SIZE_1)):
        indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
        mask_1 = indices_1 < load
        acc_copy = acc
        acc_copy_0 = acc_copy
        # src[test_loops.py:N]: acc += x[tile0, tile1].sum(-1)
        load_1 = x[indices_0, indices_1] if mask_1 else cutlass.Float32(0)
        sum_1 = cutlass.Float32(cute.arch.warp_reduction_sum(load_1, threads_in_group=32))
        acc = acc_copy_0 + sum_1
    # src[test_loops.py:N]: out[tile0] = acc
    out.__setitem__((indices_0,), acc)

def fn(x: torch.Tensor, end: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: out = x.new_empty([x.size(0)])
    out = x.new_empty([x.size(0)])
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    _BLOCK_SIZE_0 = 32
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    # src[test_loops.py:N]:     acc = hl.zeros([tile0])
    # src[test_loops.py:N]:     for tile1 in hl.tile(end[0]):
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_fn, ((512 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0,), end, x, out, block=(32, 32, 1))
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_data_dependent_bounds4)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_1 = 32
_BLOCK_SIZE_0 = 32

@cute.kernel
def _helion_fn(begin, end, x, out):
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    pid_0 = cute.arch.block_idx()[0]
    offset_1 = pid_0 * _BLOCK_SIZE_1
    indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[0])
    # src[test_loops.py:N]: acc = hl.zeros([tile0, bs])
    acc = cutlass.Float32(0.0)
    # src[test_loops.py:N]: for tile1 in hl.tile(begin[0], end[0], block_size=bs):
    load = begin[0]
    load_1 = end[0]
    # src[test_loops.py:N]: for tile1 in hl.tile(begin[0], end[0], block_size=bs):
    # src[test_loops.py:N]:     acc += x[tile0, tile1]
    for offset_0 in range(cutlass.Int32(cutlass.Int32(load)), cutlass.Int32(cutlass.Int32(load_1)), cutlass.Int32(_BLOCK_SIZE_0)):
        indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[1])
        mask_0 = indices_0 < load_1
        acc_copy = acc
        acc_copy_0 = acc_copy
        # src[test_loops.py:N]: acc += x[tile0, tile1]
        load_2 = x[indices_1, indices_0] if mask_0 else cutlass.Float32(0)
        acc = acc_copy_0 + load_2
    # src[test_loops.py:N]: out[tile0] = acc.sum(-1)
    sum_1 = cutlass.Float32(cute.arch.warp_reduction_sum(acc, threads_in_group=32))
    out.__setitem__((indices_1,), sum_1)

def fn(x: torch.Tensor, begin: torch.Tensor, end: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: out = x.new_empty([x.size(0)])
    out = x.new_empty([x.size(0)])
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    _BLOCK_SIZE_1 = 32
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    # src[test_loops.py:N]:     acc = hl.zeros([tile0, bs])
    # src[test_loops.py:N]:     for tile1 in hl.tile(begin[0], end[0], block_size=bs):
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_fn, ((512 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1,), begin, end, x, out, block=(32, 32, 1))
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_data_dependent_bounds5)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 32
_BLOCK_SIZE_1 = 32

@cute.kernel
def _helion_fn(begin, end, x, out):
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    pid_0 = cute.arch.block_idx()[0]
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    # src[test_loops.py:N]: acc = hl.zeros([tile0])
    acc = cutlass.Float32(0.0)
    # src[test_loops.py:N]: for (tile1,) in hl.tile([begin[0]], [end[0]]):
    load = begin[0]
    load_1 = end[0]
    # src[test_loops.py:N]: for (tile1,) in hl.tile([begin[0]], [end[0]]):
    # src[test_loops.py:N]:     acc += x[tile0, tile1].sum(-1)
    for offset_1 in range(cutlass.Int32(cutlass.Int32(load)), cutlass.Int32(cutlass.Int32(load_1)), cutlass.Int32(_BLOCK_SIZE_1)):
        indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
        mask_1 = indices_1 < load_1
        acc_copy = acc
        acc_copy_0 = acc_copy
        # src[test_loops.py:N]: acc += x[tile0, tile1].sum(-1)
        load_2 = x[indices_0, indices_1] if mask_1 else cutlass.Float32(0)
        sum_1 = cutlass.Float32(cute.arch.warp_reduction_sum(load_2, threads_in_group=32))
        acc = acc_copy_0 + sum_1
    # src[test_loops.py:N]: out[tile0] = acc
    out.__setitem__((indices_0,), acc)

def fn(x: torch.Tensor, begin: torch.Tensor, end: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: out = x.new_empty([x.size(0)])
    out = x.new_empty([x.size(0)])
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    _BLOCK_SIZE_0 = 32
    # src[test_loops.py:N]: for tile0 in hl.tile(x.size(0)):
    # src[test_loops.py:N]:     acc = hl.zeros([tile0])
    # src[test_loops.py:N]:     for (tile1,) in hl.tile([begin[0]], [end[0]]):
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_fn, ((512 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0,), begin, end, x, out, block=(32, 32, 1))
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_flattened_tile_with_unit_axis)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0_1 = 16

@cute.kernel
def _helion_silu_kernel(x, out):
    # src[test_loops.py:N]: for tile in hl.tile(out.size()):
    pid_flat = cute.arch.block_idx()[0]
    offsets_0_1 = pid_flat * _BLOCK_SIZE_0_1 + cutlass.Int32(cute.arch.thread_idx()[0])
    indices_0 = offsets_0_1 % 1
    indices_1 = offsets_0_1
    mask_0_1 = cutlass.Int32(cute.arch.thread_idx()[0]) < _BLOCK_SIZE_0_1 and offsets_0_1 < 100
    # src[test_loops.py:N]: out[tile] = x[tile] * torch.sigmoid(x[tile])
    load = x[indices_0, indices_1] if mask_0_1 else cutlass.Float16(0)
    load_1 = x[indices_0, indices_1] if mask_0_1 else cutlass.Float16(0)
    v_0 = cutlass.Float16(1.0 / (1.0 + cute.math.exp2(-cutlass.Float32(load_1) * 1.4426950408889634)))
    v_1 = load * v_0
    out.__setitem__((indices_0, indices_1), v_1) if mask_0_1 else None

def silu_kernel(x: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: out = torch.empty_like(x, dtype=x.dtype, device=x.device)
    out = torch.empty_like(x, dtype=x.dtype, device=x.device)
    # src[test_loops.py:N]: for tile in hl.tile(out.size()):
    _BLOCK_SIZE_0_1 = 16
    # src[test_loops.py:N]: for tile in hl.tile(out.size()):
    # src[test_loops.py:N]:     out[tile] = x[tile] * torch.sigmoid(x[tile])
    _launcher(_helion_silu_kernel, ((100 + _BLOCK_SIZE_0_1 - 1) // _BLOCK_SIZE_0_1,), x, out, block=(16, 1, 1))
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_full_with_dynamic_fill_value)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 4
_BLOCK_SIZE_1 = 8

@cute.kernel
def _helion_kernel_with_dynamic_fill(fill_value, x, out):
    # src[test_loops.py:N]: for b_tile, c_tile in hl.tile([B, C]):
    num_blocks_0 = (4 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0
    pid_0 = cute.arch.block_idx()[0] % num_blocks_0
    pid_1 = cute.arch.block_idx()[0] // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
    # src[test_loops.py:N]: filled = hl.full((b_tile, c_tile), fill_value[0], x.dtype)
    load = fill_value[0]
    filled = cutlass.Float32(load)
    # src[test_loops.py:N]: out[b_tile, c_tile] = x[b_tile, c_tile] + filled
    load_1 = x[indices_0, indices_1]
    v_0 = load_1 + filled
    out.__setitem__((indices_0, indices_1), v_0)

def kernel_with_dynamic_fill(x: torch.Tensor, fill_value: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: B, C = x.shape
    B, C = x.shape
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: for b_tile, c_tile in hl.tile([B, C]):
    _BLOCK_SIZE_0 = 4
    _BLOCK_SIZE_1 = 8
    # src[test_loops.py:N]: for b_tile, c_tile in hl.tile([B, C]):
    # src[test_loops.py:N]:     # Use scalar tensor as fill value
    # src[test_loops.py:N]:     filled = hl.full((b_tile, c_tile), fill_value[0], x.dtype)
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_kernel_with_dynamic_fill, ((4 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((8 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1),), fill_value, x, out, block=(4, 8, 1))
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_l2_grouping_3d)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

@cute.kernel
def _helion_add_3d_kernel_l2(x, y, result, _BLOCK_SIZE_0_1_2: cutlass.Constexpr):
    # src[test_loops.py:N]: for tile in hl.grid(x.size()):
    pid_flat = cute.arch.block_idx()[0]
    offsets_0_1_2 = pid_flat * _BLOCK_SIZE_0_1_2 + cutlass.Int32(cute.arch.thread_idx()[0])
    indices_2 = offsets_0_1_2 % 64
    indices_1 = offsets_0_1_2 // 64 % 32
    indices_0 = offsets_0_1_2 // 2048
    mask_0_1_2 = cutlass.Int32(cute.arch.thread_idx()[0]) < _BLOCK_SIZE_0_1_2 and offsets_0_1_2 < 32768
    # src[test_loops.py:N]: result[tile] = x[tile] + y[tile]
    load = x[indices_0, indices_1, indices_2] if mask_0_1_2 else cutlass.Float32(0)
    load_1 = y[indices_0, indices_1, indices_2] if mask_0_1_2 else cutlass.Float32(0)
    v_0 = load + load_1
    result.__setitem__((indices_0, indices_1, indices_2), v_0) if mask_0_1_2 else None

def add_3d_kernel_l2(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_loops.py:N]: for tile in hl.grid(x.size()):
    _BLOCK_SIZE_0_1_2 = 1
    # src[test_loops.py:N]: for tile in hl.grid(x.size()):
    # src[test_loops.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_add_3d_kernel_l2, ((32768 + _BLOCK_SIZE_0_1_2 - 1) // _BLOCK_SIZE_0_1_2,), x, y, result, _BLOCK_SIZE_0_1_2, block=(1, 1, 1))
    # src[test_loops.py:N]: return result
    return result

--- assertExpectedJournal(TestLoops.test_l2_grouping_4d)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

@cute.kernel
def _helion_add_4d_kernel_l2(x, y, result, _BLOCK_SIZE_0_1_2_3: cutlass.Constexpr):
    # src[test_loops.py:N]: for tile in hl.grid(x.size()):
    pid_flat = cute.arch.block_idx()[0]
    offsets_0_1_2_3 = pid_flat * _BLOCK_SIZE_0_1_2_3 + cutlass.Int32(cute.arch.thread_idx()[0])
    indices_3 = offsets_0_1_2_3 % 64
    indices_2 = offsets_0_1_2_3 // 64 % 32
    indices_1 = offsets_0_1_2_3 // 2048 % 16
    indices_0 = offsets_0_1_2_3 // 32768
    mask_0_1_2_3 = cutlass.Int32(cute.arch.thread_idx()[0]) < _BLOCK_SIZE_0_1_2_3 and offsets_0_1_2_3 < 262144
    # src[test_loops.py:N]: result[tile] = x[tile] + y[tile]
    load = x[indices_0, indices_1, indices_2, indices_3] if mask_0_1_2_3 else cutlass.Float32(0)
    load_1 = y[indices_0, indices_1, indices_2, indices_3] if mask_0_1_2_3 else cutlass.Float32(0)
    v_0 = load + load_1
    result.__setitem__((indices_0, indices_1, indices_2, indices_3), v_0) if mask_0_1_2_3 else None

def add_4d_kernel_l2(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_loops.py:N]: for tile in hl.grid(x.size()):
    _BLOCK_SIZE_0_1_2_3 = 1
    # src[test_loops.py:N]: for tile in hl.grid(x.size()):
    # src[test_loops.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_add_4d_kernel_l2, ((262144 + _BLOCK_SIZE_0_1_2_3 - 1) // _BLOCK_SIZE_0_1_2_3,), x, y, result, _BLOCK_SIZE_0_1_2_3, block=(1, 1, 1))
    # src[test_loops.py:N]: return result
    return result

--- assertExpectedJournal(TestLoops.test_l2_grouping_with_loop_order)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

@cute.kernel
def _helion_add_3d_kernel_reordered(x, y, result, _BLOCK_SIZE_0_1_2: cutlass.Constexpr):
    # src[test_loops.py:N]: for tile in hl.grid(x.size()):
    pid_flat = cute.arch.block_idx()[0]
    offsets_0_1_2 = pid_flat * _BLOCK_SIZE_0_1_2 + cutlass.Int32(cute.arch.thread_idx()[0])
    indices_0 = offsets_0_1_2 % 8
    indices_1 = offsets_0_1_2 // 8 % 16
    indices_2 = offsets_0_1_2 // 128
    mask_0_1_2 = cutlass.Int32(cute.arch.thread_idx()[0]) < _BLOCK_SIZE_0_1_2 and offsets_0_1_2 < 4096
    # src[test_loops.py:N]: result[tile] = x[tile] + y[tile]
    load = x[indices_0, indices_1, indices_2] if mask_0_1_2 else cutlass.Float32(0)
    load_1 = y[indices_0, indices_1, indices_2] if mask_0_1_2 else cutlass.Float32(0)
    v_0 = load + load_1
    result.__setitem__((indices_0, indices_1, indices_2), v_0) if mask_0_1_2 else None

def add_3d_kernel_reordered(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: result = x.new_empty(x.size())
    result = x.new_empty(x.size())
    # src[test_loops.py:N]: for tile in hl.grid(x.size()):
    _BLOCK_SIZE_0_1_2 = 1
    # src[test_loops.py:N]: for tile in hl.grid(x.size()):
    # src[test_loops.py:N]:     result[tile] = x[tile] + y[tile]
    _launcher(_helion_add_3d_kernel_reordered, ((4096 + _BLOCK_SIZE_0_1_2 - 1) // _BLOCK_SIZE_0_1_2,), x, y, result, _BLOCK_SIZE_0_1_2, block=(1, 1, 1))
    # src[test_loops.py:N]: return result
    return result

--- assertExpectedJournal(TestLoops.test_l2_grouping_with_register_block_size)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 32
_BLOCK_SIZE_1 = 16

@cute.kernel
def _helion_fn(x, out):
    # src[test_loops.py:N]: for tile0, tile1 in hl.tile(x.size(), block_size=[bs0, bs1]):
    num_pid_m = (2048 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0
    num_pid_n = (2048 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1
    inner_2d_pid = cute.arch.block_idx()[0]
    num_pid_in_group = 8 * num_pid_n
    group_id = inner_2d_pid // num_pid_in_group
    first_pid_m = group_id * 8
    group_size_m = min(num_pid_m - first_pid_m, 8)
    pid_0 = first_pid_m + inner_2d_pid % num_pid_in_group % group_size_m
    pid_1 = inner_2d_pid % num_pid_in_group // group_size_m
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
    # src[test_loops.py:N]: out[tile0, tile1] = x[tile0, tile1] + 1
    load = x[indices_0, indices_1]
    v_0 = 1
    v_1 = load + v_0
    out.__setitem__((indices_0, indices_1), v_1)

def fn(x: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: for tile0, tile1 in hl.tile(x.size(), block_size=[bs0, bs1]):
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 16
    # src[test_loops.py:N]: for tile0, tile1 in hl.tile(x.size(), block_size=[bs0, bs1]):
    # src[test_loops.py:N]:     out[tile0, tile1] = x[tile0, tile1] + 1
    _launcher(_helion_fn, ((2048 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((2048 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1),), x, out, block=(32, 16, 1))
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_loop_fixed_block)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 4
_BLOCK_SIZE_1 = 8
_BLOCK_SIZE_2 = 16

@cute.kernel
def _helion_fn(x, out):
    # src[test_loops.py:N]: for tile_a, tile_b in hl.tile([a, b], block_size=[4, 8]):
    num_blocks_0 = (128 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0
    pid_0 = cute.arch.block_idx()[0] % num_blocks_0
    pid_1 = cute.arch.block_idx()[0] // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
    # src[test_loops.py:N]: for tile_c in hl.tile(c, block_size=16):
    # src[test_loops.py:N]:     out[tile_a, tile_b, tile_c] = torch.sin(x[tile_a, tile_b, tile_c])
    for offset_2 in range(cutlass.Int32(0), cutlass.Int32(128), cutlass.Int32(_BLOCK_SIZE_2)):
        indices_2 = offset_2 + cutlass.Int32(cute.arch.thread_idx()[2])
        # src[test_loops.py:N]: out[tile_a, tile_b, tile_c] = torch.sin(x[tile_a, tile_b, tile_c])
        load = x[indices_0, indices_1, indices_2]
        v_0 = cute.math.sin(load)
        out.__setitem__((indices_0, indices_1, indices_2), v_0)

def fn(x: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: a, b, c = x.shape
    a, b, c = x.shape
    # src[test_loops.py:N]: for tile_a, tile_b in hl.tile([a, b], block_size=[4, 8]):
    _BLOCK_SIZE_0 = 4
    _BLOCK_SIZE_1 = 8
    # src[test_loops.py:N]: for tile_a, tile_b in hl.tile([a, b], block_size=[4, 8]):
    # src[test_loops.py:N]:     for tile_c in hl.tile(c, block_size=16):
    # src[test_loops.py:N]:         out[tile_a, tile_b, tile_c] = torch.sin(x[tile_a, tile_b, tile_c])
    _launcher(_helion_fn, ((128 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((128 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1),), x, out, block=(4, 8, 16))
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_loop_unroll1)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 4

@cute.kernel
def _helion_fn(x, out):
    # src[test_loops.py:N]: for tile in hl.tile(x.size()):
    pid_flat = cute.arch.block_idx()[0]
    offsets_0 = pid_flat * _BLOCK_SIZE_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    indices_0 = offsets_0
    mask_0 = cutlass.Int32(cute.arch.thread_idx()[0]) < _BLOCK_SIZE_0 and offsets_0 < 4
    # src[test_loops.py:N]: out[tile] = x[tile]
    load = x[indices_0] if mask_0 else cutlass.Float32(0)
    out.__setitem__((indices_0,), load) if mask_0 else None
    # src[test_loops.py:N]: out[tile] += i
    load_1 = out[indices_0] if mask_0 else cutlass.Float32(0)
    v_0 = 1
    v_1 = load_1 + v_0
    out.__setitem__((indices_0,), v_1) if mask_0 else None
    load_2 = out[indices_0] if mask_0 else cutlass.Float32(0)
    v_2 = 2
    v_3 = load_2 + v_2
    out.__setitem__((indices_0,), v_3) if mask_0 else None
    load_3 = out[indices_0] if mask_0 else cutlass.Float32(0)
    v_4 = 3
    v_5 = load_3 + v_4
    out.__setitem__((indices_0,), v_5) if mask_0 else None

def fn(x: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: out = torch.zeros_like(x)
    out = torch.zeros_like(x)
    # src[test_loops.py:N]: for tile in hl.tile(x.size()):
    _BLOCK_SIZE_0 = 4
    # src[test_loops.py:N]: for tile in hl.tile(x.size()):
    # src[test_loops.py:N]:     out[tile] = x[tile]
    # src[test_loops.py:N]:     for i in [1, 2, 3]:
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_fn, ((4 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0,), x, out, block=(4, 1, 1))
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_loop_unroll2)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 4

@cute.kernel
def _helion_fn(x, out):
    # src[test_loops.py:N]: for tile in hl.tile(x.size()):
    pid_flat = cute.arch.block_idx()[0]
    offsets_0 = pid_flat * _BLOCK_SIZE_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    indices_0 = offsets_0
    mask_0 = cutlass.Int32(cute.arch.thread_idx()[0]) < _BLOCK_SIZE_0 and offsets_0 < 4
    # src[test_loops.py:N]: out[tile] = x[tile]
    load = x[indices_0] if mask_0 else cutlass.Float32(0)
    out.__setitem__((indices_0,), load) if mask_0 else None
    # src[test_loops.py:N]: out[tile] += i
    load_1 = out[indices_0] if mask_0 else cutlass.Float32(0)
    v_0 = 1
    v_1 = load_1 + v_0
    out.__setitem__((indices_0,), v_1) if mask_0 else None
    load_2 = out[indices_0] if mask_0 else cutlass.Float32(0)
    v_2 = 2
    v_3 = load_2 + v_2
    out.__setitem__((indices_0,), v_3) if mask_0 else None
    load_3 = out[indices_0] if mask_0 else cutlass.Float32(0)
    v_4 = 3
    v_5 = load_3 + v_4
    out.__setitem__((indices_0,), v_5) if mask_0 else None

def fn(x: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: out = torch.zeros_like(x)
    out = torch.zeros_like(x)
    # src[test_loops.py:N]: for tile in hl.tile(x.size()):
    _BLOCK_SIZE_0 = 4
    # src[test_loops.py:N]: for tile in hl.tile(x.size()):
    # src[test_loops.py:N]:     out[tile] = x[tile]
    # src[test_loops.py:N]:     for i in (a, b, c):
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_fn, ((4 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0,), x, out, block=(4, 1, 1))
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_multiple_for_loop_1d)
from __future__ import annotations

import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 8
_BLOCK_SIZE_1 = 8
_BLOCK_SIZE_2 = 8

@cute.kernel
def _helion_addToBoth(x0, x1, x2, c0, c1, c2):
    # src[test_loops.py:N]: for tile in hl.tile(x0.size()):
    # src[test_loops.py:N]:     x0[tile] += c0
    pid_shared = cute.arch.block_idx()[0]
    if pid_shared < (5 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0:
        # src[test_loops.py:N]: for tile in hl.tile(x0.size()):
        pid_0 = pid_shared
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
        mask_0 = indices_0 < 5
        # src[test_loops.py:N]: x0[tile] += c0
        load = x0[indices_0] if mask_0 else cutlass.Float32(0)
        v_0 = cutlass.Float32(c0)
        v_1 = load + v_0
        x0.__setitem__((indices_0,), v_1) if mask_0 else None
    elif pid_shared < (5 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 + (5 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1:
        # src[test_loops.py:N]: for tile in hl.tile(x1.size()):
        pid_shared -= (5 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0
        pid_1 = pid_shared
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[0])
        mask_1 = indices_1 < 5
        # src[test_loops.py:N]: x1[tile] += c1
        load_1 = x1[indices_1] if mask_1 else cutlass.Float32(0)
        v_2 = cutlass.Float32(c1)
        v_3 = load_1 + v_2
        x1.__setitem__((indices_1,), v_3) if mask_1 else None
    else:
        # src[test_loops.py:N]: for tile in hl.tile(x2.size()):
        pid_shared -= (5 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 + (5 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1
        pid_2 = pid_shared
        offset_2 = pid_2 * _BLOCK_SIZE_2
        indices_2 = offset_2 + cutlass.Int32(cute.arch.thread_idx()[0])
        mask_2 = indices_2 < 5
        # src[test_loops.py:N]: x2[tile] += c2
        load_2 = x2[indices_2] if mask_2 else cutlass.Float32(0)
        v_4 = cutlass.Float32(c2)
        v_5 = load_2 + v_4
        x2.__setitem__((indices_2,), v_5) if mask_2 else None

def addToBoth(a, b, c, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: x0, c0 = a
    x0, c0 = a
    # src[test_loops.py:N]: x1, c1 = b
    x1, c1 = b
    # src[test_loops.py:N]: x2, c2 = c
    x2, c2 = c
    # src[test_loops.py:N]: for tile in hl.tile(x0.size()):
    _BLOCK_SIZE_0 = 8
    # src[test_loops.py:N]: for tile in hl.tile(x1.size()):
    _BLOCK_SIZE_1 = 8
    # src[test_loops.py:N]: for tile in hl.tile(x2.size()):
    _BLOCK_SIZE_2 = 8
    # src[test_loops.py:N]: for tile in hl.tile(x2.size()):
    # src[test_loops.py:N]:     x2[tile] += c2
    _launcher(_helion_addToBoth, ((5 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 + (5 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1 + (5 + _BLOCK_SIZE_2 - 1) // _BLOCK_SIZE_2,), x0, x1, x2, c0, c1, c2, block=(8, 1, 1))
    # src[test_loops.py:N]: return x0, x1, x2
    return (x0, x1, x2)

--- assertExpectedJournal(TestLoops.test_multiple_for_loop_2d)
from __future__ import annotations

import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 8
_BLOCK_SIZE_1 = 16
_BLOCK_SIZE_2 = 8
_BLOCK_SIZE_3 = 16
_BLOCK_SIZE_4 = 8
_BLOCK_SIZE_5 = 16

@cute.kernel
def _helion_addToBoth(x0, x1, x2, c0, c1, c2):
    # src[test_loops.py:N]: for tile_n in hl.tile(a_n):
    # src[test_loops.py:N]:     for tile_m in hl.tile(a_m):
    # src[test_loops.py:N]:         x0[tile_n, tile_m] += c0
    pid_shared = cute.arch.block_idx()[0]
    if pid_shared < (5 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0:
        # src[test_loops.py:N]: for tile_n in hl.tile(a_n):
        pid_0 = pid_shared
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
        mask_0 = indices_0 < 5
        # src[test_loops.py:N]: for tile_m in hl.tile(a_m):
        # src[test_loops.py:N]:     x0[tile_n, tile_m] += c0
        for offset_1 in range(cutlass.Int32(0), cutlass.Int32(10), cutlass.Int32(_BLOCK_SIZE_1)):
            indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
            mask_1 = indices_1 < 10
            # src[test_loops.py:N]: x0[tile_n, tile_m] += c0
            load = x0[indices_0, indices_1] if mask_0 and mask_1 else cutlass.Float32(0)
            v_0 = cutlass.Float32(c0)
            v_1 = load + v_0
            x0.__setitem__((indices_0, indices_1), v_1) if mask_0 and mask_1 else None
    elif pid_shared < (5 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 + (5 + _BLOCK_SIZE_2 - 1) // _BLOCK_SIZE_2:
        # src[test_loops.py:N]: for tile_n in hl.tile(b_n):
        pid_shared -= (5 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0
        pid_1 = pid_shared
        offset_2 = pid_1 * _BLOCK_SIZE_2
        indices_2 = offset_2 + cutlass.Int32(cute.arch.thread_idx()[0])
        mask_2 = indices_2 < 5
        # src[test_loops.py:N]: for tile_m in hl.tile(b_m):
        # src[test_loops.py:N]:     x1[tile_n, tile_m] += c1
        for offset_3 in range(cutlass.Int32(0), cutlass.Int32(10), cutlass.Int32(_BLOCK_SIZE_3)):
            indices_3 = offset_3 + cutlass.Int32(cute.arch.thread_idx()[1])
            mask_3 = indices_3 < 10
            # src[test_loops.py:N]: x1[tile_n, tile_m] += c1
            load_1 = x1[indices_2, indices_3] if mask_2 and mask_3 else cutlass.Float32(0)
            v_2 = cutlass.Float32(c1)
            v_3 = load_1 + v_2
            x1.__setitem__((indices_2, indices_3), v_3) if mask_2 and mask_3 else None
    else:
        # src[test_loops.py:N]: for tile_n in hl.tile(c_n):
        pid_shared -= (5 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 + (5 + _BLOCK_SIZE_2 - 1) // _BLOCK_SIZE_2
        pid_2 = pid_shared
        offset_4 = pid_2 * _BLOCK_SIZE_4
        indices_4 = offset_4 + cutlass.Int32(cute.arch.thread_idx()[0])
        mask_4 = indices_4 < 5
        # src[test_loops.py:N]: for tile_m in hl.tile(c_m):
        # src[test_loops.py:N]:     x2[tile_n, tile_m] += c2
        for offset_5 in range(cutlass.Int32(0), cutlass.Int32(10), cutlass.Int32(_BLOCK_SIZE_5)):
            indices_5 = offset_5 + cutlass.Int32(cute.arch.thread_idx()[1])
            mask_5 = indices_5 < 10
            # src[test_loops.py:N]: x2[tile_n, tile_m] += c2
            load_2 = x2[indices_4, indices_5] if mask_4 and mask_5 else cutlass.Float32(0)
            v_4 = cutlass.Float32(c2)
            v_5 = load_2 + v_4
            x2.__setitem__((indices_4, indices_5), v_5) if mask_4 and mask_5 else None

def addToBoth(a, b, c, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: x0, c0 = a
    x0, c0 = a
    # src[test_loops.py:N]: x1, c1 = b
    x1, c1 = b
    # src[test_loops.py:N]: x2, c2 = c
    x2, c2 = c
    # src[test_loops.py:N]: a_n, a_m = x0.shape
    a_n, a_m = x0.shape
    # src[test_loops.py:N]: b_n, b_m = x1.shape
    b_n, b_m = x1.shape
    # src[test_loops.py:N]: c_n, c_m = x2.shape
    c_n, c_m = x2.shape
    # src[test_loops.py:N]: for tile_n in hl.tile(a_n):
    _BLOCK_SIZE_0 = 8
    # src[test_loops.py:N]: for tile_n in hl.tile(b_n):
    _BLOCK_SIZE_2 = 8
    # src[test_loops.py:N]: for tile_n in hl.tile(c_n):
    _BLOCK_SIZE_4 = 8
    # src[test_loops.py:N]: for tile_n in hl.tile(c_n):
    # src[test_loops.py:N]:     for tile_m in hl.tile(c_m):
    # src[test_loops.py:N]:         x2[tile_n, tile_m] += c2
    _launcher(_helion_addToBoth, ((5 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 + (5 + _BLOCK_SIZE_2 - 1) // _BLOCK_SIZE_2 + (5 + _BLOCK_SIZE_4 - 1) // _BLOCK_SIZE_4,), x0, x1, x2, c0, c1, c2, block=(8, 16, 1))
    # src[test_loops.py:N]: return x0, x1, x2
    return (x0, x1, x2)

--- assertExpectedJournal(TestLoops.test_multiple_for_loop_2d_multiple_tile)
from __future__ import annotations

import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 8
_BLOCK_SIZE_1 = 16
_BLOCK_SIZE_2 = 8
_BLOCK_SIZE_3 = 16
_BLOCK_SIZE_4 = 8
_BLOCK_SIZE_5 = 16

@cute.kernel
def _helion_addToBoth(x0, x1, x2, c0, c1, c2):
    # src[test_loops.py:N]: for tile_n, tile_m in hl.tile([a_n, a_m]):
    # src[test_loops.py:N]:     x0[tile_n, tile_m] += c0
    pid_shared = cute.arch.block_idx()[0]
    if pid_shared < (5 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((10 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1):
        # src[test_loops.py:N]: for tile_n, tile_m in hl.tile([a_n, a_m]):
        num_blocks_0 = (5 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0
        pid_0 = pid_shared % num_blocks_0
        pid_1 = pid_shared // num_blocks_0
        offset_0 = pid_0 * _BLOCK_SIZE_0
        indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
        mask_0 = indices_0 < 5
        offset_1 = pid_1 * _BLOCK_SIZE_1
        indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
        mask_1 = indices_1 < 10
        # src[test_loops.py:N]: x0[tile_n, tile_m] += c0
        load = x0[indices_0, indices_1] if mask_0 and mask_1 else cutlass.Float32(0)
        v_0 = cutlass.Float32(c0)
        v_1 = load + v_0
        x0.__setitem__((indices_0, indices_1), v_1) if mask_0 and mask_1 else None
    elif pid_shared < (5 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((10 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1) + (5 + _BLOCK_SIZE_2 - 1) // _BLOCK_SIZE_2 * ((10 + _BLOCK_SIZE_3 - 1) // _BLOCK_SIZE_3):
        # src[test_loops.py:N]: for tile_n, tile_m in hl.tile([b_n, b_m]):
        pid_shared -= (5 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((10 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1)
        num_blocks_1 = (5 + _BLOCK_SIZE_2 - 1) // _BLOCK_SIZE_2
        pid_2 = pid_shared % num_blocks_1
        pid_3 = pid_shared // num_blocks_1
        offset_2 = pid_2 * _BLOCK_SIZE_2
        indices_2 = offset_2 + cutlass.Int32(cute.arch.thread_idx()[0])
        mask_2 = indices_2 < 5
        offset_3 = pid_3 * _BLOCK_SIZE_3
        indices_3 = offset_3 + cutlass.Int32(cute.arch.thread_idx()[1])
        mask_3 = indices_3 < 10
        # src[test_loops.py:N]: x1[tile_n, tile_m] += c1
        load_1 = x1[indices_2, indices_3] if mask_2 and mask_3 else cutlass.Float32(0)
        v_2 = cutlass.Float32(c1)
        v_3 = load_1 + v_2
        x1.__setitem__((indices_2, indices_3), v_3) if mask_2 and mask_3 else None
    else:
        # src[test_loops.py:N]: for tile_n, tile_m in hl.tile([c_n, c_m]):
        pid_shared -= (5 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((10 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1) + (5 + _BLOCK_SIZE_2 - 1) // _BLOCK_SIZE_2 * ((10 + _BLOCK_SIZE_3 - 1) // _BLOCK_SIZE_3)
        num_blocks_2 = (5 + _BLOCK_SIZE_4 - 1) // _BLOCK_SIZE_4
        pid_4 = pid_shared % num_blocks_2
        pid_5 = pid_shared // num_blocks_2
        offset_4 = pid_4 * _BLOCK_SIZE_4
        indices_4 = offset_4 + cutlass.Int32(cute.arch.thread_idx()[0])
        mask_4 = indices_4 < 5
        offset_5 = pid_5 * _BLOCK_SIZE_5
        indices_5 = offset_5 + cutlass.Int32(cute.arch.thread_idx()[1])
        mask_5 = indices_5 < 10
        # src[test_loops.py:N]: x2[tile_n, tile_m] += c2
        load_2 = x2[indices_4, indices_5] if mask_4 and mask_5 else cutlass.Float32(0)
        v_4 = cutlass.Float32(c2)
        v_5 = load_2 + v_4
        x2.__setitem__((indices_4, indices_5), v_5) if mask_4 and mask_5 else None

def addToBoth(a, b, c, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: x0, c0 = a
    x0, c0 = a
    # src[test_loops.py:N]: x1, c1 = b
    x1, c1 = b
    # src[test_loops.py:N]: x2, c2 = c
    x2, c2 = c
    # src[test_loops.py:N]: a_n, a_m = x0.shape
    a_n, a_m = x0.shape
    # src[test_loops.py:N]: b_n, b_m = x1.shape
    b_n, b_m = x1.shape
    # src[test_loops.py:N]: c_n, c_m = x2.shape
    c_n, c_m = x2.shape
    # src[test_loops.py:N]: for tile_n, tile_m in hl.tile([a_n, a_m]):
    _BLOCK_SIZE_0 = 8
    _BLOCK_SIZE_1 = 16
    # src[test_loops.py:N]: for tile_n, tile_m in hl.tile([b_n, b_m]):
    _BLOCK_SIZE_2 = 8
    _BLOCK_SIZE_3 = 16
    # src[test_loops.py:N]: for tile_n, tile_m in hl.tile([c_n, c_m]):
    _BLOCK_SIZE_4 = 8
    _BLOCK_SIZE_5 = 16
    # src[test_loops.py:N]: for tile_n, tile_m in hl.tile([c_n, c_m]):
    # src[test_loops.py:N]:     x2[tile_n, tile_m] += c2
    _launcher(_helion_addToBoth, ((5 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((10 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1) + (5 + _BLOCK_SIZE_2 - 1) // _BLOCK_SIZE_2 * ((10 + _BLOCK_SIZE_3 - 1) // _BLOCK_SIZE_3) + (5 + _BLOCK_SIZE_4 - 1) // _BLOCK_SIZE_4 * ((10 + _BLOCK_SIZE_5 - 1) // _BLOCK_SIZE_5),), x0, x1, x2, c0, c1, c2, block=(8, 16, 1))
    # src[test_loops.py:N]: return x0, x1, x2
    return (x0, x1, x2)

--- assertExpectedJournal(TestLoops.test_pointwise_device_loop)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 32
_BLOCK_SIZE_1 = 32

@cute.kernel
def _helion_pointwise_device_loop(x, out):
    # src[basic_kernels.py:N]: for tile_n in hl.tile(n):
    pid_0 = cute.arch.block_idx()[0]
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    # src[basic_kernels.py:N]: for tile_m in hl.tile(m):
    # src[basic_kernels.py:N]:     out[tile_n, tile_m] = torch.sigmoid(x[tile_n, tile_m] + 1)
    for offset_1 in range(cutlass.Int32(0), cutlass.Int32(512), cutlass.Int32(_BLOCK_SIZE_1)):
        indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
        # src[basic_kernels.py:N]: out[tile_n, tile_m] = torch.sigmoid(x[tile_n, tile_m] + 1)
        load = x[indices_0, indices_1]
        v_0 = 1
        v_1 = load + v_0
        v_2 = 1.0 / (1.0 + cute.math.exp2(-cutlass.Float32(v_1) * 1.4426950408889634))
        out.__setitem__((indices_0, indices_1), v_2)

def pointwise_device_loop(x: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[basic_kernels.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[basic_kernels.py:N]: n, m = x.shape
    n, m = x.shape
    # src[basic_kernels.py:N]: for tile_n in hl.tile(n):
    _BLOCK_SIZE_0 = 32
    # src[basic_kernels.py:N]: for tile_n in hl.tile(n):
    # src[basic_kernels.py:N]:     for tile_m in hl.tile(m):
    # src[basic_kernels.py:N]:         out[tile_n, tile_m] = torch.sigmoid(x[tile_n, tile_m] + 1)
    _launcher(_helion_pointwise_device_loop, ((512 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0,), x, out, block=(32, 32, 1))
    # src[basic_kernels.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_reorder_with_register_block_size)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_1 = 32
_BLOCK_SIZE_0 = 32

@cute.kernel
def _helion_fn(x, out):
    # src[test_loops.py:N]: for tile0, tile1 in hl.tile(x.size(), block_size=[bs0, bs1]):
    num_blocks_0 = (2048 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1
    pid_0 = cute.arch.block_idx()[0] % num_blocks_0
    pid_1 = cute.arch.block_idx()[0] // num_blocks_0
    offset_1 = pid_0 * _BLOCK_SIZE_1
    indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[0])
    offset_0 = pid_1 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[1])
    # src[test_loops.py:N]: out[tile0, tile1] = x[tile0, tile1] + 1
    load = x[indices_0, indices_1]
    v_0 = 1
    v_1 = load + v_0
    out.__setitem__((indices_0, indices_1), v_1)

def fn(x: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_loops.py:N]: for tile0, tile1 in hl.tile(x.size(), block_size=[bs0, bs1]):
    _BLOCK_SIZE_1 = 32
    _BLOCK_SIZE_0 = 32
    # src[test_loops.py:N]: for tile0, tile1 in hl.tile(x.size(), block_size=[bs0, bs1]):
    # src[test_loops.py:N]:     out[tile0, tile1] = x[tile0, tile1] + 1
    _launcher(_helion_fn, ((2048 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1 * ((2048 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0),), x, out, block=(32, 32, 1))
    # src[test_loops.py:N]: return out
    return out

--- assertExpectedJournal(TestLoops.test_while_atomic_cas_pass)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 16

@cute.kernel
def _helion_kernel(grad_x_lock):
    # src[test_loops.py:N]: for idx in hl.tile(grad_x_lock.size(0)):
    pid_flat = cute.arch.block_idx()[0]
    offsets_0 = pid_flat * _BLOCK_SIZE_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    indices_0 = offsets_0
    # src[test_loops.py:N]: while hl.atomic_cas(grad_x_lock, [idx], 0, 1) == 1:
    atomic_cas = cute.arch.atomic_cas(grad_x_lock.iterator + cute.crd2idx((indices_0,), grad_x_lock.layout), cmp=0, val=1, sem='relaxed')
    v_0 = 1
    v_1 = operator.eq(atomic_cas, v_0)
    # src[test_loops.py:N]: while hl.atomic_cas(grad_x_lock, [idx], 0, 1) == 1:
    # src[test_loops.py:N]:     pass
    while_cond = v_1
    while while_cond:
        # src[test_loops.py:N]: while hl.atomic_cas(grad_x_lock, [idx], 0, 1) == 1:
        atomic_cas_1 = cute.arch.atomic_cas(grad_x_lock.iterator + cute.crd2idx((indices_0,), grad_x_lock.layout), cmp=0, val=1, sem='relaxed')
        v_2 = 1
        v_3 = operator.eq(atomic_cas_1, v_2)
        # src[test_loops.py:N]: while hl.atomic_cas(grad_x_lock, [idx], 0, 1) == 1:
        # src[test_loops.py:N]:     pass
        while_cond = v_3
    # src[test_loops.py:N]: hl.atomic_cas(grad_x_lock, [idx], 1, 0)
    cute.arch.atomic_cas(grad_x_lock.iterator + cute.crd2idx((indices_0,), grad_x_lock.layout), cmp=1, val=0, sem='relaxed')

def kernel(grad_x_lock: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_loops.py:N]: for idx in hl.tile(grad_x_lock.size(0)):
    _BLOCK_SIZE_0 = 16
    # src[test_loops.py:N]: for idx in hl.tile(grad_x_lock.size(0)):
    # src[test_loops.py:N]:     while hl.atomic_cas(grad_x_lock, [idx], 0, 1) == 1:
    # src[test_loops.py:N]:         pass
    # src[test_loops.py:N-N]: ...
    _launcher(_helion_kernel, ((16 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0,), grad_x_lock, block=(16, 1, 1))
    # src[test_loops.py:N]: return grad_x_lock
    return grad_x_lock
