This file is automatically generated by assertExpectedJournal calls in test_cute_backend.py.
Update expected outputs by running tests with the EXPECTTEST_ACCEPT=1 environment variable set.

--- assertExpectedJournal(TestCuteBackend.test_kwargs_dispatch)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 32
_BLOCK_SIZE_1 = 32

@cute.kernel
def _helion_cute_affine_scalar_args(x, out, scale, bias):
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    num_blocks_0 = (65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0
    pid_0 = cute.arch.block_idx()[0] % num_blocks_0
    pid_1 = cute.arch.block_idx()[0] // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    mask_0 = indices_0 < 65
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
    mask_1 = indices_1 < 23
    # src[test_cute_backend.py:N]: out[tile] = x[tile] * scale + bias
    load = x[indices_0, indices_1] if mask_0 and mask_1 else cutlass.Float32(0)
    v_0 = cutlass.Float32(scale)
    v_1 = load * v_0
    v_2 = v_1 + bias
    out.__setitem__((indices_0, indices_1), v_2) if mask_0 and mask_1 else None

def cute_affine_scalar_args(x: torch.Tensor, scale: int, bias: float, *, _launcher=_default_cute_launcher):
    # src[test_cute_backend.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    # src[test_cute_backend.py:N]:     out[tile] = x[tile] * scale + bias
    _launcher(_helion_cute_affine_scalar_args, ((65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((23 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1),), x, out, scale, bias, block=(32, 32, 1))
    # src[test_cute_backend.py:N]: return out
    return out

--- assertExpectedJournal(TestCuteBackend.test_pointwise_add)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 32
_BLOCK_SIZE_1 = 32

@cute.kernel
def _helion_cute_add(x, y, out):
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    num_blocks_0 = (65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0
    pid_0 = cute.arch.block_idx()[0] % num_blocks_0
    pid_1 = cute.arch.block_idx()[0] // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    mask_0 = indices_0 < 65
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
    mask_1 = indices_1 < 23
    # src[test_cute_backend.py:N]: out[tile] = x[tile] + y[tile]
    load = x[indices_0, indices_1] if mask_0 and mask_1 else cutlass.Float32(0)
    load_1 = y[indices_0, indices_1] if mask_0 and mask_1 else cutlass.Float32(0)
    v_0 = load + load_1
    out.__setitem__((indices_0, indices_1), v_0) if mask_0 and mask_1 else None

def cute_add(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_cute_backend.py:N]: x, y = torch.broadcast_tensors(x, y)
    x, y = torch.broadcast_tensors(x, y)
    # src[test_cute_backend.py:N]: out = torch.empty(
    # src[test_cute_backend.py:N]:     x.shape,
    # src[test_cute_backend.py:N]:     dtype=torch.promote_types(x.dtype, y.dtype),
    # src[test_cute_backend.py:N-N]: ...
    out = torch.empty(x.shape, dtype=torch.promote_types(x.dtype, y.dtype), device=x.device)
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    # src[test_cute_backend.py:N]:     out[tile] = x[tile] + y[tile]
    _launcher(_helion_cute_add, ((65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((23 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1),), x, y, out, block=(32, 32, 1))
    # src[test_cute_backend.py:N]: return out
    return out

--- assertExpectedJournal(TestCuteBackend.test_pointwise_add_three_inputs)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 32
_BLOCK_SIZE_1 = 32

@cute.kernel
def _helion_cute_add3(x, y, z, out):
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    num_blocks_0 = (65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0
    pid_0 = cute.arch.block_idx()[0] % num_blocks_0
    pid_1 = cute.arch.block_idx()[0] // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    mask_0 = indices_0 < 65
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
    mask_1 = indices_1 < 23
    # src[test_cute_backend.py:N]: out[tile] = x[tile] + y[tile] + z[tile]
    load = x[indices_0, indices_1] if mask_0 and mask_1 else cutlass.Float32(0)
    load_1 = y[indices_0, indices_1] if mask_0 and mask_1 else cutlass.Float32(0)
    v_0 = load + load_1
    load_2 = z[indices_0, indices_1] if mask_0 and mask_1 else cutlass.Float32(0)
    v_1 = v_0 + load_2
    out.__setitem__((indices_0, indices_1), v_1) if mask_0 and mask_1 else None

def cute_add3(x: torch.Tensor, y: torch.Tensor, z: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_cute_backend.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    # src[test_cute_backend.py:N]:     out[tile] = x[tile] + y[tile] + z[tile]
    _launcher(_helion_cute_add3, ((65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((23 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1),), x, y, z, out, block=(32, 32, 1))
    # src[test_cute_backend.py:N]: return out
    return out

--- assertExpectedJournal(TestCuteBackend.test_pointwise_chain)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 32
_BLOCK_SIZE_1 = 32

@cute.kernel
def _helion_cute_pointwise_chain(x, y, out):
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    num_blocks_0 = (65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0
    pid_0 = cute.arch.block_idx()[0] % num_blocks_0
    pid_1 = cute.arch.block_idx()[0] // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    mask_0 = indices_0 < 65
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
    mask_1 = indices_1 < 23
    # src[test_cute_backend.py:N]: out[tile] = torch.sigmoid(torch.sin(torch.relu(x[tile] * y[tile])))
    load = x[indices_0, indices_1] if mask_0 and mask_1 else cutlass.Float32(0)
    load_1 = y[indices_0, indices_1] if mask_0 and mask_1 else cutlass.Float32(0)
    v_0 = load * load_1
    v_1 = 0
    v_2 = cutlass.Float32(v_0) if cutlass.Float32(v_0) > cutlass.Float32(v_1) else cutlass.Float32(v_1)
    v_3 = cute.math.sin(v_2)
    v_4 = 1.0 / (1.0 + cute.math.exp2(-cutlass.Float32(v_3) * 1.4426950408889634))
    out.__setitem__((indices_0, indices_1), v_4) if mask_0 and mask_1 else None

def cute_pointwise_chain(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_cute_backend.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    # src[test_cute_backend.py:N]:     out[tile] = torch.sigmoid(torch.sin(torch.relu(x[tile] * y[tile])))
    _launcher(_helion_cute_pointwise_chain, ((65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((23 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1),), x, y, out, block=(32, 32, 1))
    # src[test_cute_backend.py:N]: return out
    return out

--- assertExpectedJournal(TestCuteBackend.test_pointwise_mul)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 32
_BLOCK_SIZE_1 = 32

@cute.kernel
def _helion_cute_mul(x, y, out):
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    num_blocks_0 = (65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0
    pid_0 = cute.arch.block_idx()[0] % num_blocks_0
    pid_1 = cute.arch.block_idx()[0] // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    mask_0 = indices_0 < 65
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
    mask_1 = indices_1 < 23
    # src[test_cute_backend.py:N]: out[tile] = x[tile] * y[tile]
    load = x[indices_0, indices_1] if mask_0 and mask_1 else cutlass.Float32(0)
    load_1 = y[indices_0, indices_1] if mask_0 and mask_1 else cutlass.Float32(0)
    v_0 = load * load_1
    out.__setitem__((indices_0, indices_1), v_0) if mask_0 and mask_1 else None

def cute_mul(x: torch.Tensor, y: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_cute_backend.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    # src[test_cute_backend.py:N]:     out[tile] = x[tile] * y[tile]
    _launcher(_helion_cute_mul, ((65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((23 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1),), x, y, out, block=(32, 32, 1))
    # src[test_cute_backend.py:N]: return out
    return out

--- assertExpectedJournal(TestCuteBackend.test_pointwise_relu)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 32
_BLOCK_SIZE_1 = 32

@cute.kernel
def _helion_cute_relu(x, out):
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    num_blocks_0 = (65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0
    pid_0 = cute.arch.block_idx()[0] % num_blocks_0
    pid_1 = cute.arch.block_idx()[0] // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    mask_0 = indices_0 < 65
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
    mask_1 = indices_1 < 23
    # src[test_cute_backend.py:N]: out[tile] = torch.relu(x[tile])
    load = x[indices_0, indices_1] if mask_0 and mask_1 else cutlass.Float32(0)
    v_0 = 0
    v_1 = cutlass.Float32(load) if cutlass.Float32(load) > cutlass.Float32(v_0) else cutlass.Float32(v_0)
    out.__setitem__((indices_0, indices_1), v_1) if mask_0 and mask_1 else None

def cute_relu(x: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_cute_backend.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    # src[test_cute_backend.py:N]:     out[tile] = torch.relu(x[tile])
    _launcher(_helion_cute_relu, ((65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((23 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1),), x, out, block=(32, 32, 1))
    # src[test_cute_backend.py:N]: return out
    return out

--- assertExpectedJournal(TestCuteBackend.test_pointwise_sigmoid)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 32
_BLOCK_SIZE_1 = 32

@cute.kernel
def _helion_cute_sigmoid(x, out):
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    num_blocks_0 = (65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0
    pid_0 = cute.arch.block_idx()[0] % num_blocks_0
    pid_1 = cute.arch.block_idx()[0] // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    mask_0 = indices_0 < 65
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
    mask_1 = indices_1 < 23
    # src[test_cute_backend.py:N]: out[tile] = torch.sigmoid(x[tile])
    load = x[indices_0, indices_1] if mask_0 and mask_1 else cutlass.Float16(0)
    v_0 = cutlass.Float16(1.0 / (1.0 + cute.math.exp2(-cutlass.Float32(load) * 1.4426950408889634)))
    out.__setitem__((indices_0, indices_1), v_0) if mask_0 and mask_1 else None

def cute_sigmoid(x: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_cute_backend.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    # src[test_cute_backend.py:N]:     out[tile] = torch.sigmoid(x[tile])
    _launcher(_helion_cute_sigmoid, ((65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((23 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1),), x, out, block=(32, 32, 1))
    # src[test_cute_backend.py:N]: return out
    return out

--- assertExpectedJournal(TestCuteBackend.test_pointwise_sin)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 32
_BLOCK_SIZE_1 = 32

@cute.kernel
def _helion_cute_sin(x, out):
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    num_blocks_0 = (65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0
    pid_0 = cute.arch.block_idx()[0] % num_blocks_0
    pid_1 = cute.arch.block_idx()[0] // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    mask_0 = indices_0 < 65
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
    mask_1 = indices_1 < 23
    # src[test_cute_backend.py:N]: out[tile] = torch.sin(x[tile])
    load = x[indices_0, indices_1] if mask_0 and mask_1 else cutlass.Float32(0)
    v_0 = cute.math.sin(load)
    out.__setitem__((indices_0, indices_1), v_0) if mask_0 and mask_1 else None

def cute_sin(x: torch.Tensor, *, _launcher=_default_cute_launcher):
    # src[test_cute_backend.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    # src[test_cute_backend.py:N]:     out[tile] = torch.sin(x[tile])
    _launcher(_helion_cute_sin, ((65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((23 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1),), x, out, block=(32, 32, 1))
    # src[test_cute_backend.py:N]: return out
    return out

--- assertExpectedJournal(TestCuteBackend.test_scalar_args_int_and_float)
from __future__ import annotations

import torch
import cutlass
import cutlass.cute as cute
from helion.runtime import default_cute_launcher as _default_cute_launcher

_BLOCK_SIZE_0 = 32
_BLOCK_SIZE_1 = 32

@cute.kernel
def _helion_cute_affine_scalar_args(x, out, scale, bias):
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    num_blocks_0 = (65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0
    pid_0 = cute.arch.block_idx()[0] % num_blocks_0
    pid_1 = cute.arch.block_idx()[0] // num_blocks_0
    offset_0 = pid_0 * _BLOCK_SIZE_0
    indices_0 = offset_0 + cutlass.Int32(cute.arch.thread_idx()[0])
    mask_0 = indices_0 < 65
    offset_1 = pid_1 * _BLOCK_SIZE_1
    indices_1 = offset_1 + cutlass.Int32(cute.arch.thread_idx()[1])
    mask_1 = indices_1 < 23
    # src[test_cute_backend.py:N]: out[tile] = x[tile] * scale + bias
    load = x[indices_0, indices_1] if mask_0 and mask_1 else cutlass.Float32(0)
    v_0 = cutlass.Float32(scale)
    v_1 = load * v_0
    v_2 = v_1 + bias
    out.__setitem__((indices_0, indices_1), v_2) if mask_0 and mask_1 else None

def cute_affine_scalar_args(x: torch.Tensor, scale: int, bias: float, *, _launcher=_default_cute_launcher):
    # src[test_cute_backend.py:N]: out = torch.empty_like(x)
    out = torch.empty_like(x)
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    _BLOCK_SIZE_0 = 32
    _BLOCK_SIZE_1 = 32
    # src[test_cute_backend.py:N]: for tile in hl.tile(out.size()):
    # src[test_cute_backend.py:N]:     out[tile] = x[tile] * scale + bias
    _launcher(_helion_cute_affine_scalar_args, ((65 + _BLOCK_SIZE_0 - 1) // _BLOCK_SIZE_0 * ((23 + _BLOCK_SIZE_1 - 1) // _BLOCK_SIZE_1),), x, out, scale, bias, block=(32, 32, 1))
    # src[test_cute_backend.py:N]: return out
    return out
